<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Appendix C — Linear Algebra – Numerical Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ex_exam_solns.html" rel="prev">
<link href="./faviconNA.webp" rel="icon">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a439ec2cc0f685a3af892e5cbc7e709d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Appendix C — Linear Algebra – Numerical Analysis">
<meta property="og:description" content="">
<meta property="og:site_name" content="Numerical Analysis">
<meta name="twitter:title" content="Appendix C — Linear Algebra – Numerical Analysis">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./nmPython.html">Appendices</a></li><li class="breadcrumb-item"><a href="./nmLinAlg.html"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Linear Algebra</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Numerical Analysis</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://vle.york.ac.uk/ultra/courses/_115112_1/outline" title="VLE" class="quarto-navigation-tool px-1" aria-label="VLE"><i class="bi bi-house-door-fill"></i></a>
    <a href="https://maths.york.ac.uk/moodle/course/view.php?id=2727" title="Moodle quizzes" class="quarto-navigation-tool px-1" aria-label="Moodle quizzes"><i class="bi bi-mortarboard-fill"></i></a>
    <a href="https://github.com/gustavdelius/NumericalAnalysis2026/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Numerical-Analysis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmNumbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmFunctions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Functions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmRoots1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Roots 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmRoots2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Roots 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmCalculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Derivatives, Integrals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmOptimisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Optimisation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmODE1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ODEs 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmODE2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">ODEs 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmPDE1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">PDEs 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmPDE2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">PDEs 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmPython.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex_exam_solns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Exam solutions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nmLinAlg.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Linear Algebra</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#intro-to-numerical-linear-algebra" id="toc-intro-to-numerical-linear-algebra" class="nav-link active" data-scroll-target="#intro-to-numerical-linear-algebra"><span class="header-section-number">C.1</span> Intro to Numerical Linear Algebra</a></li>
  <li><a href="#notation" id="toc-notation" class="nav-link" data-scroll-target="#notation"><span class="header-section-number">C.2</span> Notation</a></li>
  <li><a href="#vectors-and-matrices-in-python" id="toc-vectors-and-matrices-in-python" class="nav-link" data-scroll-target="#vectors-and-matrices-in-python"><span class="header-section-number">C.3</span> Vectors and Matrices in Python</a></li>
  <li><a href="#matrix-and-vector-operations" id="toc-matrix-and-vector-operations" class="nav-link" data-scroll-target="#matrix-and-vector-operations"><span class="header-section-number">C.4</span> Matrix and Vector Operations</a>
  <ul>
  <li><a href="#the-dot-product" id="toc-the-dot-product" class="nav-link" data-scroll-target="#the-dot-product"><span class="header-section-number">C.4.1</span> The Dot Product</a></li>
  <li><a href="#matrix-multiplication" id="toc-matrix-multiplication" class="nav-link" data-scroll-target="#matrix-multiplication"><span class="header-section-number">C.4.2</span> Matrix Multiplication</a></li>
  </ul></li>
  <li><a href="#the-lu-factorization" id="toc-the-lu-factorization" class="nav-link" data-scroll-target="#the-lu-factorization"><span class="header-section-number">C.5</span> The LU Factorization</a>
  <ul>
  <li><a href="#a-recap-of-row-reduction" id="toc-a-recap-of-row-reduction" class="nav-link" data-scroll-target="#a-recap-of-row-reduction"><span class="header-section-number">C.5.1</span> A Recap of Row Reduction</a></li>
  <li><a href="#the-lu-decomposition" id="toc-the-lu-decomposition" class="nav-link" data-scroll-target="#the-lu-decomposition"><span class="header-section-number">C.5.2</span> The LU Decomposition</a></li>
  <li><a href="#solving-triangular-systems" id="toc-solving-triangular-systems" class="nav-link" data-scroll-target="#solving-triangular-systems"><span class="header-section-number">C.5.3</span> Solving Triangular Systems</a></li>
  <li><a href="#solving-systems-with-lu-decomposition" id="toc-solving-systems-with-lu-decomposition" class="nav-link" data-scroll-target="#solving-systems-with-lu-decomposition"><span class="header-section-number">C.5.4</span> Solving Systems with LU Decomposition</a></li>
  </ul></li>
  <li><a href="#the-qr-factorization" id="toc-the-qr-factorization" class="nav-link" data-scroll-target="#the-qr-factorization"><span class="header-section-number">C.6</span> The QR Factorization</a></li>
  <li><a href="#over-determined-systems-and-curve-fitting" id="toc-over-determined-systems-and-curve-fitting" class="nav-link" data-scroll-target="#over-determined-systems-and-curve-fitting"><span class="header-section-number">C.7</span> Over-determined Systems and Curve Fitting</a></li>
  <li><a href="#the-eigenvalue-eigenvector-problem" id="toc-the-eigenvalue-eigenvector-problem" class="nav-link" data-scroll-target="#the-eigenvalue-eigenvector-problem"><span class="header-section-number">C.8</span> The Eigenvalue-Eigenvector Problem</a></li>
  <li><a href="#algorithm-summaries" id="toc-algorithm-summaries" class="nav-link" data-scroll-target="#algorithm-summaries"><span class="header-section-number">C.9</span> Algorithm Summaries</a></li>
  <li><a href="#problems" id="toc-problems" class="nav-link" data-scroll-target="#problems"><span class="header-section-number">C.10</span> Problems</a></li>
  <li><a href="#projects" id="toc-projects" class="nav-link" data-scroll-target="#projects"><span class="header-section-number">C.11</span> Projects</a>
  <ul>
  <li><a href="#the-google-page-rank-algorithm" id="toc-the-google-page-rank-algorithm" class="nav-link" data-scroll-target="#the-google-page-rank-algorithm"><span class="header-section-number">C.11.1</span> The Google Page Rank Algorithm</a></li>
  <li><a href="#alternative-methods-for-solving-a-boldsymbolx-boldsymbolb" id="toc-alternative-methods-for-solving-a-boldsymbolx-boldsymbolb" class="nav-link" data-scroll-target="#alternative-methods-for-solving-a-boldsymbolx-boldsymbolb"><span class="header-section-number">C.11.2</span> Alternative Methods For Solving <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span></a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/gustavdelius/NumericalAnalysis2026/edit/main/nmLinAlg.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./nmPython.html">Appendices</a></li><li class="breadcrumb-item"><a href="./nmLinAlg.html"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Linear Algebra</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-linearalgebra" class="quarto-section-identifier">Appendix C — Linear Algebra</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><em>You cannot learn too much linear algebra.</em><br>
– Every mathematician</p>
</blockquote>
<section id="intro-to-numerical-linear-algebra" class="level2" data-number="C.1">
<h2 data-number="C.1" class="anchored" data-anchor-id="intro-to-numerical-linear-algebra"><span class="header-section-number">C.1</span> Intro to Numerical Linear Algebra</h2>
<p>The preceding comment says it all – linear algebra is the most important of all of the mathematical tools that you can learn as a practitioner of the mathematical sciences. The theorems, proofs, conjectures, and big ideas in almost every other mathematical field find their roots in linear algebra. Numerical Linear Algebra is the study of algorithms for solving problems in linear algebra. This subject has a somewhat different flavour than the numerical analysis we are studying in the main text and hence we present it as an optional appendix.</p>
<p>Our goal in this appendix is to explore numerical algorithms for the primary questions of linear algebra:</p>
<ul>
<li><p>solving systems of equations,</p></li>
<li><p>finding eigenvalue-eigenvector pairs for a matrix.</p></li>
</ul>
<p>Take careful note that in our current digital age, numerical linear algebra and its fast algorithms are behind the scenes for wide varieties of computing applications. Applications of numerical linear algebra include:</p>
<ul>
<li><p>building neural networks and AI algorithms,</p></li>
<li><p>determining the most important web page in a Google search,</p></li>
<li><p>modelling realistic 3D environments in video games,</p></li>
<li><p>digital image processing,</p></li>
<li><p>and many many more.</p></li>
</ul>
<p>What’s more, researchers have found provably optimal ways to perform most of the typical tasks of linear algebra so most scientific software works very well and very quickly with linear algebra.</p>
</section>
<section id="notation" class="level2" data-number="C.2">
<h2 data-number="C.2" class="anchored" data-anchor-id="notation"><span class="header-section-number">C.2</span> Notation</h2>
<p>Throughout this chapter we will use the following notation conventions.</p>
<ul>
<li><p>A bold mathematical symbol such as <span class="math inline">\(\boldsymbol{x}\)</span> or <span class="math inline">\(\boldsymbol{u}\)</span> will represent a vector.</p></li>
<li><p>If <span class="math inline">\(\boldsymbol{u}\)</span> is a vector then <span class="math inline">\(u_j\)</span> will be the <span class="math inline">\(j^{th}\)</span> entry of the vector.</p></li>
<li><p>Vectors will typically be written vertically with parenthesis as delimiters such as <span class="math display">\[\begin{equation}
\boldsymbol{u} = \begin{pmatrix} 1\\2\\3 \end{pmatrix}.
\end{equation}\]</span></p></li>
<li><p>Two bold symbols separated by a centred dot such as <span class="math inline">\(\boldsymbol{u} \cdot \boldsymbol{v}\)</span> will represent the dot product of two vectors.</p></li>
<li><p>A capital mathematical symbol such as <span class="math inline">\(A\)</span> or <span class="math inline">\(X\)</span> will represent a matrix</p></li>
<li><p>If <span class="math inline">\(A\)</span> is a matrix then <span class="math inline">\(A_{ij}\)</span> will be the element in the <span class="math inline">\(i^{th}\)</span> row and <span class="math inline">\(j^{th}\)</span> column of the matrix.</p></li>
<li><p>A matrix will typically be written with parenthesis as delimiters such as <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; \pi \end{pmatrix}.
\end{equation}\]</span></p></li>
<li><p>The juxtaposition of a capital symbol and a bold symbol such as <span class="math inline">\(A\boldsymbol{x}\)</span> will represent matrix-vector multiplication.</p></li>
<li><p>A lower case or Greek mathematical symbol such as <span class="math inline">\(x\)</span>, <span class="math inline">\(c\)</span>, or <span class="math inline">\(\lambda\)</span> will represent a scalar.</p></li>
<li><p>The scalar field of real numbers is given as <span class="math inline">\(\mathbb{R}\)</span> and the scalar field of complex numbers is given as <span class="math inline">\(\mathbb{C}\)</span>.</p></li>
<li><p>The symbol <span class="math inline">\(\mathbb{R}^n\)</span> represents the collection of all <span class="math inline">\(n\)</span>-dimensional vectors where the elements are drawn from the real numbers.</p></li>
<li><p>The symbol <span class="math inline">\(\mathbb{C}^n\)</span> represents the collection of all <span class="math inline">\(n\)</span>-dimensional vectors where the elements are drawn from the complex numbers.</p></li>
</ul>
<p>It is an important part of learning to read and write linear algebra to give special attention to the symbolic language so you can communicate your work easily and efficiently.</p>
</section>
<section id="vectors-and-matrices-in-python" class="level2" data-number="C.3">
<h2 data-number="C.3" class="anchored" data-anchor-id="vectors-and-matrices-in-python"><span class="header-section-number">C.3</span> Vectors and Matrices in Python</h2>
<p>We first need to understand how Python’s <code>numpy</code> library builds and stores vectors and matrices. The following exercises will give you some experience building and working with these data structures and will point out some common pitfalls that mathematicians fall into when using Python for linear algebra.</p>
<hr>
<div id="exm-4.1" class="theorem example">
<p><span class="theorem-title"><strong>Example C.1 (numpy Arrays)</strong></span> In Python you can build a list using square brackets such as <code>[1,2,3]</code>. This is called a “Python list” and is NOT a vector in the way that we think about it mathematically. It is simply an ordered collection of objects. To build mathematical vectors in Python we need to use <code>numpy</code> arrays with <code>np.array()</code>. For example, the vector <span class="math display">\[\begin{equation}
\boldsymbol{u} = \begin{pmatrix} 1\\2\\3\end{pmatrix}
\end{equation}\]</span> would be built with the following code.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>])</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(u)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Notice that Python defines the vector <code>u</code> as a matrix with only one dimension. You can see that in the following code.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The length of the u vector is </span><span class="ch">\n</span><span class="st">"</span>,<span class="bu">len</span>(u))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The shape of the u vector is </span><span class="ch">\n</span><span class="st">"</span>,u.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exm-4.2" class="theorem example">
<p><span class="theorem-title"><strong>Example C.2 (numpy Matrices)</strong></span> In <code>numpy</code>, a matrix is validly built as a list of lists. For example, the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{pmatrix}
\end{equation}\]</span> is defined using <code>np.array()</code> where each row is an individual list, and the matrix is a collection of these lists.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>],[<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>]])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Moreover, we can extract the shape, the number of rows, and the number of columns of <span class="math inline">\(A\)</span> using the <code>A.shape</code> command. To be a bit more clear on this one we will use the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}
\end{equation}\]</span></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The shape of the A matrix is </span><span class="ch">\n</span><span class="st">"</span>,A.shape)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of rows in A is </span><span class="ch">\n</span><span class="st">"</span>,A.shape[<span class="dv">0</span>])</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of columns in A is </span><span class="ch">\n</span><span class="st">"</span>,A.shape[<span class="dv">1</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exm-4.3" class="theorem example">
<p><span class="theorem-title"><strong>Example C.3 (Row and Column Vectors in Python)</strong></span> You can more specifically build row or column vectors in Python using the <code>np.array()</code> command and then only specifying one row or column. But take careful note that <code>numpy</code> treats a 1D array (like <code>np.array([1,2,3])</code>) differently from a 2D array (like <code>np.array([[1,2,3]])</code>). For example, if you want the vectors <span class="math display">\[\begin{equation}
\boldsymbol{u} = \begin{pmatrix} 1\\2\\3\end{pmatrix} \quad \text{and} \quad \boldsymbol{v} = \begin{pmatrix} 4 &amp; 5 &amp; 6 \end{pmatrix}
\end{equation}\]</span> then we would use the following Python code.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.array([[<span class="dv">1</span>],[<span class="dv">2</span>],[<span class="dv">3</span>]])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The column vector u is </span><span class="ch">\n</span><span class="st">"</span>,u)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]])</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The row vector v is </span><span class="ch">\n</span><span class="st">"</span>,v)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Alternatively, if you want to define a column vector you can define a row vector (since there are far fewer brackets to keep track of) and then transpose the matrix to turn it into a column. Note that the <code>.transpose()</code> method (or <code>.T</code>) only swaps dimensions; it won’t turn a 1D array into a 2D column vector unless it was already 2D.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> u.transpose()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The column vector u is </span><span class="ch">\n</span><span class="st">"</span>,u)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exm-4.4" class="theorem example">
<p><span class="theorem-title"><strong>Example C.4 (Matrix Indexing)</strong></span> Python indexes all arrays, vectors, lists, and matrices starting from index 0. Let us get used to this fact.</p>
<p>Consider the matrix <span class="math inline">\(A\)</span> defined in the previous problem. Mathematically we know that the entry in row 1 column 1 is a 1, the entry in row 1 column 2 is a 2, and so on. However, with Python we need to shift the way that we enumerate the rows and columns of a matrix. Hence we would say that the entry in row 0 column 0 is a 1, the entry in row 0 column 1 is a 2, and so on.</p>
<p>Mathematically we can view all Python matrices as follows. If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times n\)</span> matrix then <span class="math display">\[\begin{equation}
A = \begin{pmatrix} A_{0,0} &amp; A_{0,1} &amp; A_{0,2} &amp; \cdots &amp; A_{0,n-1} \\ A_{1,0} &amp; A_{1,1} &amp; A_{1,2} &amp; \cdots &amp; A_{1,n-1} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ A_{n-1,0} &amp; A_{n-1,1} &amp; A_{n-1,2} &amp; \cdots &amp; A_{n-1,n-1} \end{pmatrix}
\end{equation}\]</span></p>
<p>Similarly, we can view all vectors as follows. If <span class="math inline">\(\boldsymbol{u}\)</span> is an <span class="math inline">\(n \times 1\)</span> vector then <span class="math display">\[\begin{equation}
\boldsymbol{u} = \begin{pmatrix} u_0 \\ u_1 \\ \vdots \\ u_{n-1} \end{pmatrix}
\end{equation}\]</span></p>
<p>The following code should help to illustrate this indexing convention.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>],[<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>]])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Entry in row 0 column 0 is"</span>,A[<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Entry in row 0 column 1 is"</span>,A[<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Entry in the bottom right corner"</span>,A[<span class="dv">2</span>,<span class="dv">2</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.1</strong></span> Build your own matrix in Python and practice choosing individual entries from the matrix.</p>
</div>
<hr>
<div id="exm-4.5" class="theorem example">
<p><span class="theorem-title"><strong>Example C.5 (Matrix Slicing)</strong></span> The last thing that we need to be familiar with is <em>slicing</em> a matrix. The term “slicing” generally refers to pulling out individual rows, columns, entries, or blocks from a list, array, or matrix in Python. Examine the code below to see how to slice parts out of a <code>numpy</code> matrix.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>],[<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>]])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The first column of A is </span><span class="ch">\n</span><span class="st">"</span>,A[:,<span class="dv">0</span>])</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The second row of A is </span><span class="ch">\n</span><span class="st">"</span>,A[<span class="dv">1</span>,:])</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The top left 2x2 sub matrix of A is </span><span class="ch">\n</span><span class="st">"</span>,A[:<span class="op">-</span><span class="dv">1</span>,:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The bottom right 2x2 sub matrix of A is </span><span class="ch">\n</span><span class="st">"</span>,A[<span class="dv">1</span>:,<span class="dv">1</span>:])</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>])</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The first 3 entries of the vector u are </span><span class="ch">\n</span><span class="st">"</span>,u[:<span class="dv">3</span>])</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The last entry of the vector u is </span><span class="ch">\n</span><span class="st">"</span>,u[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The last two entries of the vector u are </span><span class="ch">\n</span><span class="st">"</span>,u[<span class="op">-</span><span class="dv">2</span>:])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.2" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.2</strong></span> Define the matrix <span class="math inline">\(A\)</span> and the vector <span class="math inline">\(u\)</span> in Python. Then perform all of the tasks below. <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 3 &amp; 5 &amp; 7 \\ 2 &amp; 4 &amp; 6 &amp; 8 \\ -3 &amp; -2 &amp; -1 &amp; 0 \end{pmatrix} \quad \text{and} \quad \boldsymbol{u} = \begin{pmatrix} 10\\20\\30 \end{pmatrix}
\end{equation}\]</span></p>
<ol type="1">
<li><p>Print the matrix <span class="math inline">\(A\)</span>, the vector <span class="math inline">\(\boldsymbol{u}\)</span>, the shape of <span class="math inline">\(A\)</span>, and the shape of <span class="math inline">\(\boldsymbol{u}\)</span>.</p></li>
<li><p>Print the first column of <span class="math inline">\(A\)</span>.</p></li>
<li><p>Print the first two rows of <span class="math inline">\(A\)</span>.</p></li>
<li><p>Print the first two entries of <span class="math inline">\(\boldsymbol{u}\)</span>.</p></li>
<li><p>Print the last two entries of <span class="math inline">\(\boldsymbol{u}\)</span>.</p></li>
<li><p>Print the bottom left <span class="math inline">\(2 \times 2\)</span> submatrix of <span class="math inline">\(A\)</span>.</p></li>
<li><p>Print the middle two elements of the middle row of <span class="math inline">\(A\)</span>.</p></li>
</ol>
</div>
</section>
<section id="matrix-and-vector-operations" class="level2" data-number="C.4">
<h2 data-number="C.4" class="anchored" data-anchor-id="matrix-and-vector-operations"><span class="header-section-number">C.4</span> Matrix and Vector Operations</h2>
<p>Now let us start doing some numerical linear algebra. We start our discussion with the basics: the dot product and matrix multiplication. The numerical routines in Python’s <code>numpy</code> packages are designed to do these tasks in very efficient ways but it is a good coding exercise to build your own dot product and matrix multiplication routines just to further cement the way that Python deals with these data structures and to remind you of the mathematical algorithms. What you will find in numerical linear algebra is that the indexing and the housekeeping in the codes is the hardest part. So why do not we start “easy.”</p>
<section id="the-dot-product" class="level3" data-number="C.4.1">
<h3 data-number="C.4.1" class="anchored" data-anchor-id="the-dot-product"><span class="header-section-number">C.4.1</span> The Dot Product</h3>
<div id="exr-4.3" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.3</strong></span> This problem is meant to jog your memory about dot products, how to compute them, and what you might use them for. If your linear algebra is a bit rusty then read ahead a bit and then come back to this problem.</p>
<p>Consider two vectors <span class="math inline">\(\boldsymbol{u}\)</span> and <span class="math inline">\(\boldsymbol{v}\)</span> defined as <span class="math display">\[\begin{equation}
\boldsymbol{u} = \begin{pmatrix} 1 \\ 2 \end{pmatrix} \quad \text{and} \quad \boldsymbol{v} = \begin{pmatrix} 3\\4 \end{pmatrix}.
\end{equation}\]</span></p>
<ol type="1">
<li><p>Draw a picture showing both <span class="math inline">\(\boldsymbol{u}\)</span> and <span class="math inline">\(\boldsymbol{v}\)</span>.</p></li>
<li><p>What is <span class="math inline">\(\boldsymbol{u} \cdot \boldsymbol{v}\)</span>?</p></li>
<li><p>What is <span class="math inline">\(\|\boldsymbol{u}\|\)</span>?</p></li>
<li><p>What is <span class="math inline">\(\|\boldsymbol{v}\|\)</span>?</p></li>
<li><p>What is the angle between <span class="math inline">\(\boldsymbol{u}\)</span> and <span class="math inline">\(\boldsymbol{v}\)</span>?</p></li>
<li><p>Give two reasons why we know that <span class="math inline">\(\boldsymbol{u}\)</span> is not perpendicular to <span class="math inline">\(\boldsymbol{v}\)</span>.</p></li>
<li><p>What is the scalar projection of <span class="math inline">\(\boldsymbol{u}\)</span> onto <span class="math inline">\(\boldsymbol{v}\)</span>? Draw this scalar projections on your picture from part (1).</p></li>
<li><p>What is the scalar projection of <span class="math inline">\(\boldsymbol{v}\)</span> onto <span class="math inline">\(\boldsymbol{u}\)</span>? Draw this scalar projections on your picture from part (1).</p></li>
</ol>
</div>
<hr>
<p>Now let us get the formal definitions of the dot product on the table.</p>
<div id="def-4.1" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.1 (Dot product)</strong></span> The <strong>dot product</strong> of two vectors <span class="math inline">\(\boldsymbol{u}, \boldsymbol{v} \in \mathbb{R}^n\)</span> is <span class="math display">\[\begin{equation}
\boldsymbol{u} \cdot \boldsymbol{v} = \sum_{j=1}^n u_j v_j.
\end{equation}\]</span> Without summation notation the dot product of two vectors is , <span class="math display">\[\begin{equation}
\boldsymbol{u} \cdot \boldsymbol{v} = u_1 v_1 + u_2 v_2 + \cdots + u_n v_n.
\end{equation}\]</span></p>
<p>You may also recall that the dot product of two vectors is given geometrically as <span class="math display">\[\begin{equation}
\boldsymbol{u} \cdot \boldsymbol{v} = \|\boldsymbol{u} \| \|\boldsymbol{v}\| \cos \theta
\end{equation}\]</span> where <span class="math inline">\(\|\boldsymbol{u}\|\)</span> and <span class="math inline">\(\|\boldsymbol{v}\|\)</span> are the magnitudes (or lengths) of <span class="math inline">\(\boldsymbol{u}\)</span> and <span class="math inline">\(\boldsymbol{v}\)</span> respectively, and <span class="math inline">\(\theta\)</span> is the angle between the two vectors. In physical applications the dot product is often used to find the angle between two vectors (e.g.&nbsp;between two forces). Hence, the last form of the dot product is often rewritten as <span class="math display">\[\begin{equation}
\theta = \cos^{-1}\left( \frac{\boldsymbol{u} \cdot \boldsymbol{v}}{ \|\boldsymbol{u} \| \| \boldsymbol{v} \|} \right).
\end{equation}\]</span></p>
</div>
<hr>
<div id="def-4.2" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.2 (Magnitude of a Vector)</strong></span> The <strong>magnitude</strong> of a vector <span class="math inline">\(\boldsymbol{u} \in \mathbb{R}^n\)</span> is defined as <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math display">\[\begin{equation}
\| \boldsymbol{u} \| = \sqrt{\boldsymbol{u} \cdot \boldsymbol{u}}.
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.5" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.4</strong></span> Write a Python function that accepts two vectors (defined as <code>numpy</code> arrays) and returns the dot product. Write this code without the use any loops.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> myDotProduct(u,v):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="co"># the dot product formula uses a product inside a sum.</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.6" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.5</strong></span> Test your <code>myDotProduct()</code> function on several dot products to make sure that it works. Example code to find the dot product between <span class="math display">\[\begin{equation}
\boldsymbol{u} = \begin{pmatrix} 1 \\ 2\\ 3\end{pmatrix} \quad \text{and} \quad \boldsymbol{v} = \begin{pmatrix} 4\\5\\6\end{pmatrix}
\end{equation}\]</span> is given below. Test your code on other vectors. Then implement an error catch into your code to catch the case where the two input vectors are not the same size. You will want to use the <code>len()</code> command to find the length of the vectors.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>])</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>])</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>myDotProduct(u,v)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.7" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.6</strong></span> Try sending Python lists instead of <code>numpy</code> arrays into your <code>myDotProduct</code> function. What happens? Why does it happen? What is the cautionary tale here? Modify your <code>myDotProduct()</code> function one more time so that it starts by converting the input vectors into <code>numpy</code> arrays.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> [<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>myDotProduct(u,v)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.8" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.7</strong></span> The <code>numpy</code> library in Python has a built-in command for doing the dot product: <code>np.dot()</code>. Test the <code>np.dot()</code> command and be sure that it does the same thing as your <code>myDotProduct()</code> function.</p>
</div>
<hr>
</section>
<section id="matrix-multiplication" class="level3" data-number="C.4.2">
<h3 data-number="C.4.2" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">C.4.2</span> Matrix Multiplication</h3>
<p>Next we will blow the dust off of your matrix multiplication skills.</p>
<div id="exr-4.9" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.8</strong></span> Verify that the product of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is indeed what we show below. Work out all of the details by hand. <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ 5 &amp; 6 \end{pmatrix} \qquad B = \begin{pmatrix} 7 &amp; 8 &amp; 9 \\ 10 &amp; 11 &amp; 12 \end{pmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
AB = \begin{pmatrix} 27 &amp; 30 &amp; 33 \\ 61 &amp; 68 &amp; 75 \\ 95 &amp; 106 &amp; 117 \end{pmatrix}
\end{equation}\]</span></p>
<hr>
<p>Now that you have practised the algorithm for matrix multiplication we can formalize the definition and then turn the algorithm into a Python function.</p>
</div>
<hr>
<div id="def-4.3" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.3 (Matrix Multiplication)</strong></span> If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are matrices with <span class="math inline">\(A \in \mathbb{R}^{n \times p}\)</span> and <span class="math inline">\(B \in \mathbb{R}^{p \times m}\)</span> then the product <span class="math inline">\(AB\)</span> is defined as <span class="math display">\[\begin{equation}
\left( AB \right)_{ij} = \sum_{k=1}^p A_{ik} B_{kj}.
\end{equation}\]</span></p>
<p>A moment’s reflection reveals that each entry in the matrix product is actually a dot product, <span class="math display">\[\begin{equation}
\left( \text{Entry in row $i$ column $j$ of $AB$} \right) = \left( \text{Row $i$ of matrix $A$} \right) \cdot \left( \text{Column $j$ of matrix $B$} \right).
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.10" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.9</strong></span> The definition of matrix multiplication above contains the cryptic phrase <em>a moment’s reflection reveals that each entry in the matrix product is actually a dot product.</em> Let us go back to the matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> defined in <a href="#exr-4.9" class="quarto-xref">Exercise&nbsp;<span>C.8</span></a> above and re-evaluate the matrix multiplication algorithm to make sure that you see each entry as the end result of a dot product.</p>
<p>We want to find the product of matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> using dot products. <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ 5 &amp; 6 \end{pmatrix} \qquad B = \begin{pmatrix} 7 &amp; 8 &amp; 9 \\ 10 &amp; 11 &amp; 12 \end{pmatrix}
\end{equation}\]</span></p>
<ol type="1">
<li><p>Why will the product <span class="math inline">\(AB\)</span> clear be a <span class="math inline">\(3 \times 3\)</span> matrix?</p></li>
<li><p>When we do matrix multiplication we take the product of a row from the first matrix times a column from the second matrix … at least that’s how many people think of it when they perform the operation by hand.</p>
<ol type="a">
<li>The rows of <span class="math inline">\(A\)</span> can be written as the vectors <span class="math display">\[\begin{equation}
\boldsymbol{a}_0 = \begin{pmatrix} 1 &amp; 2 \end{pmatrix}
\end{equation}\]</span></li>
</ol>
<p><span class="math display">\[\begin{equation}
\boldsymbol{a}_1 = \begin{pmatrix} \underline{\hspace{0.5in}} &amp; \underline{\hspace{0.5in}} \end{pmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{a}_2 = \begin{pmatrix} \underline{\hspace{0.5in}} &amp; \underline{\hspace{0.5in}} \end{pmatrix}
\end{equation}\]</span></p>
<ol start="2" type="a">
<li>The columns of <span class="math inline">\(B\)</span> can be written as the vectors <span class="math display">\[\begin{equation}
\boldsymbol{b}_0 = \begin{pmatrix} 7 \\ 10 \end{pmatrix}
\end{equation}\]</span></li>
</ol>
<p><span class="math display">\[\begin{equation}
\boldsymbol{b}_1 = \begin{pmatrix} \underline{\hspace{0.5in}} \\ \underline{\hspace{0.5in}} \end{pmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{b}_2 = \begin{pmatrix} \underline{\hspace{0.5in}} \\ \underline{\hspace{0.5in}} \end{pmatrix}
\end{equation}\]</span></p></li>
<li><p>Now let us write each entry in the product <span class="math inline">\(AB\)</span> as a dot product. <span class="math display">\[\begin{equation}
AB = \begin{pmatrix} \boldsymbol{a}_0 \cdot \boldsymbol{b}_0 &amp; \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \cdot \underline{\hspace{0.25in}} \end{pmatrix}
\end{equation}\]</span></p></li>
<li><p>Verify that you get <span class="math display">\[\begin{equation}
AB = \begin{pmatrix} 27 &amp; 30 &amp; 33 \\ 61 &amp; 68 &amp; 75 \\ 95 &amp; 106 &amp; 117 \end{pmatrix}
\end{equation}\]</span> when you perform all of the dot products from part (3).</p></li>
</ol>
</div>
<hr>
<div id="exr-4.11" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.10</strong></span> The observation that matrix multiplication is just a bunch of dot products is what makes the code for doing matrix multiplication very fast and very streamlined. We want to write a Python function that accepts two <code>numpy</code> matrices and returns the product of the two matrices. Inside the code we will leverage the <code>np.dot()</code> command to do the appropriate dot products.</p>
<p>Partial code is given below. Fill in all of the details and give ample comments showing what each line does.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> myMatrixMult(A,B):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the shapes of the matrices A and B.</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Then write an if statement that catches size mismatches </span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># in the matrices.  Next build a zeros matrix that is the </span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># correct size for the product of A and B. </span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    AB <span class="op">=</span> ??? </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># AB is a zeros matix that will be filled with the values </span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># from the product</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Next we do a double for-loop that loops through all of </span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the indices of the product</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n): <span class="co"># loop over the rows of AB</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(m): <span class="co"># loop over the columns of AB</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># use the np.dot() command to take the dot product</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>            AB[i,j] <span class="op">=</span> ???</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> AB</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Use the following test code to determine if you actually get the correct matrix product out of your code.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>``` python         </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">4</span>],[<span class="dv">5</span>,<span class="dv">6</span>]])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>],[<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>]])</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>AB <span class="op">=</span> myMatrixMult(A,B)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(AB)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.12" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.11</strong></span> Try your <code>myMatrixMult()</code> function on several other matrix multiplication problems.</p>
</div>
<hr>
<div id="exr-4.13" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.12</strong></span> Build in an error catch so that your <code>myMatrixMult()</code> function catches when the input matrices do not have compatible sizes for multiplication. Write your code so that it returns an appropriate error message in this special case.</p>
</div>
<hr>
<p>Now that you have been through the exercise of building a matrix multiplication function we will admit that using it inside larger coding problems would be a bit cumbersome (and perhaps annoying). It would be nice to just type <code>@</code> and have Python just <em>know</em> that you mean to do matrix multiplication. This is where <code>numpy</code> arrays come in quite handy.</p>
<hr>
<div id="exr-4.14" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.13 (Matrix Multiplication with Python)</strong></span> Python will handle matrix multiplication easily so long as the matrices are defined as <code>numpy</code> arrays. For example, with the matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> from above if you can just type <code>A @ B</code> (or <code>np.dot(A, B)</code>) in Python and you will get the correct result. Pretty nice!! Let us take another moment to notice, though, that regular Python lists do not behave in the same way. Can you guess what happens if you run the following Python code? (Note: <code>*</code> does strictly element-wise multiplication for numpy arrays, which we will see in a moment).</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> [[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">4</span>],[<span class="dv">5</span>,<span class="dv">6</span>]] <span class="co"># a Python list of lists</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> [[<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>],[<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>]] <span class="co"># a Python list of lists</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>A <span class="op">@</span> B</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exm-4.6" class="theorem example">
<p><span class="theorem-title"><strong>Example C.6 (Element-by-Element Multiplication)</strong></span> Sometimes it is convenient to do naive multiplication of matrices when you code. That is, if you have two matrices that are the same size, “naive multiplication” would just line up the matrices on top of each other and multiply the corresponding entries.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> In Python you can do this with the <code>*</code> operator (or <code>np.multiply()</code>). The code below demonstrates this tool with the matrices <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ 5 &amp; 6 \end{pmatrix} \quad \text{and} \quad B = \begin{pmatrix} 7 &amp; 8 \\ 9 &amp; 10 \\ 11 &amp; 12 \end{pmatrix}.
\end{equation}\]</span></p>
<p>(Note that the product <span class="math inline">\(AB\)</span> does not make sense under the mathematical definition of matrix multiplication, but it does make sense in terms of element-by-element (“naive”) multiplication.)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">4</span>],[<span class="dv">5</span>,<span class="dv">6</span>]])</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="dv">7</span>,<span class="dv">8</span>],[<span class="dv">9</span>,<span class="dv">10</span>],[<span class="dv">11</span>,<span class="dv">12</span>]])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A <span class="op">*</span> B)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<p>The key takeaways for doing matrix multiplication in Python are as follows:</p>
<ul>
<li><p>If you are doing linear algebra in Python then you should define vectors and matrices with <code>np.array()</code>.</p></li>
<li><p>If your matrices are defined with <code>np.array()</code> then <code>@</code> (or <code>np.dot()</code>) does regular matrix multiplication and <code>*</code> does element-by-element multiplication.</p></li>
</ul>
<hr>
</section>
</section>
<section id="the-lu-factorization" class="level2" data-number="C.5">
<h2 data-number="C.5" class="anchored" data-anchor-id="the-lu-factorization"><span class="header-section-number">C.5</span> The LU Factorization</h2>
<p>One of the many classic problems of linear algebra is to solve the linear system <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> where <span class="math inline">\(A\)</span> is a matrix of coefficients and <span class="math inline">\(\boldsymbol{b}\)</span> is a vector of right-hand sides. You likely recall your go-to technique for solving systems was row reduction (or Gaussian Elimination). Furthermore, you likely rarely actually did row reduction by hand, and instead you relied on a computer to do most of the computations for you. Just what was the computer doing, exactly? Do you think that it was actually following the same algorithm that you did by hand?</p>
<section id="a-recap-of-row-reduction" class="level3" data-number="C.5.1">
<h3 data-number="C.5.1" class="anchored" data-anchor-id="a-recap-of-row-reduction"><span class="header-section-number">C.5.1</span> A Recap of Row Reduction</h3>
<p>Let us blow the dust off your row reduction skills before we look at something better.</p>
<hr>
<div id="exr-4.15" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.14</strong></span> Solve the following system of equations by hand. <span class="math display">\[\begin{equation}
\begin{array}{rl} x_0 + 2x_1 + 3x_2 &amp;= 1 \\ 4x_0 + 5x_1 + 6x_2 &amp;= 0 \\ 7x_0 + 8x_1 &amp;= 2 \end{array}
\end{equation}\]</span> Note that the system of equations can also be written in the matrix form <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 0 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 2\end{pmatrix}
\end{equation}\]</span></p>
<p>If you need a nudge to get started then jump ahead to the next problem.</p>
</div>
<hr>
<div id="exr-4.16" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.15</strong></span> We want to solve the system of equations <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 0 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 2\end{pmatrix}
\end{equation}\]</span></p>
<p><strong>Row Reduction Process:</strong></p>
<p><strong>Note:</strong> Throughout this discussion we use Python-type indexing so the rows and columns are enumerated starting at 0. That is to say, we will talk about row 0, row 1, and row 2 of a matrix instead of rows 1, 2, and 3.</p>
<ol type="1">
<li><p>Augment the coefficient matrix and the vector on the right-hand side to get <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 2 &amp; 3 &amp; 1 \\ 4 &amp; 5 &amp; 6 &amp; 0 \\ 7 &amp; 8 &amp; 0 &amp; 2 \end{array} \right)
\end{equation}\]</span></p></li>
<li><p>The goal of row reduction is to perform elementary row operations until our augmented matrix gets to (or at least gets as close as possible to) <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 0 &amp; 0 &amp; \star \\ 0 &amp; 1 &amp; 0 &amp; \star \\ 0 &amp; 0 &amp; 1 &amp; \star \end{array} \right)
\end{equation}\]</span> The allowed elementary row operations are:</p>
<ol type="a">
<li><p>We are allowed to scale any row.</p></li>
<li><p>We can add two rows.</p></li>
<li><p>We can interchange two rows.</p></li>
</ol></li>
<li><p>We are going to start with column 0. We already have the “<span class="math inline">\(1\)</span>” in the top left corner so we can use it to eliminate all of the other values in the first column of the matrix.</p>
<ol type="a">
<li><p>For example, if we multiply the <span class="math inline">\(0^{th}\)</span> row by <span class="math inline">\(-4\)</span> and add it to the first row we get <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 2 &amp; 3 &amp; 1 \\ 0 &amp; -3 &amp; -6 &amp; -4 \\ 7 &amp; 8 &amp; 0 &amp; 2 \end{array} \right).
\end{equation}\]</span></p></li>
<li><p>Multiply row 0 by a scalar and add it to row 2. Your end result should be <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 2 &amp; 3 &amp; 1 \\ 0 &amp; -3 &amp; -6 &amp; -4 \\ 0 &amp; -6 &amp; -21 &amp; -5 \end{array} \right).
\end{equation}\]</span> What did you multiply by? Why?</p></li>
</ol></li>
<li><p>Now we should deal with column 1.</p>
<ol type="a">
<li><p>We want to get a 1 in row 1 column 1. We can do this by scaling row 1. What did you scale by? Why? Your end result should be <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 2 &amp; 3 &amp; 1 \\ 0 &amp; 1 &amp; 2 &amp; \frac{4}{3} \\ 0 &amp; -6 &amp; -21 &amp; -5 \end{array} \right).
\end{equation}\]</span></p></li>
<li><p>Now scale row 1 by something and add it to row 0 so that the entry in row 0 column 1 becomes a 0.</p></li>
<li><p>Next scale row 1 by something and add it to row 2 so that the entry in row 2 column 1 becomes a 0.</p></li>
<li><p>At this point you should have the augmented system <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 0 &amp; -1 &amp; -\frac{5}{3} \\ 0 &amp; 1 &amp; 2 &amp; \frac{4}{3} \\ 0 &amp; 0 &amp; -9 &amp; 3 \end{array} \right).
\end{equation}\]</span></p></li>
</ol></li>
<li><p>Finally we need to work with column 2.</p>
<ol type="a">
<li><p>Make the value in row 2 column 2 a 1 by scaling row 2. What did you scale by? Why?</p></li>
<li><p>Scale row 2 by something and add it to row 1 so that the entry in row 1 column 2 becomes a 0. What did you scale by? Why?</p></li>
<li><p>Scale row 2 by something and add it to row 0 so that the entry in row 0 column 2 becomes a 0. What did you scale by? Why?</p></li>
<li><p>By the time you have made it this far you should have the system <span class="math display">\[\begin{equation}
\left( \begin{array}{ccc|c} 1 &amp; 0 &amp; 0 &amp; -2 \\ 0 &amp; 1 &amp; 0 &amp; 2 \\ 0 &amp; 0 &amp; 1 &amp; -\frac{1}{3} \end{array} \right)
\end{equation}\]</span> and you should be able to read off the solution to the system.</p></li>
</ol></li>
<li><p>You should verify your answer in two different ways:</p>
<ol type="a">
<li><p>If you substitute your values into the original system then all of the equal signs should be true. Verify this.</p></li>
<li><p>If you substitute your values into the matrix equation and perform the matrix-vector multiplication on the left-hand side of the equation you should get the right-hand side of the equation. Verify this.</p></li>
</ol></li>
</ol>
</div>
<hr>
<div id="exr-4.17" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.16</strong></span> Summarize the process for doing Gaussian Elimination to solve a square system of linear equations.</p>
</div>
<hr>
</section>
<section id="the-lu-decomposition" class="level3" data-number="C.5.2">
<h3 data-number="C.5.2" class="anchored" data-anchor-id="the-lu-decomposition"><span class="header-section-number">C.5.2</span> The LU Decomposition</h3>
<p>You may have used the <code>rref()</code> command either on a calculator in other software to perform row reduction in the past. You will be surprised to learn that there is no <code>rref()</code> command in Python’s <code>numpy</code> library! That’s because there are far more efficient and stable ways to solve a linear system on a computer. There is an <code>rref</code> command in Python’s <code>sympy</code> (symbolic Python) library, but given that it works with symbolic algebra it is quite slow.</p>
<p>In solving systems of equations we are interested in equations of the form <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span>. Notice that the <span class="math inline">\(\boldsymbol{b}\)</span> vector is just along for the ride, so to speak, in the row reduction process since none of the values in <span class="math inline">\(\boldsymbol{b}\)</span> actually cause you to make different decisions in the row reduction algorithm. Hence, we only really need to focus on the matrix <span class="math inline">\(A\)</span>. Furthermore, let us change our awfully restrictive view of always seeking a matrix of the form <span class="math display">\[\begin{equation}
\left( \begin{array}{cccc|c} 1 &amp; 0 &amp; \cdots &amp; 0 &amp; \star \\ 0 &amp; 1 &amp; \cdots &amp; 0 &amp; \star \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 1 &amp; \star \end{array} \right)
\end{equation}\]</span> and instead say:</p>
<blockquote class="blockquote">
<p><em>What if we just row reduce until the system is simple enough to solve by hand?</em></p>
</blockquote>
<p>That’s what the next several exercises are going to lead you to. Our goal here is to develop an algorithm that is fast to implement on a computer and simultaneously performs the same basic operations as row reduction for solving systems of linear equations.</p>
<hr>
<div id="exr-4.18" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.17</strong></span> Let <span class="math inline">\(A\)</span> be defined as <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 0 \end{pmatrix}.
\end{equation}\]</span></p>
<ol type="1">
<li><p>The first step in row reducing <span class="math inline">\(A\)</span> would be to multiply row 0 by <span class="math inline">\(-4\)</span> and add it to row 1. Do this operation by hand so that you know what the result is supposed to be. Check out the following amazing observation. Define the matrix <span class="math inline">\(L_1\)</span> as follows: <span class="math display">\[\begin{equation}
L_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ -4 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix}.
\end{equation}\]</span> Now multiply <span class="math inline">\(L_1\)</span> and <span class="math inline">\(A\)</span>. <span class="math display">\[\begin{equation}
L_1 A = \begin{pmatrix} \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \end{pmatrix}
\end{equation}\]</span> What just happened?!</p></li>
<li><p>Let us do it again. The next step in the row reduction of your result from part (1) would be to multiply row 0 by <span class="math inline">\(-7\)</span> and add to row 2. Again, do this by hand so you know what the result should be. Then define the matrix <span class="math inline">\(L_2\)</span> as <span class="math display">\[\begin{equation}
L_2 = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ -7 &amp; 0 &amp; 1 \end{pmatrix}
\end{equation}\]</span> and find the product <span class="math inline">\(L_2 \left( L_1 A \right)\)</span>. <span class="math display">\[\begin{equation}
L_2 \left( L_1 A \right) = \begin{pmatrix} \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \end{pmatrix}
\end{equation}\]</span> Pure insanity!!</p></li>
<li><p>Now let us say that you want to make the entry in row 2 column 1 into a 0 by scaling row 1 by something and then adding to row 2. Determine what the scalar would be and then determine which matrix, call it <span class="math inline">\(L_3\)</span>, would do the trick so that <span class="math inline">\(L_3 (L_2 L_1 A)\)</span> would be the next row reduced step. <span class="math display">\[\begin{equation}
L_3 = \begin{pmatrix} 1 &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; 1 &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; 1 \end{pmatrix}
\end{equation}\]</span></p></li>
</ol>
<p><span class="math display">\[\begin{equation}
L_3 \left( L_2 L_1 A \right) = \begin{pmatrix} \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \end{pmatrix}
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.19" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.18</strong></span> Apply the same idea from the previous problem to do the first three steps of row reduction to the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 2 &amp; 6 &amp; 9 \\ -6 &amp; 8 &amp; 1 \\ 2 &amp; 2 &amp; 10 \end{pmatrix}
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.20" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.19</strong></span> Now let us make a few observations about the two previous problems.</p>
<ol type="1">
<li><p>What will multiplying <span class="math inline">\(A\)</span> by a matrix of the form <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 0 &amp; 0 \\ c &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix}
\end{equation}\]</span> do?</p></li>
<li><p>What will multiplying <span class="math inline">\(A\)</span> by a matrix of the form <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ c &amp; 0 &amp; 1 \end{pmatrix}
\end{equation}\]</span> do?</p></li>
<li><p>What will multiplying <span class="math inline">\(A\)</span> by a matrix of the form <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; c &amp; 1 \end{pmatrix}
\end{equation}\]</span> do?</p></li>
<li><p>More generally: If you wanted to multiply row <span class="math inline">\(j\)</span> of an <span class="math inline">\(n\times n\)</span> matrix by <span class="math inline">\(c\)</span> and add it to row <span class="math inline">\(k\)</span>, that is the same as multiplying by what matrix?</p></li>
</ol>
</div>
<hr>
<div id="exr-4.21" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.20</strong></span> After doing all of the matrix products, <span class="math inline">\(L_3 L_2 L_1 A\)</span>, the resulting matrix will have zeros in the entire lower triangle. That is, all of the non-zero entries of the resulting matrix will be on the main diagonal or above. We call this matrix <span class="math inline">\(U\)</span>, for upper-triangular. Hence, we have formed a matrix <span class="math display">\[\begin{equation}
L_3 L_2 L_1 A = U
\end{equation}\]</span> and if we want to solve for <span class="math inline">\(A\)</span> we would get <span class="math display">\[\begin{equation}
A = (\underline{\hspace{0.5in}})^{-1} (\underline{\hspace{0.5in}})^{-1} (\underline{\hspace{0.5in}})^{-1} U
\end{equation}\]</span> (Take care that everything is in the right order in your answer.)</p>
</div>
<hr>
<div id="exr-4.22" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.21</strong></span> It would be nice, now, if the inverses of the <span class="math inline">\(L\)</span> matrices were easy to find. Use <code>np.linalg.inv()</code> to directly compute the inverse of <span class="math inline">\(L_1\)</span>, <span class="math inline">\(L_2\)</span>, and <span class="math inline">\(L_3\)</span> for each of the example matrices. Then complete the statement: If <span class="math inline">\(L_k\)</span> is an identity matrix with some non-zero <span class="math inline">\(c\)</span> in row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span> then <span class="math inline">\(L_k^{-1}\)</span> is what matrix?</p>
</div>
<hr>
<div id="exr-4.23" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.22</strong></span> We started this discussion with <span class="math inline">\(A\)</span> as <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 0 \end{pmatrix}
\end{equation}\]</span> and we defined <span class="math display">\[\begin{equation}
L_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ -4 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix}, \quad L_2 = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ -7 &amp; 0 &amp; 1 \end{pmatrix}, \quad \text{and} \quad L_3 = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; -2 &amp; 1 \end{pmatrix}.
\end{equation}\]</span> Based on your answer to the previous exercises we know that <span class="math display">\[\begin{equation}
A = L_1^{-1} L_2^{-1} L_3^{-1} U.
\end{equation}\]</span> Explicitly write down the matrices <span class="math inline">\(L_1^{-1}\)</span>, <span class="math inline">\(L_2^{-1}\)</span>, and <span class="math inline">\(L_3^{-1}\)</span>.</p>
<p>Now explicitly find the product <span class="math inline">\(L_1^{-1} L_2^{-1} L_3^{-1}\)</span> and call this product <span class="math inline">\(L\)</span>. Verify that <span class="math inline">\(L\)</span> itself is also a lower-triangular matrix with ones on the main diagonal. Moreover, take note of exactly the form of the matrix. The answer should be super surprising to you!!</p>
</div>
<hr>
<p>Throughout all of the preceding exercises, our final result is that we have factored the matrix <span class="math inline">\(A\)</span> into the product of a lower-triangular matrix and an upper-triangular matrix. Stop and think about that for a minute … we just factored a matrix!</p>
<p>Let us return now to our discussion of solving the system of equations <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span>. If <span class="math inline">\(A\)</span> can be factored into <span class="math inline">\(A = LU\)</span> then the system of equations can be rewritten as <span class="math inline">\(LU \boldsymbol{x} = \boldsymbol{b}\)</span>. As we will see in the next subsection, solving systems of equations with triangular matrices is super fast and relatively simple! Hence, we have partially achieved our modified goal of reducing the row reduction into some simpler case.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>It remains to implement the <span class="math inline">\(LU\)</span> decomposition (also called the <span class="math inline">\(LU\)</span> factorization) in Python.</p>
<hr>
<div id="exm-4.LU" class="theorem example">
<p><span class="theorem-title"><strong>Example C.7 (The LU Factorization)</strong></span> The following Python function takes a square matrix <span class="math inline">\(A\)</span> and outputs the matrices <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> such that <span class="math inline">\(A = LU\)</span>. The entire code is given to you. It will be up to you in the next exercise to pick apart every step of the function.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> myLU(A):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> A.shape[<span class="dv">0</span>] <span class="co"># get the dimension of the matrix A</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> np.eye(n) <span class="co"># Build the identity part of L</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> np.copy(A) <span class="co"># start the U matrix as a copy of A</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,n<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(j<span class="op">+</span><span class="dv">1</span>,n):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>            mult <span class="op">=</span> U[i,j] <span class="op">/</span> U[j,j]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>            U[i, :] <span class="op">=</span> U[i, :] <span class="op">-</span> mult <span class="op">*</span> U[j,:]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>            L[i,j] <span class="op">=</span> mult</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L,U</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.24" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.23</strong></span> Go to <a href="#exm-4.LU" class="quarto-xref">Example&nbsp;<span>C.7</span></a> and go through every iteration of every loop <strong>by hand</strong> starting with the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 0 \end{pmatrix}.
\end{equation}\]</span> Give details of what happens at every step of the algorithm. I will get you started.</p>
<ul>
<li><p><code>n=3</code>, <code>L</code> starts as an identity matrix of the correct size, and <code>U</code> starts as a copy of <code>A</code>.</p></li>
<li><p>Start the outer loop: <code>j=0</code>: (<code>j</code> is the counter for the column)</p>
<ul>
<li><p>Start the inner loop: <code>i=1</code>: (<code>i</code> is the counter for the row)</p>
<ul>
<li><p><code>mult = A[1,0] / A[0,0]</code> so <code>mult</code><span class="math inline">\(=4/1\)</span>.</p></li>
<li><p><code>A[1, 1:3] = A[1, 1:3] - 4 * A[0,1:3]</code>. Translated, this states that columns 1 and 2 of matrix <span class="math inline">\(A\)</span> took their original value minus 4 times the corresponding values in row 0.</p></li>
<li><p><code>U[1, 1:3] = A[1, 1:3]</code>. Now we replace the locations in <span class="math inline">\(U\)</span> with the updated information from our first step of row reduction.</p></li>
<li><p><code>L[1,0]=4</code>. We now fill the <span class="math inline">\(L\)</span> matrix with the proper value.</p></li>
<li><p><code>U[1,0]=0</code>. Finally, we zero out the lower triangle piece of the <span class="math inline">\(U\)</span> matrix which we have now taken care of.</p></li>
</ul></li>
<li><p><code>i=2</code>:</p>
<ul>
<li>… keep going from here …</li>
</ul></li>
</ul></li>
</ul>
</div>
<hr>
<div id="exr-4.25" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.24</strong></span> Apply your new <code>myLU</code> code to other square matrices and verify that indeed <span class="math inline">\(A\)</span> is the product of the resulting <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> matrices. You can produce a random matrix with <code>np.random.randn(n,n)</code> where <code>n</code> is the number of rows and columns of the matrix. For example, <code>np.random.randn(10,10)</code> will produce a random <span class="math inline">\(10 \times 10\)</span> matrix with entries chosen from the normal distribution with centre 0 and standard deviation 1. Random matrices are just as good as any other when testing your algorithm.</p>
</div>
<hr>
</section>
<section id="solving-triangular-systems" class="level3" data-number="C.5.3">
<h3 data-number="C.5.3" class="anchored" data-anchor-id="solving-triangular-systems"><span class="header-section-number">C.5.3</span> Solving Triangular Systems</h3>
<p>We now know that row reduction is just a collection of sneaky matrix multiplications. In the previous exercises we saw that we can often turn our system of equations <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> into the system <span class="math inline">\(LU \boldsymbol{x} = \boldsymbol{b}\)</span> where <span class="math inline">\(L\)</span> is lower-triangular (with ones on the main diagonal) and <span class="math inline">\(U\)</span> is upper-triangular. But why was this important?</p>
<p>Well, if <span class="math inline">\(LU \boldsymbol{x} = \boldsymbol{b}\)</span> then we can rewrite our system of equations as two systems: <span class="math display">\[\begin{equation}
\text{An upper-triangular system: } U \boldsymbol{x} = \boldsymbol{y}
\end{equation}\]</span> and <span class="math display">\[\begin{equation}
\text{A lower-triangular system: } L \boldsymbol{y} = \boldsymbol{b}.
\end{equation}\]</span></p>
<p>In the following exercises we will devise algorithms for solving triangular systems. After we know how to work with triangular systems we will put all of the pieces together and show how to leverage the <span class="math inline">\(LU\)</span> decomposition and the solution techniques for triangular systems to quickly and efficiently solve linear systems.</p>
<hr>
<div id="exr-4.26" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.25</strong></span> Outline a fast algorithm (without formal row reduction) for solving the lower-triangular system <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 4 &amp; 1 &amp; 0 \\ 7 &amp; 2 &amp; 1 \end{pmatrix} \begin{pmatrix} y_0 \\ y_1 \\ y_2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 2\end{pmatrix}.
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.27" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.26</strong></span> As a convention we will always write our lower-triangular matrices with ones on the main diagonal. Generalize your steps from the previous exercise so that you have an algorithm for solving any lower-triangular system. The most natural algorithm that most people devise here is called <strong>forward substitution</strong>.</p>
</div>
<hr>
<div id="def-4.5" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.4 (Forward Substutition Algorithm (<code>lsolve</code>))</strong></span> The general statement of the Forward Substitution Algorithm is:</p>
<p><em>Solve</em> <span class="math inline">\(L \boldsymbol{y} = \boldsymbol{b}\)</span> for <span class="math inline">\(\boldsymbol{y}\)</span>, where the matrix <span class="math inline">\(L\)</span> is assumed to be lower-triangular with ones on the main diagonal.</p>
<p>The code below gives a full implementation of the <strong>Forward Substitution</strong> algorithm (also called the <code>lsolve</code> algorithm).</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lsolve(L, b):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># L is assumed to be a lower-triangular np.array</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> b.size <span class="co"># what does this do?</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.zeros(n) <span class="co"># what does this do?</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># start the loop by assigning y to the value on the right</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        y[i] <span class="op">=</span> b[i] </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i): <span class="co"># now adjust y </span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>            y[i] <span class="op">=</span> y[i] <span class="op">-</span> L[i,j] <span class="op">*</span> y[j]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(y)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.28" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.27</strong></span> Work with your partner(s) to apply the <code>lsolve()</code> code to the lower-triangular system<br>
</p>
<p><span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 4 &amp; 1 &amp; 0 \\ 7 &amp; 2 &amp; 1 \end{pmatrix} \begin{pmatrix} y_0 \\ y_1 \\ y_2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 2\end{pmatrix}
\end{equation}\]</span> <strong>by hand</strong>. It is incredibly important to implement numerical linear algebra routines by hand a few times so that you truly understand how everything is being tracked and calculated.</p>
<p>I will get you started.</p>
<ul>
<li><p>Start: <code>i=0</code>:</p>
<ul>
<li><p><code>y[0]=1</code> since <code>b[0]=1</code>.</p></li>
<li><p>The next <code>for</code> loop does not start since <code>range(0)</code> has no elements (stop and think about why this is).</p></li>
</ul></li>
<li><p>Next step in the loop: <code>i=1</code>:</p>
<ul>
<li><p><code>y[1]</code> is initialized as 0 since <code>b[1]=0</code>.</p></li>
<li><p>Now we enter the inner loop at <code>j=0</code>:</p>
<ul>
<li>What does <code>y[1]</code> become when <code>j=0</code>?</li>
</ul></li>
<li><p>Does <code>j</code> increment to anything larger?</p></li>
</ul></li>
<li><p>Finally we increment <code>i</code> to <code>i=2</code>:</p>
<ul>
<li><p>What does <code>y[2]</code> get initialized to?</p></li>
<li><p>Enter the inner loop at <code>j=0</code>:</p>
<ul>
<li>What does <code>y[2]</code> become when <code>j=0</code>?</li>
</ul></li>
<li><p>Increment the inner loop to <code>j=1</code>:</p>
<ul>
<li>What does <code>y[2]</code> become when <code>j=1</code>?</li>
</ul></li>
</ul></li>
<li><p>Stop</p></li>
</ul>
</div>
<hr>
<div id="exr-4.29" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.28</strong></span> Copy the code from <a href="#def-4.5" class="quarto-xref">Definition&nbsp;<span>C.4</span></a> into a Python function but in your code write a comment on every line stating what it is doing. Write a test script that creates a lower-triangular matrix of the correct form and a right-hand side <span class="math inline">\(\boldsymbol{b}\)</span> and solve for <span class="math inline">\(\boldsymbol{y}\)</span>. Test your code by giving it a large lower-triangular system.</p>
</div>
<hr>
<p>Now that we have a method for solving lower-triangular systems, let us build a similar method for solving upper-triangular systems. The merging of lower and upper-triangular systems will play an important role in solving systems of equations.</p>
<hr>
<div id="exr-4.30" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.29</strong></span> Outline a fast algorithm (without formal row reduction) for solving the upper-triangular system <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 0 &amp; -3 &amp; -6 \\ 0 &amp; 0 &amp; -9 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 1 \\ -4 \\ 3\end{pmatrix}
\end{equation}\]</span> The most natural algorithm that most people devise here is called <strong>backward substitution</strong>. Notice that in our upper-triangular matrix we do not have a diagonal containing all ones.</p>
</div>
<hr>
<div id="exr-4.31" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.30</strong></span> Generalize your backward substitution algorithm from the previous problem so that it could be applied to any upper-triangular system.</p>
</div>
<hr>
<div id="def-4.6" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.5 (Backward Substitution Algorithm)</strong></span> The following code solves the problem <span class="math inline">\(U \boldsymbol{x} = \boldsymbol{y}\)</span> using backward substitution. The matrix <span class="math inline">\(U\)</span> is assumed to be upper-triangular. You will notice that most of this code is incomplete. It is your job to complete this code, and the next exercise should help.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> usolve(U, y):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># U is assumed to be an upper-triangular np.array</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> y.size</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.zeros(n)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( ??? ):     <span class="co"># what should we be looping over?</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        x[i] <span class="op">=</span> y[i] <span class="op">/</span> ???      <span class="co"># what should we be dividing by?</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>( ??? ): <span class="co"># what should we be looping over:</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>            x[i] <span class="op">=</span> x[i] <span class="op">-</span> U[i,j] <span class="op">*</span> x[j] <span class="op">/</span> ??? <span class="co"># complete this line </span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ... what does the previous line do?</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.32" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.31</strong></span> Now we will work through the backward substitution algorithm to help fill in the blanks in the code. Consider the upper-triangular system <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 0 &amp; -3 &amp; -6 \\ 0 &amp; 0 &amp; -9 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 1 \\ -4 \\ 3\end{pmatrix}
\end{equation}\]</span></p>
<p>Work the code from <a href="#def-4.6" class="quarto-xref">Definition&nbsp;<span>C.5</span></a> to solve the system. Keep track of all of the indices as you work through the code. You may want to work this problem in conjunction with the previous two problems to unpack all of the parts of the <em>backward substitution</em> algorithm.</p>
<p>I will get you started.</p>
<ul>
<li><p>In your backward substitution algorithm you should have started with the last row, therefore the outer loop starts at <code>n-1</code> and reads backward to 0. (Why are we starting at <code>n-1</code> and not <code>n</code>?)</p></li>
<li><p>Outer loop: <code>i=2</code>:</p>
<ul>
<li><p>We want to solve the equation <span class="math inline">\(-9x_2 = 3\)</span> so the clear solution is to divide by <span class="math inline">\(-9\)</span>. In code this means that <code>x[2]=y[2]/U[2,2]</code>.</p></li>
<li><p>There is nothing else to do for row 3 of the matrix, so we should not enter the inner loop. How can we keep from entering the inner loop?</p></li>
</ul></li>
<li><p>Outer loop: <code>i=1</code>:</p>
<ul>
<li><p>Now we are solving the algebraic equation <span class="math inline">\(-3x_1 - 6x_2 = -4\)</span>. If we follow the high school algebra we see that <span class="math inline">\(x_1 = \frac{-4 - (-6)x_2}{-3}\)</span> but this can be rearranged to <span class="math display">\[\begin{equation}
x_1 = \frac{-4}{-3} - \frac{-6x_2}{-3}.
\end{equation}\]</span> So we can initialize <span class="math inline">\(x_1\)</span> with <span class="math inline">\(x_1 = \frac{-4}{-3}\)</span>. In code, this means that we initialize with <code>x[1] = y[1] / U[1,1]</code>.</p></li>
<li><p>Now we need to enter the inner loop at <code>j=2</code>: (why are we entering the loop at <code>j=2</code>?)</p>
<ul>
<li>To complete the algebra we need to take our initialized value of <code>x[1]</code> and subtract off <span class="math inline">\(\frac{-6x_2}{-3}\)</span>. In code this is <code>x[1] = x[1] - U[1,2] * x[2] / U[1,1]</code></li>
</ul></li>
<li><p>There is nothing else to do so the inner loop should end.</p></li>
</ul></li>
<li><p>Outer loop: <code>i=0</code>:</p>
<ul>
<li><p>Finally, we are solving the algebraic equation <span class="math inline">\(x_0 + 2x_1 + 3 x_2 = 1\)</span> for <span class="math inline">\(x_0\)</span>. The clear and obvious solution is <span class="math inline">\(x_0 = \frac{1 - 2x_1 - 3x_2}{1}\)</span> (why am I explicitly showing the division by <span class="math inline">\(1\)</span> here?).</p></li>
<li><p>Initialize <span class="math inline">\(x_0\)</span> at <code>x[0] = ???</code></p></li>
<li><p>Enter the inner loop at <code>j=2</code>:</p>
<ul>
<li>Adjust the value of <code>x[0]</code> by subtracting off <span class="math inline">\(\frac{3x_2}{1}\)</span>. In code we have <code>x[0] = x[0] - ??? * ??? / ???</code></li>
</ul></li>
<li><p>Increment <code>j</code> to <code>j=1</code>:</p>
<ul>
<li>Adjust the value of <code>x[0]</code> by subtracting off <span class="math inline">\(\frac{2x_1}{1}\)</span>. In code we have <code>x[0] = x[0] - ??? * ??? / ???</code></li>
</ul></li>
</ul></li>
<li><p>Stop.</p></li>
<li><p>You should now have a solution to the equation <span class="math inline">\(U \boldsymbol{x} = \boldsymbol{y}\)</span>. Substitute your solution in and verify that your solution is correct.</p></li>
</ul>
</div>
<hr>
<div id="exr-4.33" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.32</strong></span> Copy the code from <a href="#def-4.6" class="quarto-xref">Definition&nbsp;<span>C.5</span></a> into a Python function but in your code write a comment on every line stating what it is doing. Write a test script that creates an upper-triangular matrix of the correct form and a right-hand side <span class="math inline">\(\boldsymbol{y}\)</span> and solve for <span class="math inline">\(\boldsymbol{x}\)</span>. Your code needs to work on systems of arbitrarily large size.</p>
</div>
<hr>
</section>
<section id="solving-systems-with-lu-decomposition" class="level3" data-number="C.5.4">
<h3 data-number="C.5.4" class="anchored" data-anchor-id="solving-systems-with-lu-decomposition"><span class="header-section-number">C.5.4</span> Solving Systems with LU Decomposition</h3>
<p>We are finally ready for the punch line of this whole <span class="math inline">\(LU\)</span> and triangular systems business!</p>
<hr>
<div id="exr-4.34" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.33</strong></span> If we want to solve <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> then</p>
<ol type="1">
<li><p>If we can, write the system of equations as <span class="math inline">\(LU \boldsymbol{x} = \boldsymbol{b}\)</span>.</p></li>
<li><p>Solve <span class="math inline">\(L \boldsymbol{y} = \boldsymbol{b}\)</span> for <span class="math inline">\(\boldsymbol{y}\)</span> using forward substitution.</p></li>
<li><p>Solve <span class="math inline">\(U \boldsymbol{x} = \boldsymbol{y}\)</span> for <span class="math inline">\(\boldsymbol{x}\)</span> using backward substitution.</p></li>
</ol>
<p>Pick a matrix <span class="math inline">\(A\)</span> and a right-hand side <span class="math inline">\(\boldsymbol{b}\)</span> and solve the system using this process.</p>
</div>
<hr>
<div id="exr-4.35" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.34</strong></span> Try the process again on the <span class="math inline">\(3\times 3\)</span> system of equations <span class="math display">\[\begin{equation}
\begin{pmatrix} 3 &amp; 6 &amp; 8\\ 2 &amp; 7 &amp; -1 \\ 5 &amp; 2 &amp; 2 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} -13 \\ 4 \\ 1 \end{pmatrix}
\end{equation}\]</span> That is: Find matrices <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> such that <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> can be written as <span class="math inline">\(LU\boldsymbol{x} = \boldsymbol{b}\)</span>. Then do two triangular solves to determine <span class="math inline">\(\boldsymbol{x}\)</span>.</p>
</div>
<hr>
<p>Let us take stock of what we have done so far.</p>
<ul>
<li><p>Solving lower-triangular systems is super fast and easy!</p></li>
<li><p>Solving upper-triangular systems is super fast and easy (so long as we never divide by zero).</p></li>
<li><p>It is often possible to rewrite the matrix <span class="math inline">\(A\)</span> as the product of a lower-triangular matrix <span class="math inline">\(L\)</span> and an upper-triangular matrix <span class="math inline">\(U\)</span> so <span class="math inline">\(A=LU\)</span>.</p></li>
<li><p>Now we can re-frame the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> as <span class="math inline">\(LU \boldsymbol{x} = \boldsymbol{b}\)</span>.</p></li>
<li><p>Substitute <span class="math inline">\(\boldsymbol{y} = U \boldsymbol{x}\)</span> so the system becomes <span class="math inline">\(L \boldsymbol{y} = \boldsymbol{b}\)</span>. Solve for <span class="math inline">\(\boldsymbol{y}\)</span> with forward substitution.</p></li>
<li><p>Now solve <span class="math inline">\(U \boldsymbol{x} = \boldsymbol{y}\)</span> using backward substitution.</p></li>
</ul>
<p>We have successfully take row reduction and turned into some fast matrix multiplications and then two very quick triangular solves. Ultimately this will be a faster algorithm for solving a system of linear equations.</p>
<hr>
<div id="def-4.7" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.6 (Solving Linear Systems with the LU Decomposition)</strong></span> Let <span class="math inline">\(A\)</span> be a square matrix in <span class="math inline">\(\mathbb{R}^{n \times n}\)</span> and let <span class="math inline">\(\boldsymbol{x}, \boldsymbol{b} \in \mathbb{R}^n\)</span>. To solve the problem <span class="math inline">\(A \boldsymbol{x} =\boldsymbol{b}\)</span>,</p>
<ol type="1">
<li><p>Factor <span class="math inline">\(A\)</span> into lower and upper-triangular matrices <span class="math inline">\(A = LU\)</span>.<br>
<code>L, U = myLU(A)</code></p></li>
<li><p>The system can now be written as <span class="math inline">\(LU \boldsymbol{x} = \boldsymbol{b}\)</span>. Substitute <span class="math inline">\(U \boldsymbol{x} = \boldsymbol{y}\)</span> and solve the system <span class="math inline">\(L \boldsymbol{y} = \boldsymbol{b}\)</span> with forward substitution.&nbsp; <code>y = lsolve(L,b)</code></p></li>
<li><p>Finally, solve the system <span class="math inline">\(U \boldsymbol{x} = \boldsymbol{y}\)</span> with backward substitution.<br>
<code>x = usolve(U,y)</code></p></li>
</ol>
</div>
<hr>
<div id="exr-4.37" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.35</strong></span> The <span class="math inline">\(LU\)</span> decomposition is not perfect. Discuss where the algorithm will fail.</p>
</div>
<hr>
<div id="exr-4.38" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.36</strong></span> What happens when you try to solve the system of equations <span class="math display">\[\begin{equation}
\begin{pmatrix} 0 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 0 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 7 \\ 9\\-3\end{pmatrix}
\end{equation}\]</span> with the <span class="math inline">\(LU\)</span> decomposition algorithm? Discuss.</p>
</div>
</section>
</section>
<section id="the-qr-factorization" class="level2" data-number="C.6">
<h2 data-number="C.6" class="anchored" data-anchor-id="the-qr-factorization"><span class="header-section-number">C.6</span> The QR Factorization</h2>
<p>In this section we will try to find an improvement on the <span class="math inline">\(LU\)</span> factorization scheme from the previous section. What we will do here is leverage the geometry of the column space of the <span class="math inline">\(A\)</span> matrix instead of leveraging the row reduction process.</p>
<hr>
<div id="exr-4.39" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.37</strong></span> We want to solve the system of equations <span class="math display">\[\begin{equation}
\begin{pmatrix} 1/3 &amp; 2/3 &amp; 2/3 \\ 2/3 &amp; 1/3 &amp; -2/3 \\ -2/3 &amp; 2/3 &amp; -1/3 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 6 \\ 12\\ -9 \end{pmatrix}.
\end{equation}\]</span></p>
<ol type="1">
<li><p>We could do row reduction by hand … yuck … do not do this.</p></li>
<li><p>We could apply our new-found skills with the <span class="math inline">\(LU\)</span> decomposition to solve the system, so go ahead and do that with your Python code.</p></li>
<li><p>What do you get if you compute the product <span class="math inline">\(A^T A\)</span>?</p>
<ol type="a">
<li><p>Why do you get what you get? In other words, what was special about <span class="math inline">\(A\)</span> that gave such an nice result?</p></li>
<li><p>What does this mean about the matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(A^T\)</span>?</p></li>
</ol></li>
<li><p>Now let us leverage what we found in part (3) to solve the system of equations <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> much faster. Multiply both sides of the matrix equation by <span class="math inline">\(A^T\)</span>, and now you should be able to just read off the solution. This seems amazing!!</p></li>
<li><p>What was it about this particular problem that made part (4) so elegant and easy?</p></li>
</ol>
</div>
<hr>
<p>The previous exercise tells us something amazing:</p>
<div id="thm-4.1" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.1 (Orthonomal Matrices)</strong></span> If <span class="math inline">\(A\)</span> is an orthonormal matrix where the columns are mutually orthogonal and every column is a unit vector, then <span class="math inline">\(A^T = A^{-1}\)</span> and to solve the system of equation <span class="math inline">\(A\boldsymbol{x} = \boldsymbol{b}\)</span> we simply need to multiply both sides of the equation by <span class="math inline">\(A^T\)</span>. Hence, the solution to <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> is just <span class="math inline">\(\boldsymbol{x} = A^T \boldsymbol{b}\)</span> in this special case.</p>
</div>
<hr>
<p><a href="#thm-4.1" class="quarto-xref">Theorem&nbsp;<span>C.1</span></a> begs an obvious question: <em>Is there a way to turn any matrix</em> <span class="math inline">\(A\)</span> into an orthogonal matrix so that we can solve <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> in this same very efficient and fast way?</p>
<p>The answer: Yes. Kind of.</p>
<p>In essence, if we can factor our coefficient matrix into an orthonormal matrix and some other nicely formatted matrix (like a triangular matrix, perhaps) then the job of solving the linear system of equations comes down to matrix multiplication and a quick triangular solve – both of which are extremely fast!</p>
<p>What we will study in this section is a new matrix factorization called the <span class="math inline">\(QR\)</span> factorization whose goal is to convert the matrix <span class="math inline">\(A\)</span> into a product of two matrices, <span class="math inline">\(Q\)</span> and <span class="math inline">\(R\)</span>, where <span class="math inline">\(Q\)</span> is orthonormal and <span class="math inline">\(R\)</span> is upper-triangular.</p>
<hr>
<div id="exr-4.40" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.38</strong></span> Let us say that we have a matrix <span class="math inline">\(A\)</span> and we know that it can be factored into <span class="math inline">\(A = QR\)</span> where <span class="math inline">\(Q\)</span> is an orthonormal matrix and <span class="math inline">\(R\)</span> is an upper-triangular matrix. How would we then leverage this factorization to solve the system of equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> for <span class="math inline">\(\boldsymbol{x}\)</span>?</p>
</div>
<hr>
<p>Before proceeding to the algorithm for the <span class="math inline">\(QR\)</span> factorization let us pause for a moment and review scalar and vector projections from Linear Algebra. In <a href="#fig-4.1" class="quarto-xref">Figure&nbsp;<span>C.1</span></a> we see a graphical depiction of the vector <span class="math inline">\(\boldsymbol{u}\)</span> projected onto vector <span class="math inline">\(\boldsymbol{v}\)</span>. Notice that the projection is indeed the perpendicular projection as this is what seems natural geometrically.</p>
<p>The <strong>vector projection</strong> of <span class="math inline">\(\boldsymbol{u}\)</span> onto <span class="math inline">\(\boldsymbol{v}\)</span> is the vector <span class="math inline">\(c \boldsymbol{v}\)</span>. That is, the vector projection of <span class="math inline">\(\boldsymbol{u}\)</span> onto <span class="math inline">\(\boldsymbol{v}\)</span> is a scalar multiple of the vector <span class="math inline">\(\boldsymbol{v}\)</span>. The value of the scalar <span class="math inline">\(c\)</span> is called the <strong>scalar projection</strong> of <span class="math inline">\(\boldsymbol{u}\)</span> onto <span class="math inline">\(\boldsymbol{v}\)</span>.</p>
<div id="fig-4.1" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://numericalmethodssullivan.github.io/images/Ch04Projection.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.1: Projection of one vector onto another.
</figcaption>
</figure>
</div>
<p>Figure 4.1: Projection of one vector onto another.</p>
<p>We can arrive at a formula for the scalar projection rather easily if we consider that the vector <span class="math inline">\(\boldsymbol{w}\)</span> in <a href="#fig-4.1" class="quarto-xref">Figure&nbsp;<span>C.1</span></a> must be perpendicular to <span class="math inline">\(c\boldsymbol{v}\)</span>. Hence <span class="math display">\[\begin{equation}
\boldsymbol{w} \cdot \left( c\boldsymbol{v} \right) = 0.
\end{equation}\]</span> From vector geometry we also know that <span class="math inline">\(\boldsymbol{w} = \boldsymbol{u}-c\boldsymbol{v}\)</span>. Therefore <span class="math display">\[\begin{equation}
\left( \boldsymbol{u} - c\boldsymbol{v} \right) \cdot \left( c \boldsymbol{v} \right) = 0.
\end{equation}\]</span> If we distribute we can see that <span class="math display">\[\begin{equation}
c \boldsymbol{u} \cdot \boldsymbol{v} - c^2 \boldsymbol{v} \cdot \boldsymbol{v} = 0
\end{equation}\]</span> and therefore either <span class="math inline">\(c=0\)</span>, which is only true if <span class="math inline">\(\boldsymbol{u} \perp \boldsymbol{v}\)</span>, or <span class="math display">\[\begin{equation}
c = \frac{\boldsymbol{u} \cdot \boldsymbol{v}}{\boldsymbol{v} \cdot \boldsymbol{v}} = \frac{\boldsymbol{u} \cdot \boldsymbol{v}}{\|\boldsymbol{v} \|^2}.
\end{equation}\]</span></p>
<p>Therefore,</p>
<ul>
<li><p>the <strong>scalar projection of</strong> <span class="math inline">\(\boldsymbol{u}\)</span> onto <span class="math inline">\(\boldsymbol{v}\)</span> is <span class="math display">\[\begin{equation}
c = \frac{\boldsymbol{u} \cdot \boldsymbol{v}}{\|\boldsymbol{v} \|^2}
\end{equation}\]</span></p></li>
<li><p>the <strong>vector projection of</strong> <span class="math inline">\(\boldsymbol{u}\)</span> onto <span class="math inline">\(\boldsymbol{v}\)</span> is <span class="math display">\[\begin{equation}
c \boldsymbol{v} = \left( \frac{\boldsymbol{u} \cdot \boldsymbol{v}}{\|\boldsymbol{v} \|^2} \right) \boldsymbol{v}
\end{equation}\]</span></p></li>
</ul>
<p>Another problem related to scalar and vector projections is to take a basis for the column space of a matrix and transform that basis into an orthogonal (or orthonormal) basis. Indeed, in <a href="#fig-4.1" class="quarto-xref">Figure&nbsp;<span>C.1</span></a> if we have the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} | &amp; | \\ \boldsymbol{u} &amp; \boldsymbol{v} \\ | &amp; | \end{pmatrix}
\end{equation}\]</span> it should be clear from the picture that the columns of this matrix are not perpendicular. However, if we take the vector <span class="math inline">\(\boldsymbol{v}\)</span> and the vector <span class="math inline">\(\boldsymbol{w}\)</span> we do arrive at two orthogonal vector that form a basis for the same space. Moreover, if we normalize these vectors (by dividing by their respective lengths) then we can easily transform the original basis for the column space of <span class="math inline">\(A\)</span> into an orthonormal basis. This process is called the Gram-Schmidt process, and you have encountered it in your Linear Algebra module.</p>
<p>Now we return to our goal of finding a way to factor a matrix <span class="math inline">\(A\)</span> into an orthonormal matrix <span class="math inline">\(Q\)</span> and an upper-triangular matrix <span class="math inline">\(R\)</span>. The algorithm that we are about to build depends greatly on the ideas of scalar and vector projections.</p>
<hr>
<div id="exr-4.41" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.39</strong></span> We want to build a <span class="math inline">\(QR\)</span> factorization of the matrix <span class="math inline">\(A\)</span> in the matrix equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> so that we can leverage the fact that solving the equation <span class="math inline">\(QR\boldsymbol{x} = \boldsymbol{b}\)</span> is easy. Consider the matrix <span class="math inline">\(A\)</span> defined as <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 3 &amp; 1 \\ 4 &amp; 1 \end{pmatrix}.
\end{equation}\]</span> Notice that the columns of <span class="math inline">\(A\)</span> are NOT orthonormal (they are not unit vectors and they are not perpendicular to each other).</p>
<ol type="1">
<li><p>Draw a picture of the two column vectors of <span class="math inline">\(A\)</span> in <span class="math inline">\(\mathbb{R}^2\)</span>. we will use this picture to build geometric intuition for the rest of the <span class="math inline">\(QR\)</span> factorization process.</p></li>
<li><p>Define <span class="math inline">\(\boldsymbol{a}_0\)</span> as the first column of <span class="math inline">\(A\)</span> and <span class="math inline">\(\boldsymbol{a}_1\)</span> as the second column of <span class="math inline">\(A\)</span>. That is <span class="math display">\[\begin{equation}
\boldsymbol{a}_0 = \begin{pmatrix} 3\\4\end{pmatrix} \quad \text{and} \quad \boldsymbol{a}_1 = \begin{pmatrix} 1\\1\end{pmatrix}.
\end{equation}\]</span> Turn <span class="math inline">\(\boldsymbol{a}_0\)</span> into a unit vector and call this unit vector <span class="math inline">\(\boldsymbol{q}_0\)</span> <span class="math display">\[\begin{equation}
\boldsymbol{q}_0 = \frac{\boldsymbol{a}_0}{\|\boldsymbol{a}_0\|} = \begin{pmatrix} \underline{\hspace{0.5in}} \\ \underline{\hspace{0.5in}} \end{pmatrix}.
\end{equation}\]</span> This vector <span class="math inline">\(\boldsymbol{q}_0\)</span> will be the first column of the <span class="math inline">\(2 \times 2\)</span> matrix <span class="math inline">\(Q\)</span>. Why is this a nice place to start building the <span class="math inline">\(Q\)</span> matrix (think about the desired structure of <span class="math inline">\(Q\)</span>)?</p></li>
<li><p>In your picture of <span class="math inline">\(\boldsymbol{a}_0\)</span> and <span class="math inline">\(\boldsymbol{a}_1\)</span> mark where <span class="math inline">\(\boldsymbol{q}_0\)</span> is. Then draw the orthogonal projection from <span class="math inline">\(\boldsymbol{a}_1\)</span> onto <span class="math inline">\(\boldsymbol{q}_0\)</span>. In your picture you should now see a right triangle with <span class="math inline">\(\boldsymbol{a}_1\)</span> on the hypotenuse, the projection of <span class="math inline">\(\boldsymbol{a}_1\)</span> onto <span class="math inline">\(\boldsymbol{q}_0\)</span> on one leg, and the second leg is the vector difference of the hypotenuse and the first leg. Simplify the projection formula for leg 1 and write the formula for leg 2.<br>
</p></li>
</ol>
<p><span class="math display">\[\begin{equation}
\text{hypotenuse } = \boldsymbol{a}_1
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\text{leg 1 } = \left( \frac{\boldsymbol{a}_1 \cdot \boldsymbol{q}_0}{\boldsymbol{q}_0 \cdot \boldsymbol{q}_0} \right) \boldsymbol{q}_0 = \underline{\hspace{1in}}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\text{leg 2 } = \underline{\hspace{1in}} - \underline{\hspace{1in}}.
\end{equation}\]</span></p>
<ol start="4" type="1">
<li><p>Compute the vector for leg 2 and then normalize it to turn it into a unit vector. Call this vector <span class="math inline">\(\boldsymbol{q}_1\)</span> and put it in the second column of <span class="math inline">\(Q\)</span>.</p></li>
<li><p>Verify that the columns of <span class="math inline">\(Q\)</span> are now orthogonal and are both unit vectors.</p></li>
<li><p>The matrix <span class="math inline">\(R\)</span> is supposed to complete the matrix factorization <span class="math inline">\(A = QR\)</span>. We have built <span class="math inline">\(Q\)</span> as an orthonormal matrix. How can we use this fact to solve for the matrix <span class="math inline">\(R\)</span>?</p></li>
<li><p>You should now have an orthonormal matrix <span class="math inline">\(Q\)</span> and an upper-triangular matrix <span class="math inline">\(R\)</span>. Verify that <span class="math inline">\(A = QR\)</span>.</p></li>
<li><p>An alternate way to build the <span class="math inline">\(R\)</span> matrix is to observe that <span class="math display">\[\begin{equation}
R = \begin{pmatrix} \boldsymbol{a}_0 \cdot \boldsymbol{q}_0 &amp; \boldsymbol{a}_1 \cdot \boldsymbol{q}_0 \\ 0 &amp; \boldsymbol{a}_1 \cdot \boldsymbol{q}_1 \end{pmatrix}.
\end{equation}\]</span> Show that this is indeed true for the matrix <span class="math inline">\(A\)</span> from this problem.</p></li>
</ol>
</div>
<hr>
<div id="exr-4.42" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.40</strong></span> Keeping track of all of the arithmetic in the <span class="math inline">\(QR\)</span> factorization process is quite challenging, so let us leverage Python to do some of the work for us. The following block of code walks through the previous exercise without any looping (that way we can see every step transparently). Some of the code is missing so you will need to fill it in.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the matrix $A$</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">3</span>,<span class="dv">1</span>],[<span class="dv">4</span>,<span class="dv">1</span>]])</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> A.shape[<span class="dv">0</span>]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the vectors a0 and a1</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>a0 <span class="op">=</span> A[??? , ???] <span class="co"># ... write code to get column 0 from A</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>a1 <span class="op">=</span> A[??? , ???] <span class="co"># ... write code to get column 1 from A</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up storage for Q</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros( (n,n) )</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># build the vector q0 by normalizing a0</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>q0 <span class="op">=</span> a0 <span class="op">/</span> np.linalg.norm(a0)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Put q0 as the first column of Q</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>Q[:,<span class="dv">0</span>] <span class="op">=</span> q0</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the lengths of the two legs of the triangle</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>leg1 <span class="op">=</span> <span class="co"># write code to get the vector for leg 1 of the triangle</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>leg2 <span class="op">=</span> <span class="co"># write code to get the vector for leg 2 of the triangle</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize leg2 and call it q1</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>q1 <span class="op">=</span> <span class="co"># write code to normalize leg2</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>q1 <span class="op">=</span> q1 <span class="op">/</span> np.linalg.norm(q1) <span class="co"># Just to be safe with normalization if not implied</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>Q[:,<span class="dv">1</span>] <span class="op">=</span> q1 <span class="co"># What does this line do?</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> <span class="co"># ... build the R matrix out of A and Q</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The Q matrix is </span><span class="ch">\n</span><span class="st">"</span>,Q,<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The R matrix is </span><span class="ch">\n</span><span class="st">"</span>,R,<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The A matrix is </span><span class="ch">\n</span><span class="st">"</span>,A,<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The product QR is</span><span class="ch">\n</span><span class="st">"</span>,Q <span class="op">@</span> R)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.43" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.41</strong></span> You should notice that the code in the previous exercise does not depend on the specific matrix <span class="math inline">\(A\)</span> that we used? Put in a different <span class="math inline">\(2 \times 2\)</span> matrix and verify that the process still works. That is, verify that <span class="math inline">\(Q\)</span> is orthonormal, <span class="math inline">\(R\)</span> is upper-triangular, and <span class="math inline">\(A = QR\)</span>. Be sure, however, that your matrix <span class="math inline">\(A\)</span> is full rank.</p>
</div>
<hr>
<div id="exr-4.44" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.42</strong></span> Draw two generic vectors in <span class="math inline">\(\mathbb{R}^2\)</span> and demonstrate the process outlined in the previous problem to build the vectors for the <span class="math inline">\(Q\)</span> matrix starting from your generic vectors.</p>
</div>
<hr>
<div id="exr-4.45" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.43</strong></span> Now we will extend the process from the previous exercises to three dimensions. This time we will seek a matrix <span class="math inline">\(Q\)</span> that has three orthonormal vectors starting from the three original columns of a <span class="math inline">\(3 \times 3\)</span> matrix <span class="math inline">\(A\)</span>. Perform each of the following steps <strong>by hand</strong> on the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{pmatrix}.
\end{equation}\]</span> In the end you should end up with an orthonormal matrix <span class="math inline">\(Q\)</span> and an upper-triangular matrix <span class="math inline">\(R\)</span>.</p>
<ul>
<li><p><strong>Step 1</strong>: Pick column <span class="math inline">\(\boldsymbol{a}_0\)</span> from the matrix <span class="math inline">\(A\)</span> and normalize it. Call this new vector <span class="math inline">\(\boldsymbol{q}_0\)</span> and make that the first column of the matrix <span class="math inline">\(Q\)</span>.</p></li>
<li><p><strong>Step 2</strong>: Project column <span class="math inline">\(\boldsymbol{a}_1\)</span> of <span class="math inline">\(A\)</span> onto <span class="math inline">\(\boldsymbol{q}_0\)</span>. This forms a right triangle with <span class="math inline">\(\boldsymbol{a}_1\)</span> as the hypotenuse, the projection of <span class="math inline">\(\boldsymbol{a}_1\)</span> onto <span class="math inline">\(\boldsymbol{q}_0\)</span> as one of the legs, and the vector difference between these two as the second leg. Notice that the second leg of the newly formed right triangle is perpendicular to <span class="math inline">\(\boldsymbol{q}_0\)</span> by design. If we normalize this vector then we have the second column of <span class="math inline">\(Q\)</span>, <span class="math inline">\(\boldsymbol{q}_1\)</span>.</p></li>
<li><p><strong>Step 3:</strong> Now we need a vector that is perpendicular to both <span class="math inline">\(\boldsymbol{q}_0\)</span> AND <span class="math inline">\(\boldsymbol{q}_1\)</span>. To achieve this we are going to project column <span class="math inline">\(\boldsymbol{a}_2\)</span> from <span class="math inline">\(A\)</span> onto the plane formed by <span class="math inline">\(\boldsymbol{q}_0\)</span> and <span class="math inline">\(\boldsymbol{q}_1\)</span>. we will do this in two steps:</p>
<ul>
<li><p><strong>Step 3a</strong>: We first project <span class="math inline">\(\boldsymbol{a}_2\)</span> down onto both <span class="math inline">\(\boldsymbol{q}_0\)</span> and <span class="math inline">\(\boldsymbol{q}_1\)</span>.</p></li>
<li><p><strong>Step 3b</strong>: The vector that is perpendicular to both <span class="math inline">\(\boldsymbol{q}_0\)</span> and <span class="math inline">\(\boldsymbol{q}_1\)</span> will be the difference between <span class="math inline">\(\boldsymbol{a}_2\)</span> the projection of <span class="math inline">\(\boldsymbol{a}_2\)</span> onto <span class="math inline">\(\boldsymbol{q}_0\)</span> and the projection of <span class="math inline">\(\boldsymbol{a}_2\)</span> onto <span class="math inline">\(\boldsymbol{q}_1\)</span>. That is, we form the vector <span class="math inline">\(\boldsymbol{w} = \boldsymbol{a}_2 - (\boldsymbol{a}_2 \cdot \boldsymbol{q}_0 ) \boldsymbol{q}_0 - (\boldsymbol{a}_2 \cdot \boldsymbol{q}_1) \boldsymbol{q}_1.\)</span> Normalizing this vector will give us <span class="math inline">\(\boldsymbol{q}_2\)</span>. (Stop now and prove that <span class="math inline">\(\boldsymbol{q}_2\)</span> is indeed perpendicular to both <span class="math inline">\(\boldsymbol{q}_1\)</span> and <span class="math inline">\(\boldsymbol{q}_0\)</span>.)</p></li>
</ul></li>
</ul>
<p>The result should be the matrix <span class="math inline">\(Q\)</span> which contains orthonormal columns. To build the matrix <span class="math inline">\(R\)</span> we simply recall that <span class="math inline">\(A = QR\)</span> and <span class="math inline">\(Q^{-1} = Q^T\)</span> so <span class="math inline">\(R = Q^T A\)</span>.</p>
</div>
<hr>
<div id="exr-4.46" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.44</strong></span> Repeat the previous exercise but write code for each step so that Python can handle all of the computations. Again use the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{pmatrix}.
\end{equation}\]</span></p>
</div>
<hr>
<div id="exm-4.7" class="theorem example">
<p><span class="theorem-title"><strong>Example C.8</strong></span> (<strong>QR for</strong> <span class="math inline">\(n=3\)</span>) For the sake of clarity let us now write down the full <span class="math inline">\(QR\)</span> factorization for a <span class="math inline">\(3 \times 3\)</span> matrix.</p>
<p>If the columns of <span class="math inline">\(A\)</span> are <span class="math inline">\(\boldsymbol{a}_0\)</span>, <span class="math inline">\(\boldsymbol{a}_1\)</span>, and <span class="math inline">\(\boldsymbol{a}_2\)</span> then <span class="math display">\[\begin{equation}
\boldsymbol{q}_0 = \frac{\boldsymbol{a}_0}{\|\boldsymbol{a}_0\|}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{q}_1 = \frac{ \boldsymbol{a}_1 - \left( \boldsymbol{a}_1 \cdot \boldsymbol{q}_0 \right) \boldsymbol{q}_0 }{\| \boldsymbol{a}_1 - \left( \boldsymbol{a}_1 \cdot \boldsymbol{q}_0 \right) \boldsymbol{q}_0 \|}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{q}_2 = \frac{ \boldsymbol{a}_2 - \left( \boldsymbol{a}_2 \cdot \boldsymbol{q}_0 \right) \boldsymbol{q}_0 - \left( \boldsymbol{a}_2 \cdot \boldsymbol{q}_1 \right) \boldsymbol{q}_1}{\| \boldsymbol{a}_2 - \left( \boldsymbol{a}_2 \cdot \boldsymbol{q}_0 \right) \boldsymbol{q}_0 - \left( \boldsymbol{a}_2 \cdot \boldsymbol{q}_1 \right) \boldsymbol{q}_1 \|}
\end{equation}\]</span></p>
<p>and <span class="math display">\[\begin{equation}
R = \begin{pmatrix} \boldsymbol{a}_0 \cdot \boldsymbol{q}_0 &amp; \boldsymbol{a}_1 \cdot \boldsymbol{q}_0 &amp; \boldsymbol{a}_2 \cdot \boldsymbol{q}_0 \\ 0 &amp; \boldsymbol{a}_1 \cdot \boldsymbol{q}_1 &amp; \boldsymbol{a}_2 \cdot \boldsymbol{q}_1 \\ 0 &amp; 0 &amp; \boldsymbol{a}_2 \cdot \boldsymbol{q}_2 \end{pmatrix}
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.47" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.45 (The QR Factorization)</strong></span> Now we are ready to build general code for the <span class="math inline">\(QR\)</span> factorization. The following Python function definition is partially complete. Fill in the missing pieces of code and then test your code on square matrices of many different sizes. The easiest way to check if you have an error is to find the normed difference between <span class="math inline">\(A\)</span> and <span class="math inline">\(QR\)</span> with <code>np.linalg.norm(A - Q*R)</code>.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> myQR(A):</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> A.shape[<span class="dv">0</span>]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    Q <span class="op">=</span> np.zeros( (n,n) )</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>( ??? ): <span class="co"># The outer loop goes over the columns</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> A[:,j]</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The next loop is meant to do all of the projections.</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># When do you start the inner loop and how far do you go?</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Hint: You do not need to enter this loop the first time </span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( ??? ): </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>            length_of_leg <span class="op">=</span> np.dot(A[:,j], Q[:,i])</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>            q <span class="op">=</span> q <span class="op">-</span>  ??? <span class="op">*</span> ??? <span class="co"># This is where we do projections</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        Q[:,j] <span class="op">=</span> q <span class="op">/</span> np.linalg.norm(q)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    R <span class="op">=</span> <span class="co"># finally build the R matrix</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Q, R</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test Code</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array( ... )</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># or you can build A with use np.random.randn() </span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Often time random matrices are good test cases</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>Q, R <span class="op">=</span> myQR(A)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> np.linalg.norm(A <span class="op">-</span> Q <span class="op">@</span> R)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(error)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<p>We now have a robust algorithm for doing <span class="math inline">\(QR\)</span> factorization of square matrices we can finally return to solving systems of equations.</p>
<div id="thm-4.2" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.2</strong></span> (<strong>Solving Systems with</strong> <span class="math inline">\(QR\)</span>) Remember that we want to solve <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> and since <span class="math inline">\(A = QR\)</span> we can rewrite it with <span class="math inline">\(QR \boldsymbol{x} = \boldsymbol{b}\)</span>. Since we know that <span class="math inline">\(Q\)</span> is orthonormal by design we can multiply both sides of the equation by <span class="math inline">\(Q^T\)</span> to get <span class="math inline">\(R \boldsymbol{x} = Q^T \boldsymbol{b}\)</span>. Finally, since <span class="math inline">\(R\)</span> is upper-triangular we can use our <code>usolve</code> code from the previous section to solve the resulting triangular system.</p>
</div>
<hr>
<div id="exr-4.48" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.46</strong></span> Solve the system of equations <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 0 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}
\end{equation}\]</span> by first computing the <span class="math inline">\(QR\)</span> factorization of <span class="math inline">\(A\)</span> and then solving the resulting upper-triangular system.</p>
</div>
<hr>
<div id="exr-4.49" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.47</strong></span> Write code that builds a random <span class="math inline">\(n \times n\)</span> matrix and a random <span class="math inline">\(n \times 1\)</span> vector. Solve the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> using the <span class="math inline">\(QR\)</span> factorization and compare the answer to what we find from <code>np.linalg.solve()</code>. Do this many times for various values of <span class="math inline">\(n\)</span> and create a plot with <span class="math inline">\(n\)</span> on the horizontal axis and the normed error between Python’s answer and your answer from the <span class="math inline">\(QR\)</span> algorithm on the vertical axis. It would be wise to use a <code>plt.semilogy()</code> plot. To find the normed difference you should use <code>np.linalg.norm()</code>. What do you notice?</p>
</div>
<hr>
</section>
<section id="over-determined-systems-and-curve-fitting" class="level2" data-number="C.7">
<h2 data-number="C.7" class="anchored" data-anchor-id="over-determined-systems-and-curve-fitting"><span class="header-section-number">C.7</span> Over-determined Systems and Curve Fitting</h2>
<div id="exr-4.50" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.48</strong></span> Consider the problem of finding the quadratic function <span class="math inline">\(f(x) = ax^2 + bx + c\)</span> that <em>best fits</em> the points <span class="math display">\[\begin{equation}
(0, 1.07), (1, 3.9), (2, 14.8), (3, 26.8).
\end{equation}\]</span> We do not know the values of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, or <span class="math inline">\(c\)</span> but we do have four different <span class="math inline">\((x,y)\)</span> ordered pairs. Hence, we have four equations: <span class="math display">\[\begin{equation}
1.07 = a(0)^2 + b(0) + c
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
3.9 = a(1)^2 + b(1) + c
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
14.8 = a(2)^2 + b(2) + c
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
26.8 = a(3)^2 + b(3) + c.
\end{equation}\]</span></p>
<p>There are four equations and only three unknowns. This is what is called an <strong>over determined systems</strong> – when there are more equations than unknowns. Let us play with this problem.</p>
<ol type="1">
<li><p>First turn the system of equations into a matrix equation. <span class="math display">\[\begin{equation}
\begin{pmatrix} 0 &amp; 0 &amp; 1 \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \\ \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} &amp; \underline{\hspace{0.25in}} \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 1.07 \\ 3.9 \\ 14.8 \\ 26.8 \end{pmatrix}.
\end{equation}\]</span></p></li>
<li><p>None of our techniques for solving systems will likely work here since it is highly unlikely that the vector on the right-hand side of the equation is in the column space of the coefficient matrix. Discuss this.</p></li>
<li><p>One solution to the unfortunate fact from part (b) is that we can project the vector on the right-hand side into the subspace spanned by the columns of the coefficient matrix. Think of this as casting the shadow of the right-hand vector down onto the space spanned by the columns. If we do this projection we will be able to solve the equation for the values of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span> that will create the projection exactly – and hence be as close as we can get to the actual right-hand side. Draw a picture of what we have said here.</p></li>
<li><p>Now we need to project the right-hand side, call it <span class="math inline">\(\boldsymbol{b}\)</span>, onto the column space of the the coefficient matrix <span class="math inline">\(A\)</span>. Recall the following facts:</p>
<ul>
<li><p>Projections are dot products</p></li>
<li><p>Matrix multiplication is nothing but a bunch of dot products.</p></li>
<li><p>The projections of <span class="math inline">\(\boldsymbol{b}\)</span> onto the columns of <span class="math inline">\(A\)</span> are the dot products of <span class="math inline">\(\boldsymbol{b}\)</span> with each of the columns of <span class="math inline">\(A\)</span>.</p></li>
<li><p>What matrix can we multiply both sides of the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> by in order for the right-hand side to become the projection that we want? (Now do the projection in Python)</p></li>
</ul></li>
<li><p>If you have done part (d) correctly then you should now have a square system (i.e.&nbsp;the matrix on the left-hand side should now be square). Solve this system for <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span>.</p></li>
</ol>
</div>
<hr>
<div id="thm-4.3" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.3 (Solving Overdetermined Systems)</strong></span> If <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> is an overdetermined system (i.e.&nbsp;<span class="math inline">\(A\)</span> has more rows than columns) then we first multiply both sides of the equation by <span class="math inline">\(A^T\)</span> (why do we do this?) and then solve the square system of equations <span class="math inline">\((A^T A) \boldsymbol{x} = A^T \boldsymbol{b}\)</span> using a system solving like <span class="math inline">\(LU\)</span> or <span class="math inline">\(QR\)</span>. The answer to this new system is interpreted as the vector <span class="math inline">\(\boldsymbol{x}\)</span> which solves exactly for the projection of <span class="math inline">\(\boldsymbol{b}\)</span> onto the column space of <span class="math inline">\(A\)</span>.</p>
<p>The equation <span class="math inline">\((A^T A) \boldsymbol{x} = A^T \boldsymbol{b}\)</span> is called <strong>the normal equations</strong> and arises often in Statistics and Machine Learning.</p>
</div>
<hr>
<div id="exr-4.51" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.49</strong></span> Fit a linear function to the following data. Solve for the slope and intercept using the technique outlined in <a href="#thm-4.3" class="quarto-xref">Theorem&nbsp;<span>C.3</span></a>. Make a plot of the points along with your best fit curve.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>4.6</td>
</tr>
<tr class="even">
<td>1</td>
<td>11</td>
</tr>
<tr class="odd">
<td>2</td>
<td>12</td>
</tr>
<tr class="even">
<td>3</td>
<td>19.1</td>
</tr>
<tr class="odd">
<td>4</td>
<td>18.8</td>
</tr>
<tr class="even">
<td>5</td>
<td>39.5</td>
</tr>
<tr class="odd">
<td>6</td>
<td>31.1</td>
</tr>
<tr class="even">
<td>7</td>
<td>43.4</td>
</tr>
<tr class="odd">
<td>8</td>
<td>40.3</td>
</tr>
<tr class="even">
<td>9</td>
<td>41.5</td>
</tr>
<tr class="odd">
<td>10</td>
<td>41.6</td>
</tr>
</tbody>
</table>
</div>
<hr>
<div id="exr-4.52" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.50</strong></span> Fit a quadratic function to the following data using the technique outlined in <a href="#thm-4.3" class="quarto-xref">Theorem&nbsp;<span>C.3</span></a>. Make a plot of the points along with your best fit curve.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>-6.8</td>
</tr>
<tr class="even">
<td>1</td>
<td>11.8</td>
</tr>
<tr class="odd">
<td>2</td>
<td>50.6</td>
</tr>
<tr class="even">
<td>3</td>
<td>94</td>
</tr>
<tr class="odd">
<td>4</td>
<td>224.3</td>
</tr>
<tr class="even">
<td>5</td>
<td>301.7</td>
</tr>
<tr class="odd">
<td>6</td>
<td>499.2</td>
</tr>
<tr class="even">
<td>7</td>
<td>454.7</td>
</tr>
<tr class="odd">
<td>8</td>
<td>578.5</td>
</tr>
<tr class="even">
<td>9</td>
<td>1102</td>
</tr>
<tr class="odd">
<td>10</td>
<td>1203.2</td>
</tr>
</tbody>
</table>
<p>Code to download the data directly is given below.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>URL1 <span class="op">=</span> <span class="st">'https://raw.githubusercontent.com/NumericalMethodsSullivan'</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>URL2 <span class="op">=</span> <span class="st">'/NumericalMethodsSullivan.github.io/master/data/'</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>URL <span class="op">=</span> URL1<span class="op">+</span>URL2</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array( pd.read_csv(URL<span class="op">+</span><span class="st">'Exercise4_52.csv'</span>) )</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Exercise4_52.csv</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.53" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.51</strong></span> The Statistical technique of curve fitting is often called “linear regression.” This even holds when we are fitting quadratic functions, cubic functions, etc to the data … we still call that linear regression! Why?</p>
</div>
<hr>
<p>This section of the text on solving over determined systems is just a bit of a teaser for a bit of higher-level statistics, data science, and machine learning. The normal equations and solving systems via projections is the starting point of many modern machine learning algorithms.</p>
<hr>
</section>
<section id="the-eigenvalue-eigenvector-problem" class="level2" data-number="C.8">
<h2 data-number="C.8" class="anchored" data-anchor-id="the-eigenvalue-eigenvector-problem"><span class="header-section-number">C.8</span> The Eigenvalue-Eigenvector Problem</h2>
<p>We finally turn our attention to another major topic in numerical linear algebra.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div id="def-4.8" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.7 (The Eigenvalue Problem)</strong></span> Recall that the eigenvectors, <span class="math inline">\(\boldsymbol{x}\)</span>, and the eigenvalues, <span class="math inline">\(\lambda\)</span> of a square matrix satisfy the equation <span class="math inline">\(A\boldsymbol{x}=\lambda \boldsymbol{x}\)</span>. Geometrically, the eigen-problem is the task of finding the special vectors <span class="math inline">\(\boldsymbol{x}\)</span> such that multiplication by the matrix <span class="math inline">\(A\)</span> only produces a scalar multiple of <span class="math inline">\(\boldsymbol{x}\)</span>.</p>
</div>
<hr>
<p>Thinking about matrix multiplication, the geometric notion of the eigenvalue problem is rather peculiar since matrix-vector multiplication usually results in a scaling and a rotation of the vector <span class="math inline">\(\boldsymbol{x}\)</span>. Therefore, in some sense the eigenvectors are the only special vectors which avoid geometric rotation under matrix multiplication. For a graphical exploration of this idea see:<br>
<a href="https://www.geogebra.org/m/JP2XZpzV" class="uri">https://www.geogebra.org/m/JP2XZpzV</a>.</p>
<hr>
<p>Recall that to solve the eigen-problem for a square matrix <span class="math inline">\(A\)</span> we complete the following steps:</p>
<ol type="1">
<li><p>First rearrange the definition of the eigenvalue-eigenvector pair to <span class="math display">\[\begin{equation}
(A\boldsymbol{x}-\lambda \boldsymbol{x})=\boldsymbol{0}.
\end{equation}\]</span></p></li>
<li><p>Next, factor the <span class="math inline">\(\boldsymbol{x}\)</span> on the right to get <span class="math display">\[\begin{equation}
(A-\lambda I) \boldsymbol{x}=\boldsymbol{0}.
\end{equation}\]</span></p></li>
<li><p>Now observe that since <span class="math inline">\(\boldsymbol{x} \ne 0\)</span> the matrix <span class="math inline">\(A-\lambda I\)</span> must NOT have an inverse. Therefore, <span class="math display">\[\begin{equation}
\det(A-\lambda I)=0.
\end{equation}\]</span></p></li>
<li><p>Solve the equation <span class="math inline">\(\det(A-\lambda I)=0\)</span> for all of the values of <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>For each <span class="math inline">\(\lambda\)</span>, find a solution to the equation <span class="math inline">\((A-\lambda I) \boldsymbol{x}=\boldsymbol{0}\)</span>. Note that there will be infinitely many solutions so you will need to make wise choices for the free variables.</p></li>
</ol>
<hr>
<div id="exr-4.54" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.52</strong></span> Find the eigenvalues and eigenvectors of <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 \\ 4 &amp; 3 \end{pmatrix}.
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.55" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.53</strong></span> In the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{pmatrix}
\end{equation}\]</span> one of the eigenvalues is <span class="math inline">\(\lambda_1 = 0\)</span>.</p>
<ol type="1">
<li><p>What does that tell us about the matrix <span class="math inline">\(A\)</span>?</p></li>
<li><p>What is the eigenvector <span class="math inline">\(\boldsymbol{v}_1\)</span> associated with <span class="math inline">\(\lambda_1 = 0\)</span>?</p></li>
<li><p>What is the null space of the matrix <span class="math inline">\(A\)</span>?</p></li>
</ol>
</div>
<hr>
<p>OK. Now that you have recalled some of the basics, let us play with a little limit problem. The following exercises are going to work us toward the <strong>power method</strong> for finding certain eigen-structures of a matrix.</p>
<hr>
<div id="exr-4.56" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.54</strong></span> Consider the matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 8 &amp; 5 &amp; -6 \\ -12 &amp; -9 &amp; 12 \\ -3 &amp; -3 &amp; 5 \end{pmatrix}.
\end{equation}\]</span> This matrix has the following eigen-structure: <span class="math display">\[\begin{equation}
\boldsymbol{v}_1 = \begin{pmatrix} 1\\-1\\0\end{pmatrix} \quad \text{with} \quad \lambda_1 = 3
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{v}_2 = \begin{pmatrix} 2\\0\\2\end{pmatrix} \quad \text{with} \quad \lambda_2 = 2
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{v}_3 = \begin{pmatrix} -1\\3\\1\end{pmatrix} \quad \text{with} \quad \lambda_3 = -1
\end{equation}\]</span></p>
<p>If we have <span class="math display">\[\begin{equation}
\boldsymbol{x} = -2 \boldsymbol{v}_1 + 1 \boldsymbol{v}_2 - 3 \boldsymbol{v}_3 = \begin{pmatrix} 3 \\ -7 \\ -1 \end{pmatrix}
\end{equation}\]</span> then we want to do a bit of an experiment. What happens when we iteratively multiply <span class="math inline">\(\boldsymbol{x}\)</span> by <span class="math inline">\(A\)</span> but at the same time divide by the largest eigenvalue. Let us see:</p>
<ul>
<li><p>What is <span class="math inline">\(A^1 \boldsymbol{x} / 3^1\)</span>?</p></li>
<li><p>What is <span class="math inline">\(A^2 \boldsymbol{x} / 3^2\)</span>?</p></li>
<li><p>What is <span class="math inline">\(A^3 \boldsymbol{x} / 3^3\)</span>?</p></li>
<li><p>What is <span class="math inline">\(A^4 \boldsymbol{x} / 3^4\)</span>?</p></li>
<li><p>…</p></li>
</ul>
<p>It might be nice now to go to some Python code to do the computations (if you have not already). Use your code to conjecture about the following limit. <span class="math display">\[\begin{equation}
\lim_{k \to \infty} \frac{A^k \boldsymbol{x}}{\lambda_{max}^k} = ???.
\end{equation}\]</span> In this limit we are really interested in the direction of the resulting vector, not the magnitude. Therefore, in the code below you will see that we normalize the resulting vector so that it is a unit vector.</p>
<p>Note: be careful, computers do not do infinity, so for powers that are too large you will not get any results.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">8</span>,<span class="dv">5</span>,<span class="op">-</span><span class="dv">6</span>],[<span class="op">-</span><span class="dv">12</span>,<span class="op">-</span><span class="dv">9</span>,<span class="dv">12</span>],[<span class="op">-</span><span class="dv">3</span>,<span class="op">-</span><span class="dv">3</span>,<span class="dv">5</span>]])</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([[<span class="dv">3</span>],[<span class="op">-</span><span class="dv">7</span>],[<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>eigval_max <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: For numpy arrays, A**k is element-wise power. </span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># We must use np.linalg.matrix_power for matrix power.</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> np.linalg.matrix_power(A, k) <span class="op">@</span> x <span class="op">/</span> eigval_max<span class="op">**</span>k</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result <span class="op">/</span> np.linalg.norm(result) )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.57" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.55</strong></span> If a matrix <span class="math inline">\(A\)</span> has eigenvectors <span class="math inline">\(\boldsymbol{v}_1\)</span>, <span class="math inline">\(\boldsymbol{v}_2\)</span>, <span class="math inline">\(\boldsymbol{v}_3\)</span>, <span class="math inline">\(\cdots,\)</span> <span class="math inline">\(\boldsymbol{v}_n\)</span> with eigenvalues <span class="math inline">\(\lambda_1, \lambda_2, \lambda_3, \ldots, \lambda_n\)</span> and <span class="math inline">\(\boldsymbol{x}\)</span> is in the column space of <span class="math inline">\(A\)</span> then what will we get, approximately, if we evaluate <span class="math inline">\(A^k \boldsymbol{x} / \max_{j}(\lambda_j)^k\)</span> for very large values of <span class="math inline">\(k\)</span>?</p>
<p>Discuss your conjecture with your peers. Then try to verify it with several numerical examples.</p>
</div>
<hr>
<div id="exr-4.58" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.56</strong></span> Explain your result from the previous exercise geometrically.</p>
</div>
<hr>
<div id="exr-4.59" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.57</strong></span> The algorithm that we have been toying with will find the dominant eigenvector of a matrix fairly quickly. Why might you be only interested in the dominant eigenvector of a matrix? Discuss.</p>
</div>
<hr>
<div id="exr-4.60" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.58</strong></span> In this problem we will formally prove the conjecture that you just made. This conjecture will lead us to the <strong>power method</strong> for finding the dominant eigenvector and eigenvalue of a matrix.</p>
<ol type="1">
<li><p>Assume that <span class="math inline">\(A\)</span> has <span class="math inline">\(n\)</span> linearly independent eigenvectors <span class="math inline">\(\boldsymbol{v}_1, \boldsymbol{v}_2, \dots, \boldsymbol{v}_n\)</span> and choose <span class="math inline">\(\boldsymbol{x} = \sum_{j=1}^n c_j \boldsymbol{v}_j\)</span>. You have proved in the past that <span class="math display">\[\begin{equation}
A^k \boldsymbol{x} = c_1 \lambda_1^k \boldsymbol{v}_1 + c_2 \lambda_2^k \boldsymbol{v}_2 + \cdots c_n \lambda_n^k \boldsymbol{v}_n.
\end{equation}\]</span> Stop and sketch out the details of this proof now.</p></li>
<li><p>If we factor <span class="math inline">\(\lambda_1^k\)</span> out of the right-hand side we get <span class="math display">\[\begin{equation}
A^k \boldsymbol{x} = \lambda_1^k \left( c_1 ??? + c_2 \left( \frac{???}{???} \right)^k \boldsymbol{v}_2 + c_3 \left( \frac{???}{???} \right)^k \boldsymbol{v}_3 + \cdots + c_n \left( \frac{???}{???} \right)^k \boldsymbol{v}_n \right)
\end{equation}\]</span> (fill in the question marks)</p></li>
<li><p>If <span class="math inline">\(|\lambda_1| &gt; |\lambda_2| \ge |\lambda_3| \ge \cdots \ge |\lambda_n|\)</span> then what happens to each of the <span class="math inline">\((\lambda_j/\lambda_1)^k\)</span> terms as <span class="math inline">\(k \to \infty\)</span>?</p></li>
<li><p>Using your answer to part (c), what is <span class="math inline">\(\lim_{k \to \infty} A^k \boldsymbol{x} / \lambda_1^k\)</span>?</p></li>
</ol>
</div>
<hr>
<div id="thm-4.5" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.4 (The Power Method)</strong></span> The following algorithm, called <strong>the power method</strong> will quickly find the eigenvalue of largest absolute value for a square matrix <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> as well as the associated (normalized) eigenvector. We are assuming that there are <span class="math inline">\(n\)</span> linearly independent eigenvectors of <span class="math inline">\(A\)</span>.</p>
<dl>
<dt><strong>Step 1:</strong></dt>
<dd>
<p>Given a non-zero vector <span class="math inline">\(\boldsymbol{x}\)</span>, set <span class="math inline">\(\boldsymbol{v}^{(1)} = \boldsymbol{x} / \|\boldsymbol{x}\|\)</span>. (Here the superscript indicates the iteration number) Note that the initial vector <span class="math inline">\(\boldsymbol{x}\)</span> is pretty irrelevant to the process so it can just be a random vector of the correct size..</p>
</dd>
<dt><strong>Step 2:</strong></dt>
<dd>
<p>For <span class="math inline">\(k=2, 3, \ldots\)</span></p>
<dl>
<dt><strong>Step 2a:</strong></dt>
<dd>
<p>Compute <span class="math inline">\(\tilde{\boldsymbol{v}}^{(k)} = A \boldsymbol{v}^{(k-1)}\)</span> (this gives a non-normalized version of the next estimate of the dominant eigenvector.)</p>
</dd>
<dt><strong>Step 2b:</strong></dt>
<dd>
<p>Set <span class="math inline">\(\lambda^{(k)} = \tilde{\boldsymbol{v}}^{(k)} \cdot \boldsymbol{v}^{(k-1)}\)</span>. (this gives an approximation of the eigenvalue since if <span class="math inline">\(\boldsymbol{v}^{(k-1)}\)</span> was the actual eigenvector we would have <span class="math inline">\(\lambda = A \boldsymbol{v}^{(k-1)} \cdot \boldsymbol{v}^{(k-1)}\)</span>. Stop now and explain this.)</p>
</dd>
<dt><strong>Step 2c:</strong></dt>
<dd>
<p>Normalize <span class="math inline">\(\tilde{\boldsymbol{v}}^{(k)}\)</span> by computing <span class="math inline">\(\boldsymbol{v}^{(k)} = \tilde{\boldsymbol{v}}^{(k)} / \| \tilde{\boldsymbol{v}}^{(k)} \|\)</span>. (This guarantees that you will be sending a unit vector into the next iteration of the loop)</p>
</dd>
</dl>
</dd>
</dl>
</div>
<hr>
<div id="exr-4.61" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.59</strong></span> Go through <a href="#thm-4.5" class="quarto-xref">Theorem&nbsp;<span>C.4</span></a> carefully and describe what we need to do in each step and why we are doing it. Then complete all of the missing pieces of the following Python function.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> myPower(A, tol <span class="op">=</span> <span class="fl">1e-8</span>):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> A.shape[<span class="dv">0</span>]</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.random.randn(n)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="co"># turn x into a unit vector</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we do not actually need to keep track of the old iterates</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> <span class="dv">1</span> <span class="co"># initialize the dominant eigenvalue</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> <span class="dv">0</span> <span class="co"># keep track of how many steps we have taken</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You can build a stopping rule from the definition</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ax = lambda x ... </span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> (???) <span class="op">&gt;</span> tol <span class="kw">and</span> counter <span class="op">&lt;</span> <span class="dv">10000</span>:</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> A <span class="op">@</span> x <span class="co"># update the dominant eigenvector</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> ??? <span class="co"># normalize</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        L <span class="op">=</span> ??? <span class="co"># approximate the eignevalue</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        counter <span class="op">+=</span> <span class="dv">1</span> <span class="co"># increment the counter</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, L</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.62" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.60</strong></span> Test your <code>myPower()</code> function on several matrices where you know the eigenstructure. Then try the <code>myPower()</code> function on larger random matrices. You can check that it is working using <code>np.linalg.eig()</code> (be sure to normalize the vectors in the same way so you can compare them.)</p>
</div>
<hr>
<div id="exr-4.63" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.61</strong></span> In the Power Method iteration you may end up getting a different sign on your eigenvector as compared to <code>np.linalg.eig()</code>. Why might this happen? Generate a few examples so you can see this. You can avoid this issue if you use a <code>while</code> loop in your Power Method code and the logical check takes advantage of the fact that we are trying to solve the equation <span class="math inline">\(A\boldsymbol{x} = \lambda \boldsymbol{x}\)</span>. Hint: <span class="math inline">\(A\boldsymbol{x} = \lambda \boldsymbol{x}\)</span> is equivalent to <span class="math inline">\(A\boldsymbol{x} - \lambda \boldsymbol{x} = \boldsymbol{0}\)</span>.</p>
</div>
<hr>
<div id="exr-4.64" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.62</strong></span> What happens in the power method iterations when <span class="math inline">\(\lambda_1\)</span> is complex. The maximum eigenvalue can certainly be complex if <span class="math inline">\(|\lambda_1|\)</span> (the modulus of the complex number) is larger than all of the other eigenvalues. It may be helpful to build a matrix specifically with complex eigenvalues.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
</div>
<hr>
<div id="exr-4.65" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.63 (Convergence Rate of the Power Method)</strong></span> The proof that the power method will work hinges on the fact that <span class="math inline">\(|\lambda_1| &gt; |\lambda_2| \geq |\lambda_3| \geq \cdots \geq |\lambda_n|\)</span>. In <a href="#exr-4.60" class="quarto-xref">Exercise&nbsp;<span>C.58</span></a> we proved that the limit <span class="math display">\[\begin{equation}
\lim_{k \to \infty} \frac{A^k \boldsymbol{x}}{\lambda_1^k}
\end{equation}\]</span> converges to the dominant eigenvector, but how fast is the convergence? What does the speed of the convergence depend on?</p>
<p>Take note that since we are assuming that the eigenvalues are ordered, the ratio <span class="math inline">\(\lambda_2 / \lambda_1\)</span> will be larger than <span class="math inline">\(\lambda_j / \lambda_1\)</span> for all <span class="math inline">\(j&gt;2\)</span>. Hence, the speed at which the power method converges depends mostly on the ratio <span class="math inline">\(\lambda_2 / \lambda_1\)</span>. Let us build a numerical experiment to see how sensitive the power method is to this ratio.</p>
<p>Build a <span class="math inline">\(4 \times 4\)</span> matrix <span class="math inline">\(A\)</span> with dominant eigenvalue <span class="math inline">\(\lambda_1 = 1\)</span> and all other eigenvalues less than 1 in absolute value. Then choose several values of <span class="math inline">\(\lambda_2\)</span> and build an experiment to determine the number of iterations that it takes for the power method to converge to within a pre-determined tolerance to the dominant eigenvector. In the end you should produce a plot with the ratio <span class="math inline">\(\lambda_2 / \lambda_1\)</span> on the horizontal axis and the number of iterations to converge to a fixed tolerance on the vertical axis. Discuss what you see in your plot.</p>
<p>Hint: To build a matrix with specific eigen-structure use the matrix factorization <span class="math inline">\(A = PDP^{-1}\)</span> where the columns of <span class="math inline">\(P\)</span> contain the eigenvectors of <span class="math inline">\(A\)</span> and the diagonal of <span class="math inline">\(D\)</span> contains the eigenvalues. In this case the <span class="math inline">\(P\)</span> matrix can be random but you need to control the <span class="math inline">\(D\)</span> matrix. Moreover, remember that <span class="math inline">\(\lambda_3\)</span> and <span class="math inline">\(\lambda_4\)</span> should be smaller than <span class="math inline">\(\lambda_2\)</span>.</p>
</div>
</section>
<section id="algorithm-summaries" class="level2" data-number="C.9">
<h2 data-number="C.9" class="anchored" data-anchor-id="algorithm-summaries"><span class="header-section-number">C.9</span> Algorithm Summaries</h2>
<div id="exr-4.66" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.64</strong></span> Explain in clear language how to efficiently solve an upper-triangular system of linear equations.</p>
</div>
<hr>
<div id="exr-4.67" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.65</strong></span> Explain in clear language how to efficiently solve a lower-triangular system of linear equations.</p>
</div>
<hr>
<div id="exr-4.68" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.66</strong></span> Explain in clear language how to solve the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> using an <span class="math inline">\(LU\)</span> decomposition.</p>
</div>
<hr>
<div id="exr-4.69" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.67</strong></span> Explain in clear language how to solve an overdetermined system of linear equations (more equations than unknowns) numerically.</p>
</div>
<hr>
<div id="exr-4.70" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.68</strong></span> Explain in clear language the algorithm for finding the columns of the <span class="math inline">\(Q\)</span> matrix in the <span class="math inline">\(QR\)</span> factorization. Give all of the mathematical details.</p>
</div>
<hr>
<div id="exr-4.71" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.69</strong></span> Explain in clear language how to find the upper-triangular matrix <span class="math inline">\(R\)</span> in the <span class="math inline">\(QR\)</span> factorization. Give all of the mathematical details.</p>
</div>
<hr>
<div id="exr-4.72" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.70</strong></span> Explain in clear language how to solve the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> using a <span class="math inline">\(QR\)</span> decomposition.</p>
</div>
<hr>
<div id="exr-4.73" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.71</strong></span> Explain in clear language how the power method works to find the dominant eigenvalue and eigenvector of a square matrix. Give all of the mathematical details.</p>
</div>
<hr>
</section>
<section id="problems" class="level2" data-number="C.10">
<h2 data-number="C.10" class="anchored" data-anchor-id="problems"><span class="header-section-number">C.10</span> Problems</h2>
<div id="exr-4.74" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.72</strong></span> As mentioned much earlier in this chapter, there is an <code>rref()</code> command in Python, but it is in the <code>sympy</code> library instead of the <code>numpy</code> library – it is implemented as a symbolic computation instead of a numerical computation. OK. So what? In this problem we want to compare the time to solve a system of equations <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> with each of the following techniques:</p>
<ul>
<li><p>row reduction of an augmented matrix <span class="math inline">\(\begin{pmatrix} A &amp; | &amp; b\end{pmatrix}\)</span> with <code>sympy</code>,</p></li>
<li><p>our implementation of the <span class="math inline">\(LU\)</span> decomposition,</p></li>
<li><p>our implementation of the <span class="math inline">\(QR\)</span> decomposition, and</p></li>
<li><p>the <code>numpy.linalg.solve()</code> command.</p></li>
</ul>
<p>To time code in Python first import the <code>time</code> library. Then use <code>start = time.time()</code> at the start of your code and <code>stop = time.time()</code> and the end of your code. The difference between <code>stop</code> and <code>start</code> is the elapsed computation time.</p>
<p>Make observations about how the algorithms perform for different sized matrices. You can use random matrices and vectors for <span class="math inline">\(A\)</span> and <span class="math inline">\(\boldsymbol{b}\)</span>. The end result should be a plot showing how the average computation time for each algorithm behaves as a function of the size of the coefficient matrix.</p>
<p>The code below will compute the reduced row echelon form of a matrix (RREF). Implement the code so that you know how it works.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sympy <span class="im">as</span> sp</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># in this problem it will be easiest to start with numpy matrices</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>]])</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([[<span class="dv">3</span>],[<span class="dv">7</span>],[<span class="dv">3</span>]])</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>Augmented <span class="op">=</span> np.c_[A,b] <span class="co"># augment b onto the right hand side of A</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>Msymbolic <span class="op">=</span> sp.Matrix(Augmented)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>MsymbolicRREF <span class="op">=</span> Msymbolic.rref()</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(MsymbolicRREF)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>To time code you can use code like the following.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># some code that you want to time</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>stop <span class="op">=</span>  time.time()</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>total_time <span class="op">=</span> stop <span class="op">-</span> start</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Total computation time="</span>,total_time)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.75" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.73</strong></span> Imagine that we have a 1 meter long thin metal rod that has been heated to 100<span class="math inline">\(^\circ\)</span> on the left-hand side and cooled to 0<span class="math inline">\(^\circ\)</span> on the right-hand side. We want to know the temperature every 10 cm from left to right on the rod.</p>
<ol type="1">
<li><p>First we break the rod into equal 10cm increments as shown. See <a href="#fig-4.2" class="quarto-xref">Figure&nbsp;<span>C.2</span></a>. How many unknowns are there in this picture?</p></li>
<li><p>The temperature at each point along the rod is the average of the temperatures at the adjacent points. For example, if we let <span class="math inline">\(T_1\)</span> be the temperature at point <span class="math inline">\(x_1\)</span> then <span class="math display">\[\begin{equation}
T_1 = \frac{T_0 + T_2}{2}.
\end{equation}\]</span> Write a system of equations for each of the unknown temperatures.</p></li>
<li><p>Solve the system for the temperature at each unknown node using either <span class="math inline">\(LU\)</span> or <span class="math inline">\(QR\)</span> decomposition.</p></li>
</ol>
<div id="fig-4.2" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://numericalmethodssullivan.github.io/images/Ch04_HeatedRod.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.2: A rod to be heated broken into 10 equal-length segments.
</figcaption>
</figure>
</div>
</div>
<hr>
<div id="exr-4.76" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.74</strong></span> Write code to solve the following systems of equations via both LU and QR decompositions. If the algorithm fails then be sure to explain exactly why.</p>
<ol type="1">
<li><p><span class="math display">\[\begin{equation}
\begin{array}{rl} x + 2y + 3z &amp;= 4 \\ 2x + 4y + 3z &amp;= 5 \\ x + y &amp;= 4 \end{array}
\end{equation}\]</span></p></li>
<li><p><span class="math display">\[\begin{equation}
\begin{array}{rl} 2y + 3z &amp;= 4 \\ 2x + 3z &amp;= 5 \\ y &amp;= 4 \end{array}
\end{equation}\]</span></p></li>
<li><p><span class="math display">\[\begin{equation}
\begin{array}{rl} 2y + 3z &amp;= 4 \\ 2x + 4y + 3z &amp;= 5 \\ x+y &amp;= 4 \end{array}
\end{equation}\]</span></p></li>
</ol>
</div>
<hr>
<div id="exr-4.77" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.75</strong></span> Give a specific example of a non-zero matrix which will NOT have an <span class="math inline">\(LU\)</span> decomposition. Give specific reasons why <span class="math inline">\(LU\)</span> will fail on your matrix.</p>
</div>
<hr>
<div id="exr-4.78" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.76</strong></span> Give a specific example of a non-zero matrix which will NOT have an <span class="math inline">\(QR\)</span> decomposition. Give specific reasons why <span class="math inline">\(QR\)</span> will fail on your matrix.</p>
</div>
<hr>
<div id="exr-4.79" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.77</strong></span> Have you ever wondered how scientific software computes a determinant? The formula that you learned for <a href="https://en.wikipedia.org/wiki/Determinant">calculating determinants by hand</a> is horribly cumbersome and computationally intractable for large matrices. This problem is meant to give you glimpse of what is <em>actually</em> going on under the hood.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>If <span class="math inline">\(A\)</span> has an <span class="math inline">\(LU\)</span> decomposition then <span class="math inline">\(A = LU\)</span>. Use properties that you know about determinants to come up with a simple way to find the determinant for matrices that have an <span class="math inline">\(LU\)</span> decomposition. Show all of your work in developing your formula.</p>
<p>Once you have your formula for calculating <span class="math inline">\(\det(A)\)</span>, write a Python function that accepts a matrix, produces the <span class="math inline">\(LU\)</span> decomposition, and returns the determinant of <span class="math inline">\(A\)</span>. Check your work against Python’s <code>np.linalg.det()</code> function.</p>
</div>
<hr>
<div id="exr-4.80" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.78</strong></span> For this problem we are going to run a numerical experiment to see how the process of solving the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> using the <span class="math inline">\(LU\)</span> factorization performs on random coefficient matrices <span class="math inline">\(A\)</span> and random right-hand sides <span class="math inline">\(\boldsymbol{b}\)</span>. We will compare against Python’s algorithm for solving linear systems.</p>
<p>We will do the following:</p>
<p>Create a loop that does the following:</p>
<ol type="1">
<li><p>Loop over the size of the matrix <span class="math inline">\(n\)</span>.</p></li>
<li><p>Build a random matrix <span class="math inline">\(A\)</span> of size <span class="math inline">\(n \times n\)</span>. You can do this with the code <code>A = np.random.randn(n,n)</code></p></li>
<li><p>Build a random vector <span class="math inline">\(\boldsymbol{b}\)</span> in <span class="math inline">\(\mathbb{R}^{n}\)</span>. You can do this with the code <code>b = np.random.randn(n)</code></p></li>
<li><p>Find Python’s answer to the problem <span class="math inline">\(A\boldsymbol{x}=\boldsymbol{b}\)</span> =0 using the command <code>exact = np.linalg.solve(A,b)</code></p></li>
<li><p>Write code that uses your three <span class="math inline">\(LU\)</span> functions (<code>myLU</code>, <code>lsolve</code>, <code>usolve</code>) to find a solution to the equation <span class="math inline">\(A\boldsymbol{x}=\boldsymbol{b}\)</span>.</p></li>
<li><p>Find the error between your answer and the exact answer using the code <code>np.linalg.norm(x - exact)</code></p></li>
<li><p>Make a plot (<code>plt.semilogy()</code>) that shows how the error behaves as the size of the problem changes. You should run this for matrices of larger and larger size but be warned that the loop will run for quite a long time if you go above <span class="math inline">\(300 \times 300\)</span> matrices. Just be patient.</p></li>
</ol>
<p><strong>Conclusions:</strong> What do you notice in your final plot. What does this tell you about the behaviour of our <span class="math inline">\(LU\)</span> decomposition code?</p>
</div>
<hr>
<div id="exr-4.81" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.79</strong></span> Repeat <a href="#exr-4.80" class="quarto-xref">Exercise&nbsp;<span>C.78</span></a> for the <span class="math inline">\(QR\)</span> decomposition. Your final plot should show both the behaviour of <span class="math inline">\(QR\)</span> and of <span class="math inline">\(LU\)</span> throughout the experiment. What do you notice?</p>
</div>
<hr>
<div id="exr-4.82" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.80</strong></span> Find a least squares solution to the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> in two different ways with <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 4 &amp; -2 &amp; 6 \\ 4 &amp; 7 &amp; 8 \\ 3 &amp; 7 &amp; 19 \end{pmatrix} \quad \text{and} \quad \boldsymbol{b} = \begin{pmatrix} 5 \\ 2 \\ -2 \\ 8\end{pmatrix}.
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.83" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.81</strong></span> Let <span class="math inline">\(A\)</span> be defined as <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 10^{-20} &amp; 1 \\ 1 &amp; 1 \end{pmatrix}
\end{equation}\]</span> and let <span class="math inline">\(\boldsymbol{b}\)</span> be the vector <span class="math display">\[\begin{equation}
\boldsymbol{b}=\begin{pmatrix} 2 \\ 3\end{pmatrix}.
\end{equation}\]</span><br>
Notice that <span class="math inline">\(A\)</span> has a tiny, but non-zero, value in the first entry.</p>
<ol type="1">
<li><p>Solve the linear system <span class="math inline">\(A \boldsymbol{x}=\boldsymbol{b}\)</span> by hand.</p></li>
<li><p>Use your <code>myLU</code>, <code>lsolve</code>, and <code>usolve</code> functions to solve this problem using the LU decomposition method.</p></li>
<li><p>Compare your answers to parts (a) and (b). What went wrong?</p></li>
</ol>
</div>
<hr>
<div id="exr-4.84" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.82 (Hilbert Matrices)</strong></span> A Hilbert Matrix is a matrix of the form <span class="math inline">\(H_{ij} = 1 / (i+j+1)\)</span> where both <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> both start indexed at <span class="math inline">\(0\)</span>. For example, a <span class="math inline">\(4 \times 4\)</span> Hilbert Matrix is <span class="math display">\[\begin{equation}
H = \begin{pmatrix} 1 &amp; \frac{1}{2} &amp; \frac{1}{3} &amp; \frac{1}{4} \\ \frac{1}{2} &amp; \frac{1}{3} &amp; \frac{1}{4} &amp; \frac{1}{5} \\ \frac{1}{3} &amp; \frac{1}{4} &amp; \frac{1}{5} &amp; \frac{1}{6} \\ \frac{1}{4} &amp; \frac{1}{5} &amp; \frac{1}{6} &amp; \frac{1}{7} \end{pmatrix}.
\end{equation}\]</span> This type of matrix is often used to test numerical linear algebra algorithms since it is known to have some <em>odd</em> behaviours … which you will see in a moment.</p>
<ol type="1">
<li><p>Write code to build a <span class="math inline">\(n\times n\)</span> Hilbert Matrix and call this matrix <span class="math inline">\(H\)</span>. Test your code for various values of <span class="math inline">\(n\)</span> to be sure that it is building the correct matrices.</p></li>
<li><p>Build a vector of ones called <span class="math inline">\(\boldsymbol{b}\)</span> with code <code>b = np.ones((n,1))</code>. We will use <span class="math inline">\(\boldsymbol{b}\)</span> as the right hand side of the system of equations <span class="math inline">\(H\boldsymbol{x} = \boldsymbol{b}\)</span>.</p></li>
<li><p>Solve the system of equations <span class="math inline">\(H \boldsymbol{x} = \boldsymbol{b}\)</span> using any technique you like from this chapter.</p></li>
<li><p>Now let us say that you change the first entry of <span class="math inline">\(\boldsymbol{b}\)</span> by just a little bit, say <span class="math inline">\(10^{-15}\)</span>. If we were to now solve the equation <span class="math inline">\(H \boldsymbol{x}_{new} = \boldsymbol{b}_{new}\)</span> what would you expect as compared to solving <span class="math inline">\(H \boldsymbol{x} = \boldsymbol{b}\)</span>.</p></li>
<li><p>Now let us actually make the change suggested in part (d). Use the code <code>bnew = np.ones((n,1))</code> and then <code>bnew[0] = bnew[0] + 1e-15</code> to build a new <span class="math inline">\(\boldsymbol{b}\)</span> vector with this small change. Solve <span class="math inline">\(H\boldsymbol{x}=\boldsymbol{b}\)</span> and <span class="math inline">\(H\boldsymbol{x}_{new}=\boldsymbol{b}_{new}\)</span> and then compare the maximum absolute difference <code>np.max(np.abs(x - xnew))</code>. What do you notice? Make a plot with <span class="math inline">\(n\)</span> on the horizontal axis and the maximum absolute difference on the vertical axis. What does this plot tell you about the solution to the equation <span class="math inline">\(H \boldsymbol{x} = \boldsymbol{b}\)</span>?</p></li>
<li><p>We know that <span class="math inline">\(H H^{-1}\)</span> should be the identity matrix. As we will see, however, Hilbert matrices are particularly poorly behaved! Write a loop over <span class="math inline">\(n\)</span> that (i) builds a Hilbert matrix of size <span class="math inline">\(n\)</span>, (ii) calculates <span class="math inline">\(H H^{-1}\)</span> (using <code>np.linalg.inv()</code> to compute the inverse directly), (iii) calculates the norm of the difference between the identity matrix (<code>np.identity(n)</code>) and your calculated identity matrix from part (ii). Finally. Build a plot that shows <span class="math inline">\(n\)</span> on the horizontal axis and the normed difference on the vertical axis. What do you see? What does this mean about the matrix inversion of the Hilbert matrix.</p></li>
<li><p>There are cautionary tales hiding in this problem. Write a paragraph explaining what you can learn by playing with pathological matrices like the Hilbert Matrix.</p></li>
</ol>
</div>
<hr>
<div id="exr-4.85" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.83</strong></span> Now that you have <span class="math inline">\(QR\)</span> and <span class="math inline">\(LU\)</span> code we are going to use both of them! The problem is as follows:<br>
We are going to find the polynomial of degree 4 that best fits the function <span class="math display">\[\begin{equation}
y = \cos(4t) + 0.1 \varepsilon(t)
\end{equation}\]</span> at 50 equally spaced points <span class="math inline">\(t\)</span> between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. Here we are using <span class="math inline">\(\varepsilon(t)\)</span> as a function that outputs normally distributed random white noise. In Python you will build <span class="math inline">\(y\)</span> as <code>y = np.cos(4*t) + 0.1*np.random.randn(t.shape[0])</code></p>
<p>Build the <span class="math inline">\(t\)</span> vector and the <span class="math inline">\(y\)</span> vector (these are your data). We need to set up the least squares problems <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> by setting up the matrix <span class="math inline">\(A\)</span> as we did in the other least squares curve fitting problems and by setting up the <span class="math inline">\(\boldsymbol{b}\)</span> vector using the <span class="math inline">\(y\)</span> data you just built. Solve the problem of finding the coefficients of the best degree 4 polynomial that fits this data. Report the sum of squared error and show a plot of the data along with the best fit curve.</p>
</div>
<hr>
<div id="exr-4.86" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.84</strong></span> Find the largest eigenvalue and the associated eigenvector of the matrix <span class="math inline">\(A\)</span> WITHOUT using <code>np.linalg.eig()</code>. (Do not do this by hand either) <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 4 \\ 5 &amp; 6 &amp; 7 &amp; 8 \\ 9 &amp; 0 &amp; 1 &amp; 2 \\ 3 &amp; 4 &amp; 5 &amp; 6 \end{pmatrix}
\end{equation}\]</span></p>
</div>
<hr>
<div id="exr-4.87" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.85</strong></span> It is possible in a matrix that the eigenvalues <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span> are equal but with the corresponding eigenvectors not equal. Before you experiment with matrices of this sort, write a conjecture about what will happen to the power method in this case (look back to our proof in <a href="#exr-4.60" class="quarto-xref">Exercise&nbsp;<span>C.58</span></a> of how the power method works). Now build several specific matrices where this is the case and see what happens to the power method.</p>
</div>
<hr>
<div id="exr-4.88" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.86</strong></span> Will the power method fail, slow down, or be unaffected if one (or more) of the non-dominant eigenvalues is zero? Give sufficient mathematical evidence or show several numerical experiments to support your answer.</p>
</div>
<hr>
<div id="thm-4.6" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.5</strong></span> If <span class="math inline">\(A\)</span> is a symmetric matrix with eigenvalues <span class="math inline">\(\lambda_1, \lambda_2, \ldots, \lambda_n\)</span> then <span class="math inline">\(|\lambda_1| &gt; |\lambda_2| &gt; \cdots &gt; |\lambda_n|\)</span>. Furthermore, the eigenvectors will be orthogonal to each other.</p>
</div>
<hr>
<div id="exr-4.90" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.87 (The Deflation Method)</strong></span> For symmetric matrices we can build an extension to the power method in order to find the second most dominant eigen-pair for a matrix <span class="math inline">\(A\)</span>. <a href="#thm-4.6" class="quarto-xref">Theorem&nbsp;<span>C.5</span></a> suggests the following method for finding the second dominant eigen-pair for a symmetric matrix. This method is called the <strong>deflation method</strong>.</p>
<ul>
<li><p>Use the power method to find the dominant eigenvalue and eigenvector.</p></li>
<li><p>Start with a random unit vector of the correct shape.</p></li>
<li><p>Multiplying your vector by <span class="math inline">\(A\)</span> will <em>pull it toward</em> the dominant eigenvector. After you multiply, project your vector onto the dominant eigenvector and find the projection error.</p></li>
<li><p>Use the projection error as the new approximation for the eigenvector (Why should we do this? What are we really finding here?)</p></li>
</ul>
<p>Note that the deflation method is really exactly the same as the power method with the exception that we orthogonalize at every step. Hence, when you write your code expect to only change a few lines from your power method.</p>
<p>Write a function to find the second largest eigenvalue and eigenvector pair by putting the deflation method into practice. Test your code on a matrix <span class="math inline">\(A\)</span> and compare against Python’s <code>np.linalg.eig()</code> command. Your code needs to work on symmetric matrices of arbitrary size and you need to write test code that clearly shows the error between your calculated eigenvalue and Python’s eigenvalue as well as your calculated eigenvector and ’s eigenvector.</p>
<p>To guarantee that you start with a symmetric matrix you can use the following code.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">40</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(N,N)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># A = np.matrix(A) # No need for matrix class</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.transpose(A) <span class="op">@</span> A <span class="co"># why should this build a symmetric matrix</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
<div id="exr-4.91" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.88</strong></span> (This concept for this problem is modified from <span class="citation" data-cites="Meerschaert">(<a href="#ref-Meerschaert" role="doc-biblioref">Meerschaert 2013</a>)</span>). The data is taken from <a href="https://www.weather.gov/arx/mississippi_river">NOAA and the National Weather Service</a> with the specific values associated with La Crosse, WI.)</p>
<p>Floods in the Mississippi River Valleys of the upper Midwest have somewhat predictable day-to-day behaviour in that the flood stage today has high predictive power for the flood stage tomorrow. Assume that the flood stages are:</p>
<ul>
<li><p>Stage 0 (Normal): Average daily flow is below 90,000 <span class="math inline">\(ft^3/sec\)</span> (cubic feet per second = cfs). This is the <em>normal</em> river level.</p></li>
<li><p>Stage 1 (Action Level): Average daily flow is between 90,000 cfs and 124,000 cfs.</p></li>
<li><p>Stage 2 (Minor Flood): Average daily flow is between 124,000 cfs and 146,000 cfs.</p></li>
<li><p>Stage 3 (Moderate Flood): Average daily flow is between 146,000 cfs and 170,000 cfs.</p></li>
<li><p>Stage 4 (Extreme Flood): Average daily flow is above 170,000 cfs.</p></li>
</ul>
<p>The following table shows the probability of one stage transitioning into another stage from one day to the next.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>0 Today</strong></th>
<th><strong>1 Today</strong></th>
<th><strong>2 Today</strong></th>
<th><strong>3 Today</strong></th>
<th><strong>4 Today</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0 Tomorrow</td>
<td>0.9</td>
<td>0.3</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>1 Tomorrow</td>
<td>0.05</td>
<td>0.7</td>
<td>0.4</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2 Tomorrow</td>
<td>0.025</td>
<td>0</td>
<td>0.6</td>
<td>0.6</td>
<td>0</td>
</tr>
<tr class="even">
<td>3 Tomorrow</td>
<td>0.015</td>
<td>0</td>
<td>0</td>
<td>0.4</td>
<td>0.8</td>
</tr>
<tr class="odd">
<td>4 Tomorrow</td>
<td>0.01</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>Mathematically, if <span class="math inline">\(\boldsymbol{s}_k\)</span> is the state at day <span class="math inline">\(k\)</span> and <span class="math inline">\(A\)</span> is the matrix given in the table above then the difference equation <span class="math inline">\(\boldsymbol{s}_{k+1} = A \boldsymbol{s}_k\)</span> shows how a state will transition from day to day. For example, if we are currently in Stage 0 then <span class="math display">\[\begin{equation}
\boldsymbol{s}_0 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}.
\end{equation}\]</span> We can interpret this as “<em>there is a probability of 1 that we are in Stage 0 today and there is a probability of 0 that we are in any other stage today.</em>”</p>
<p>If we want to advance this model forward in time then we just need to iterate. In our example, the state tomorrow would be <span class="math inline">\(\boldsymbol{s}_1 = A \boldsymbol{s}_0\)</span>. The state two days from now would be <span class="math inline">\(\boldsymbol{s}_2 = A \boldsymbol{s}_1\)</span>, and if we use the expression for <span class="math inline">\(\boldsymbol{s}_1\)</span> we can simplify to <span class="math inline">\(\boldsymbol{s}_2 = A^2 \boldsymbol{s}_0\)</span>.</p>
<ol type="1">
<li><p>Prove that the state at day <span class="math inline">\(n\)</span> is <span class="math inline">\(\boldsymbol{s}_n = A^n \boldsymbol{s}_0\)</span>.</p></li>
<li><p>If <span class="math inline">\(n\)</span> is large then the steady state solution to the difference equation in part (1) is given exactly by the power method iteration that we have studied in this chapter. Hence, as the iterations proceed they will be pulled toward the dominant eigenvector. Use the power method to find the dominant eigenvector of the matrix <span class="math inline">\(A\)</span>.</p></li>
<li><p>The vectors in this problem are called <strong>probability vectors</strong> in the sense that the vectors sum to 1 and every entry can be interpreted as a probability. Re-scale your answer from part (b) so that we can interpret the entries as probabilities. That is, ensure that the sum of the vector from part (b) is 1.</p></li>
<li><p>Interpret your answer to part (c) in the context of the problem. Be sure that your interpretation could be well understood by someone that does not know the mathematics that you just did.</p></li>
</ol>
</div>
<hr>
<div id="exr-4.92" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.89</strong></span> The <span class="math inline">\(LU\)</span> factorization as we have built it in this chapter is not <em>smart</em> about the way that it uses the memory on your computer. In the <span class="math inline">\(LU\)</span> factorization the 1’s on the main diagonal do not actually need to be stored since we know that they will always be there. The zeros in the lower triangle of <span class="math inline">\(U\)</span> do not need to be stored either. If you store the upper triangle values in the <span class="math inline">\(U\)</span> matrix on top of the upper triangle of the <span class="math inline">\(L\)</span> matrix then we still store a full matrix for <span class="math inline">\(L\)</span> which contains both <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> simultaneously, but we do not have to store <span class="math inline">\(U\)</span> separately and hence save computer memory. The modifications to the existing code for an <span class="math inline">\(LU\)</span> solve is minimal – every time you call on an entry of the <span class="math inline">\(U\)</span> matrix it is stored in the upper triangle of <span class="math inline">\(L\)</span> instead. Write code to implement this new data storage idea and demonstrate your code on a few examples.</p>
</div>
<hr>
<div id="exr-4.93" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.90</strong></span> In the algorithm that we used to build the <span class="math inline">\(QR\)</span> factorization we built the <span class="math inline">\(R\)</span> matrix as <span class="math inline">\(R = Q^T A\)</span> The trouble with this step is that it fills in a lot of redundant zeros into the <span class="math inline">\(R\)</span> matrix – some of which may not be exactly zero. First explain why this will be the case. Then rewrite your <span class="math inline">\(QR\)</span> factorization code so that the top triangle of <span class="math inline">\(R\)</span> is filled with all of the projections (do this with a double <code>for</code> loop). Demonstrate that your code works on a few examples.</p>
</div>
</section>
<section id="projects" class="level2" data-number="C.11">
<h2 data-number="C.11" class="anchored" data-anchor-id="projects"><span class="header-section-number">C.11</span> Projects</h2>
<p>In this section we propose several ideas for projects related to numerical linear algebra. These projects are meant to be open ended, to encourage creative mathematics, to push your coding skills, and to require you to write and communicate your mathematics.</p>
<section id="the-google-page-rank-algorithm" class="level3" data-number="C.11.1">
<h3 data-number="C.11.1" class="anchored" data-anchor-id="the-google-page-rank-algorithm"><span class="header-section-number">C.11.1</span> The Google Page Rank Algorithm</h3>
<p>In this project you will discover how the Page Rank algorithm works to give the most relevant information as the top hit on a Google search.</p>
<p>Search engines compile large indexes of the dynamic information on the Internet so they are easily searched. This means that when you do a Google search, you are not actually searching the Internet; instead, you are searching the indexes at Google.</p>
<p>When you type a query into Google the following two steps take place:</p>
<ol type="1">
<li><p>Query Module: The query module at Google converts your natural language into a language that the search system can understand and consults the various indexes at Google in order to answer the query. This is done to find the list of relevant pages.</p></li>
<li><p>Ranking Module: The ranking module takes the set of relevant pages and ranks them. The outcome of the ranking is an ordered list of web pages such that the pages near the top of the list are most likely to be what you desire from your search. This ranking is the same as assigning a <em>popularity score</em> to each web site and then listing the relevant sites by this score.</p></li>
</ol>
<p>This section focuses on the Linear Algebra behind the Ranking Module developed by the founders of Google: Sergey Brin and Larry Page. Their algorithm is called the <em>Page Rank algorithm</em>, and you use it every single time you use Google’s search engine.</p>
<p>In simple terms: <em>A webpage is important if it is pointed to by other important pages</em>.</p>
<p>The Internet can be viewed as a directed graph (look up this term <a href="https://en.wikipedia.org/wiki/Directed_graph">here on Wikipedia</a>) where the nodes are the web pages and the edges are the hyperlinks between the pages. The hyperlinks into a page are called <em>in links</em>, and the ones pointing out of a page are called <em>out links</em>. In essence, a hyperlink from my page to yours is my endorsement of your page. Thus, a page with more recommendations must be more important than a page with a few links. However, the status of the recommendation is also important.</p>
<p>Let us now translate this into mathematics. To help understand this we first consider the small web of six pages shown in <a href="#fig-4.3" class="quarto-xref">Figure&nbsp;<span>C.3</span></a> (a graph of the router level of the internet can be found <a href="https://personalpages.manchester.ac.uk/staff/m.dodge/cybergeography/atlas/lumeta_large.jpg">here</a>). The links between the pages are shown by arrows. An arrow pointing into a node is an <em>in link</em> and an arrow pointing out of a node is an <em>out link</em>. In <a href="#fig-4.3" class="quarto-xref">Figure&nbsp;<span>C.3</span></a>, node 3 has three out links (to nodes 1, 2, and 5) and 1 in link (from node 1).</p>
<div id="fig-4.3" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://numericalmethodssullivan.github.io/images/Ch04_GoogleGraph1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.3: Example web graph.
</figcaption>
</figure>
</div>
<p>We will first define some notation in the Page Rank algorithm:</p>
<ul>
<li><p><span class="math inline">\(|P_i|\)</span> is the number of out links from page <span class="math inline">\(P_i\)</span></p></li>
<li><p><span class="math inline">\(H\)</span> is the <em>hyperlink</em> matrix defined as <span class="math display">\[\begin{equation}
H_{ij} = \left\{ \begin{array}{cl} \frac{1}{|P_j|}, &amp; \text{if there is a link from node $j$ to node $i$} \\ 0, &amp; \text{otherwise} \end{array} \right.
\end{equation}\]</span> where the “<span class="math inline">\(i\)</span>” and “<span class="math inline">\(j\)</span>” are the row and column indices respectively.</p></li>
<li><p><span class="math inline">\(\boldsymbol{x}\)</span> is a vector that contains all of the Page Ranks for the individual pages.</p></li>
</ul>
<p>The Page Rank algorithm works as follows:</p>
<ol type="1">
<li><p>Initialize the page ranks to all be equal. This means that our initial assumption is that all pages are of equal rank. In the case of <a href="#fig-4.3" class="quarto-xref">Figure&nbsp;<span>C.3</span></a> we would take <span class="math inline">\(\boldsymbol{x}_0\)</span> to be <span class="math display">\[\begin{equation}
\boldsymbol{x}_0 = \begin{pmatrix} 1/6 \\ 1/6 \\ 1/6 \\ 1/6 \\ 1/6 \\ 1/6 \end{pmatrix}.
\end{equation}\]</span></p></li>
<li><p>Build the hyperlink matrix.<br>
As an example we will consider node 3 in <a href="#fig-4.3" class="quarto-xref">Figure&nbsp;<span>C.3</span></a>. There are three out links from node 3 (to nodes 1, 2, and 5). Hence <span class="math inline">\(H_{13}=1/3\)</span>, <span class="math inline">\(H_{23} = 1/3\)</span>, and <span class="math inline">\(H_{53} = 1/3\)</span> and the partially complete hyperlink matrix is <span class="math display">\[\begin{equation}
H = \begin{pmatrix} - &amp; - &amp; 1/3 &amp; - &amp; - &amp; - \\ - &amp; - &amp; 1/3 &amp; - &amp; - &amp; - \\ - &amp; - &amp; 0 &amp; - &amp; - &amp; - \\ - &amp; - &amp; 0 &amp; - &amp; - &amp; - \\ - &amp; - &amp; 1/3 &amp; - &amp; - &amp; - \\ - &amp; - &amp; 0 &amp; - &amp; - &amp; - \end{pmatrix}
\end{equation}\]</span></p></li>
<li><p>The difference equation <span class="math inline">\(\boldsymbol{x}_{n+1} = H \boldsymbol{x}_n\)</span> is used to iteratively refine the estimates of the page ranks. You can view the iterations as a person visiting a page and then following a link at random, then following a random link on the next page, and the next, and the next, etc. Hence we see that the iterations evolve exactly as expected for a difference equation.</p></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 81%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Iteration</strong></th>
<th><strong>New Page Rank Estimation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td><span class="math inline">\(\boldsymbol{x}_0\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\(\boldsymbol{x}_1 = H \boldsymbol{x}_0\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\(\boldsymbol{x}_2 = H \boldsymbol{x}_1 = H^2 \boldsymbol{x}_0\)</span></td>
</tr>
<tr class="even">
<td>3</td>
<td><span class="math inline">\(\boldsymbol{x}_3 = H \boldsymbol{x}_2 = H^3 \boldsymbol{x}_0\)</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td><span class="math inline">\(\boldsymbol{x}_4 = H \boldsymbol{x}_3 = H^4 \boldsymbol{x}_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(k\)</span></td>
<td><span class="math inline">\(\boldsymbol{x}_k = H^k \boldsymbol{x}_0\)</span></td>
</tr>
</tbody>
</table>
<ol start="4" type="1">
<li>When a steady state is reached we sort the resulting vector <span class="math inline">\(\boldsymbol{x}_k\)</span> to give the page rank. The node (web page) with the highest rank will be the top search result, the second highest rank will be the second search result, and so on.</li>
</ol>
<p>It does not take much to see that this process can be very time consuming. Think about your typical web search with hundreds of thousands of hits; that makes a square matrix <span class="math inline">\(H\)</span> that has a size of hundreds of thousands of entries by hundreds of thousands of entries! The matrix multiplications alone would take many minutes (or possibly many hours) for every search! …but Brin and Page were pretty smart dudes!!</p>
<p>We now state a few theorems and definitions that will help us simplify the iterative Page Rank process.</p>
<hr>
<div id="thm-4.7" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.6</strong></span> If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times n\)</span> matrix with <span class="math inline">\(n\)</span> linearly independent eigenvectors <span class="math inline">\(\boldsymbol{v}_1, \boldsymbol{v}_2, \boldsymbol{v}_3,\)</span> <span class="math inline">\(\ldots, \boldsymbol{v}_n\)</span> and associated eigenvalues <span class="math inline">\(\lambda_1, \lambda_2, \lambda_3, \ldots, \lambda_n\)</span> then for any initial vector <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span> we can write <span class="math inline">\(A^k \boldsymbol{x}\)</span> as <span class="math display">\[\begin{equation}
A^k \boldsymbol{x} = c_1 \lambda_1^k \boldsymbol{v}_1 + c_2 \lambda_2^k \boldsymbol{v}_2 + c_3 \lambda_3^k \boldsymbol{v}_3 + \cdots c_n \lambda_n^k \boldsymbol{v}_n
\end{equation}\]</span> where <span class="math inline">\(c_1, c_2, c_3, \ldots, c_n\)</span> are the constants found by expressing <span class="math inline">\(\boldsymbol{x}\)</span> as a linear combination of the eigenvectors.<br>
Note: We can assume that the eigenvalues are ordered such that <span class="math inline">\(|\lambda_1| &gt; |\lambda_2| \ge |\lambda_3| \ge \cdots \ge |\lambda_n|\)</span>.</p>
</div>
<hr>
<div id="exr-4.94" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.91</strong></span> Prove the preceding theorem.</p>
</div>
<hr>
<div id="def-4.1" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.8</strong></span> A <strong>probability vector</strong> is a vector with entries on the interval <span class="math inline">\([0,1]\)</span> that add up to 1. A <strong>stochastic matrix</strong> is a square matrix whose columns are probability vectors.</p>
</div>
<hr>
<div id="thm-4.8" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.7</strong></span> If <span class="math inline">\(A\)</span> is a stochastic <span class="math inline">\(n \times n\)</span> matrix then <span class="math inline">\(A\)</span> will have <span class="math inline">\(n\)</span> linearly independent eigenvectors. Furthermore, the largest eigenvalue of a stochastic matrix will be <span class="math inline">\(\lambda_1 = 1\)</span> and the smallest eigenvalue will always be non-negative: <span class="math inline">\(0 \le |\lambda_n| &lt; 1\)</span>.</p>
<p>Some of the following tasks will ask you to <em>prove</em> a statement or a theorem. This means to clearly write all of the logical and mathematical reasons why the statement is true. Your proof should be absolutely crystal clear to anyone with a similar mathematical background …if you are in doubt then have a peer from a different group read your proof to you .</p>
</div>
<hr>
<div id="exr-4.95" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.92</strong></span> Finish writing the hyperlink matrix <span class="math inline">\(H\)</span> from <a href="#fig-4.3" class="quarto-xref">Figure&nbsp;<span>C.3</span></a>.</p>
</div>
<hr>
<div id="exr-4.96" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.93</strong></span> Write code to implement the iterative process defined previously. Make a plot that shows how the rank evolves over the iterations.</p>
</div>
<hr>
<div id="exr-4.97" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.94</strong></span> What must be true about a collection of <span class="math inline">\(n\)</span> pages such that an <span class="math inline">\(n\times n\)</span> hyperlink matrix <span class="math inline">\(H\)</span> is a stochastic matrix.</p>
</div>
<hr>
<div id="exr-4.98" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.95</strong></span> The statement of the next theorem is incomplete, but the proof is given to you. Fill in the blank in the statement of the theorem and provide a few sentences supporting your answer.</p>
</div>
<hr>
<div id="thm-4.9" class="theorem">
<p><span class="theorem-title"><strong>Theorem C.8</strong></span> If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times n\)</span> stochastic matrix and <span class="math inline">\(\boldsymbol{x}_0\)</span> is some initial vector for the difference equation <span class="math inline">\(\boldsymbol{x}_{n+1} = A \boldsymbol{x}_n\)</span>, then the steady state vector is <span class="math display">\[\begin{equation}
\boldsymbol{x}_{equilib} = \lim_{k \to\infty} A^k \boldsymbol{x}_0 = \underline{\hspace{1in}}.
\end{equation}\]</span></p>
<p><em>Proof:</em></p>
<p>First note that <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times n\)</span> stochastic matrix so from <a href="#thm-4.8" class="quarto-xref">Theorem&nbsp;<span>C.7</span></a> we know that there are <span class="math inline">\(n\)</span> linearly independent eigenvectors. We can then substitute the eigenvalues from <a href="#thm-4.8" class="quarto-xref">Theorem&nbsp;<span>C.7</span></a> in <a href="#thm-4.7" class="quarto-xref">Theorem&nbsp;<span>C.6</span></a>. Noting that if <span class="math inline">\(0&lt;\lambda_j&lt;1\)</span> we have <span class="math inline">\(\lim_{k \to \infty} \lambda_j^k = 0\)</span> the result follows immediately.</p>
</div>
<hr>
<div id="exr-4.99" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.96</strong></span> Discuss how <a href="#thm-4.9" class="quarto-xref">Theorem&nbsp;<span>C.8</span></a> greatly simplifies the PageRank iterative process described previously. In other words: there is no reason to iterate at all. Instead, just find … what?</p>
</div>
<hr>
<div id="exr-4.100" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.97</strong></span> Now use the previous two problems to find the resulting PageRank vector from the web in <a href="#fig-4.3" class="quarto-xref">Figure&nbsp;<span>C.3</span></a>? Be sure to rank the pages in order of importance. Compare your answer to the one that you got in problem 2.</p>
</div>
<hr>
<div id="fig-4.4" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://numericalmethodssullivan.github.io/images/Ch04_GoogleGraph2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.4: A second example web graph.
</figcaption>
</figure>
</div>
<div id="exr-4.101" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.98</strong></span> Consider the web in <a href="#fig-4.4" class="quarto-xref">Figure&nbsp;<span>C.4</span></a>.</p>
<ol type="1">
<li><p>Write the <span class="math inline">\(H\)</span> matrix and find the initial state <span class="math inline">\(\boldsymbol{x}_0\)</span>,</p></li>
<li><p>Find steady state PageRank vector using the two different methods described: one using the iterative difference equation and the other using <a href="#thm-4.9" class="quarto-xref">Theorem&nbsp;<span>C.8</span></a> and the dominant eigenvector.</p></li>
<li><p>Rank the pages in order of importance.</p></li>
</ol>
</div>
<hr>
<div id="exr-4.102" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.99</strong></span> One thing that we did not consider in this version of the Google Page Rank algorithm is the random behaviour of humans. One, admittedly slightly naive, modification that we can make to the present algorithm is to assume that the person surfing the web will randomly jump to any other page in the web at any time. For example, if someone is on page 1 in <a href="#fig-4.4" class="quarto-xref">Figure&nbsp;<span>C.4</span></a> then they could randomly jump to any page 2 - 8. They also have links to pages 2, 3, and 7. That is a total of 10 possible next steps for the web surfer. There is a <span class="math inline">\(2/10\)</span> chance of heading to page 2. One of those is following the link from page 1 to page 2 and the other is a random jump to page 2 without following the link. Similarly, there is a <span class="math inline">\(2/10\)</span> chance of heading to page 3, <span class="math inline">\(2/10\)</span> chance of heading to page 7, and a <span class="math inline">\(1/10\)</span> chance of randomly heading to any other page.</p>
<p>Implement this new algorithm, called the <em>random surfer algorithm</em>, on the web in <a href="#fig-4.4" class="quarto-xref">Figure&nbsp;<span>C.4</span></a>. Compare your ranking to the non-random surfer results from the previous problem.</p>
</div>
<hr>
</section>
<section id="alternative-methods-for-solving-a-boldsymbolx-boldsymbolb" class="level3" data-number="C.11.2">
<h3 data-number="C.11.2" class="anchored" data-anchor-id="alternative-methods-for-solving-a-boldsymbolx-boldsymbolb"><span class="header-section-number">C.11.2</span> Alternative Methods For Solving <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span></h3>
<p>Throughout most of the linear algebra chapter we have studied ways to solve systems of equations of the form <span class="math inline">\(A\boldsymbol{x} = \boldsymbol{b}\)</span> where <span class="math inline">\(A\)</span> is a square <span class="math inline">\(n \times n\)</span> matrix, <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span>, and <span class="math inline">\(\boldsymbol{b} \in\mathbb{R}^n\)</span>. We have reviewed by-hand row reduction and learned new techniques such as the <span class="math inline">\(LU\)</span> decomposition and the <span class="math inline">\(QR\)</span> decomposition – all of which are great in their own right and all of which have their shortcomings.</p>
<p>Both <span class="math inline">\(LU\)</span> and <span class="math inline">\(QR\)</span> are great solution techniques and they generally work very very well. However (no surprise), we can build algorithms that will <em>usually</em> be faster!</p>
<p>In the following new algorithms we want to solve the linear system of equations <span class="math display">\[\begin{equation}
A \boldsymbol{x} = \boldsymbol{b}
\end{equation}\]</span> but in each we will do so iteratively by applying an algorithm over and over until the algorithm converges to an approximation of the solution vector <span class="math inline">\(\boldsymbol{x}\)</span>. Convergence here means that <span class="math inline">\(\|A\ \boldsymbol{x} - \boldsymbol{b} \|\)</span> is less than some pre-determined tolerance.</p>
<p><strong>Method 1:</strong> Start by “factoring”<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> the matrix <span class="math inline">\(A\)</span> into <span class="math inline">\(A = L + U\)</span> where <span class="math inline">\(L\)</span> is a lower-triangular matrix and <span class="math inline">\(U\)</span> is an upper-triangular matrix. Take note that this time we will not force the diagonal entries of <span class="math inline">\(L\)</span> to be <span class="math inline">\(1\)</span> like we did in the classical <span class="math inline">\(LU\)</span> factorization . The <span class="math inline">\(U\)</span> in the factorization <span class="math inline">\(A = L + U\)</span> is an upper-triangular matrix where the entries on the main diagonal are exactly 0.</p>
<p>Specifically, <span class="math display">\[\begin{equation}
\begin{split}
A = L + U =&amp; \begin{pmatrix} a_{00} &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ a_{10} &amp; a_{11} &amp; 0 &amp; \cdots &amp; 0 \\ a_{20} &amp; a_{21} &amp; a_{22} &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_{n0} &amp; a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{n-1,n-1} \end{pmatrix}\\
&amp;+ \begin{pmatrix} 0 &amp; a_{01} &amp; a_{02} &amp; \cdots &amp; a_{0,n-1} \\ 0 &amp; 0 &amp; a_{12} &amp; \cdots &amp; a_{1,n-1} \\ 0 &amp; 0 &amp; 0 &amp; a_{23} &amp; \cdots &amp; \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; 0 &amp; &amp; 0 \end{pmatrix}.
\end{split}
\end{equation}\]</span></p>
<p>As an example,</p>
<p><span class="math display">\[\begin{equation}
\begin{pmatrix} 2 &amp; 3 &amp; 4 \\ 5 &amp; 6 &amp; 7 \\ 8 &amp; 9 &amp; 1 \end{pmatrix} = \begin{pmatrix} 2 &amp; 0 &amp; 0 \\ 5 &amp; 6 &amp; 0 \\ 8 &amp; 9 &amp; 1\end{pmatrix} + \begin{pmatrix} 0 &amp; 3 &amp; 4 \\ 0 &amp; 0 &amp; 7 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\end{equation}\]</span></p>
<p>After factoring the system of equations can be rewritten as <span class="math display">\[\begin{equation}
A \boldsymbol{x} = \boldsymbol{b} \implies (L+U)x = \boldsymbol{b} \implies L\boldsymbol{x} + U\boldsymbol{x} = \boldsymbol{b}.
\end{equation}\]</span> Moving the term <span class="math inline">\(U\boldsymbol{x}\)</span> to the right-hand side gives <span class="math inline">\(L\boldsymbol{x} = b-U\boldsymbol{x}\)</span>, and if we solve for the unknown <span class="math inline">\(\boldsymbol{x}\)</span> we get <span class="math inline">\(\boldsymbol{x} = L^{-1}(\boldsymbol{b}-U\boldsymbol{x}).\)</span></p>
<p>Of course we would never (<em>ever</em>!) actually compute the inverse of <span class="math inline">\(L\)</span>, and consequently we have to do something else in place of the matrix inverse. Stop and think here for a moment. We have run into this problem earlier in this chapter and you have some code that you will need to modify for this job (but take very careful note that the <span class="math inline">\(L\)</span> matrix here does not quite have the same structure as the <span class="math inline">\(L\)</span> matrix we used in the past). Moreover, notice that we have the unknown <span class="math inline">\(\boldsymbol{x}\)</span> on both sides of the equation. Initially this may seem like nonsense, but if we treat this as an iterative scheme by first making a <strong>guess</strong> about <span class="math inline">\(x\)</span> and then iteratively find better approximations of solutions via the difference equation <span class="math display">\[\begin{equation}
\boldsymbol{x}_{k+1} = L^{-1} (b-U\boldsymbol{x}_k)
\end{equation}\]</span> we may, under moderate conditions on <span class="math inline">\(A\)</span>, quickly be able to approximate the solution to <span class="math inline">\(A\boldsymbol{x}=\boldsymbol{b}\)</span>. The subscripts in the iterative scheme represent the iteration number. Hence, <span class="math display">\[\begin{equation}
\boldsymbol{x}_{1} = L^{-1} (b-U\boldsymbol{x}_0)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{x}_{2} = L^{-1} (b-U\boldsymbol{x}_1)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\vdots
\end{equation}\]</span></p>
<p>What we need to pay attention to is that the method is not guaranteed to converge to the actual solution to the equation <span class="math inline">\(A \boldsymbol{x} = \boldsymbol{b}\)</span> unless some conditions on <span class="math inline">\(A\)</span> are met, and you will need to experiment with the algorithm to come up with a conjecture about the appropriate conditions.</p>
<p><strong>Method 2:</strong> Start by factoring the matrix <span class="math inline">\(A\)</span> into <span class="math inline">\(A = L + D + U\)</span> where <span class="math inline">\(L\)</span> is strictly lower-triangular (0’s on the main diagonal and in the entire upper triangle), <span class="math inline">\(D\)</span> is a diagonal matrix, and <span class="math inline">\(U\)</span> is a strictly upper-triangular matrix (0’s on the main diagonal and in the entire lower triangle). In this new factorization, the diagonal matrix <span class="math inline">\(D\)</span> simply contains the entries from the main diagonal of <span class="math inline">\(A\)</span>. The <span class="math inline">\(L\)</span> matrix is the lower triangle of <span class="math inline">\(A\)</span>, and the <span class="math inline">\(U\)</span> matrix is the upper triangle of <span class="math inline">\(A\)</span>.</p>
<p>Considering the system of equations <span class="math inline">\(A\boldsymbol{x} = \boldsymbol{b}\)</span> we get <span class="math display">\[\begin{equation}
(L+D+U)\boldsymbol{x} = \boldsymbol{b}
\end{equation}\]</span> and after simplifying, rearranging, and solving for <span class="math inline">\(\boldsymbol{x}\)</span> we get <span class="math inline">\(\boldsymbol{x} = D^{-1} (b-L\boldsymbol{x}-U\boldsymbol{x}).\)</span> A moment’s reflection should reveal that the inverse of <span class="math inline">\(D\)</span> is really easy to find (no heavy-duty linear algebra necessary) if some mild conditions on the diagonal entries of <span class="math inline">\(A\)</span> are met. Like before there is an <span class="math inline">\(\boldsymbol{x}\)</span> on both sides of the equation, but if we again make the algorithm iterative we can get successive approximations of the solution with <span class="math display">\[\begin{equation}
\boldsymbol{x}_{k+1} = D^{-1}(b - L\boldsymbol{x}_k - U\boldsymbol{x}_k).
\end{equation}\]</span></p>
<p><strong>Your Tasks:</strong></p>
<ol type="1">
<li><p>Pick a small (larger than <span class="math inline">\(3 \times 3\)</span>) matrix and an appropriate right-hand side <span class="math inline">\(\boldsymbol{b}\)</span> and work each of the algorithms by hand. You do not need to write this step up in the final product, but this exercise will help you locate where things may go wrong in the algorithms and what conditions we might need on <span class="math inline">\(A\)</span> in order to get convergent sequences of approximate solutions.</p></li>
<li><p>Build Python functions that accept a square matrix <span class="math inline">\(A\)</span> and complete the factorizations <span class="math inline">\(A = L+U\)</span> and <span class="math inline">\(A = L+D+U\)</span>.</p></li>
<li><p>Build functions to implement the two methods and then demonstrate that the methods work on a handful of carefully chosen test examples. As part of these functions you need to build a way to deal with the matrix inversions as well as build a stopping rule for the iterative schemes. Hint: You should use a <code>while</code> loop with a proper logical condition. Think carefully about what we are finding at each iteration and what we can use to check our accuracy at each iteration. It would also be wise to write your code in such a way that it checks to see if the sequence of approximations is diverging.</p></li>
<li><p>Discuss where each method might fail and then demonstrate the possible failures with several carefully chosen examples. Stick to small examples and work these out by hand to clearly show the failure.</p></li>
<li><p>Iterative methods such as these will produce a sequence of approximations, but there is no guarantee that either method will actually produce a convergent sequence. Experiment with several examples and propose a condition on the matrix <span class="math inline">\(A\)</span> which will likely result in a convergent sequence. Demonstrate that the methods fail if your condition is violated and that the methods converge if your condition is met. Take care that it is tempting to think that your code is broken if it does not converge. The more likely scenario is that the problem that you have chosen to solve will result in a non-convergent sequence of iterations, and you need to think and experiment carefully when choosing the example problems to solve. One such convergence criterion has something to do with the diagonal entries of <span class="math inline">\(A\)</span> relative to the other entries, but that does not mean that you should not explore other features of the matrices as well (I cannot give you any more hints than that). This task is not asking for a proof; just a conjecture and convincing numerical evidence that the conjecture holds. The actual proofs are beyond the scope of this project and this course.</p></li>
<li><p>Devise a way to demonstrate how the time to solve a large linear system <span class="math inline">\(A\boldsymbol{x} = \boldsymbol{b}\)</span> compares between our two new methods, the <span class="math inline">\(LU\)</span> algorithm, and the <span class="math inline">\(QR\)</span> algorithm that we built earlier in the chapter. Conclude this demonstration with appropriate plots and ample discussion.</p></li>
</ol>
<p>You need to do this project without the help of your old buddy Google. All code must be originally yours or be modified from code that we built in class. You can ask Google how Python works with matrices and the like, but searching directly for the algorithms (which are actually well-known, well-studied, and named algorithms) is not allowed.</p>
<p>Finally, solving systems of equations with the <code>|np.linalg.solve()</code> command can only be done to verify or check your answer(s).</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Meerschaert" class="csl-entry" role="listitem">
Meerschaert, Mark. 2013. <em>Mathematical <span>Modeling</span></em>. 4th edition. Amsterdam ; Boston: Academic Press.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>You should also note that <span class="math inline">\(\|\boldsymbol{u}\| = \sqrt{\boldsymbol{u} \cdot \boldsymbol{u}}\)</span> is not the only definition of distance. More generally, if you let <span class="math inline">\(\left&lt; \boldsymbol{u}, \boldsymbol{v}\right&gt;\)</span> be an inner product for <span class="math inline">\(\boldsymbol{u}\)</span> and <span class="math inline">\(\boldsymbol{v}\)</span> in some vector space <span class="math inline">\(\mathcal{V}\)</span> then <span class="math inline">\(\|\boldsymbol{u}\| = \sqrt{\left&lt; \boldsymbol{u}, \boldsymbol{u}\right&gt;}\)</span>. In most cases in this text we will be using the dot product as our preferred inner product so we will not have to worry much about this particular natural extension of the definition of the length of a vector.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>You might have thought that <em>naive multiplication</em> was a much more natural way to do matrix multiplication when you first saw it. Hopefully now you see the power in the definition of matrix multiplication that we actually use. If not, then I give you this moment to ponder that (a) matrix multiplication is just a bunch of dot products, and (b) dot products can be seen as projections. Hence, matrix multiplication is really just a projection of the rows of <span class="math inline">\(A\)</span> onto the columns of <span class="math inline">\(B\)</span>. This has much more rich geometric flavour than <em>naive multiplication</em>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Take careful note here. We have actually just built a special case of the <span class="math inline">\(LU\)</span> decomposition. Remember that in row reduction you are allowed to swap the order of the rows, but in our <span class="math inline">\(LU\)</span> algorithm we do not have any row swaps. The version of <span class="math inline">\(LU\)</span> with row swaps is called <span class="math inline">\(LU\)</span> with partial pivoting. We will not built the full partial pivoting algorithm in this text but feel free to look it up. The <a href="https://en.wikipedia.org/wiki/LU_decomposition#LU_factorization_with_partial_pivoting">wikipedia page</a> is a decent place to start. What you will find is that there are indeed many different versions of the <span class="math inline">\(LU\)</span> decomposition.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Numerical Linear Algebra is a huge field and there is way more to say … but alas, this is an introductory course in Numerical Analysis so we cannot do everything. Sigh.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>To build a matrix with specific eigenvalues it may be helpful to recall the matrix factorization <span class="math inline">\(A = PDP^{-1}\)</span> where the columns of <span class="math inline">\(P\)</span> are the eigenvectors of <span class="math inline">\(A\)</span> and the diagonal entries of <span class="math inline">\(D\)</span> are the eigenvalues. If you choose <span class="math inline">\(P\)</span> and <span class="math inline">\(D\)</span> then you can build <span class="math inline">\(A\)</span> with your specific eigen-structure. If you are looking for complex eigenvalues then remember that the eigenvectors may well be complex too.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Actually, the determinant computation uses LU with partial pivoting which we did not cover here in the text. What we are looking at in this exercise is a smaller sub-case of what happens when you have a matrix <span class="math inline">\(A\)</span> that does not require any row swaps in the row reduction process.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Technically speaking we should not call this a “factorization” since we have not split the matrix <span class="math inline">\(A\)</span> into a product of two matrices. Instead we should call it a “partition” since in number theory we call the process of breaking an integer into the sum of two integers is called a “partition.” Even so, we will still use the word factorization here for simplicity.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ex_exam_solns.html" class="pagination-link" aria-label="Exam solutions">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Exam solutions</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/gustavdelius/NumericalAnalysis2026/edit/main/nmLinAlg.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>