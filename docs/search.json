[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Numerical Analysis",
    "section": "",
    "text": "Introduction\nMathematics is not just an abstract pursuit; it is an essential tool that powers a vast array of applications. From weather forecasting to black hole simulations, from urban planning to medical research, from ecology to epidemiology, the application of mathematics has become indispensable. Central to this applied force is Numerical Analysis.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-what_is_numerical_analysis",
    "href": "index.html#sec-what_is_numerical_analysis",
    "title": "Numerical Analysis",
    "section": "What Is Numerical Analysis?",
    "text": "What Is Numerical Analysis?\nNumerical Analysis is the discipline that bridges continuous mathematical theories with their concrete implementation on digital computers. These computers, by design, work with discrete quantities, and translating continuous problems into this discrete realm is not always straightforward.\nIn this module, we will explore some key techniques, algorithms, and principles of Numerical Analysis that enable us to translate mathematical problems into computational solutions. We will delve into the challenges that arise in this translation, the strategies to overcome them, and the interaction of theory and practice.\nMany mathematical problems cannot be solved analytically in closed form. In Numerical Analysis, we aim to find approximation algorithms for mathematical problems, i.e., schemes that allow us to compute the solution approximately. These algorithms use only elementary operations that computers know how to do (\\(+,-,\\times,/\\)), but often a long sequence of them, so that in practice they need to be run on computers.\n\nExample from Algebra\nSolve the equation \\[\\log(x) = \\sin(x)\\] for \\(x\\) in the interval \\(x \\in (0,\\pi)\\). Stop and try using all of the algebra that you ever learned to find \\(x\\). You will quickly realize that there are no by-hand techniques that can solve this problem! A numerical approximation, however, is not so hard to come by. The following graph shows that there is a solution to this equation somewhere between \\(x=2\\) and \\(x=2.5\\).\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.linspace(1, 4, 100)\nplt.plot(x, np.log(x), label=\"log(x)\")\nplt.plot(x, np.sin(x), label=\"sin(x)\")\nplt.xlabel(\"x\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†1: The graphs of the real functions \\(\\log(x)\\) and \\(\\sin(x)\\) intersect at exactly one point, giving the solution to the equation \\(\\log(x) = \\sin(x)\\).\n\n\n\n\n\n\n\nExample from Calculus\nWhat if we want to evaluate\n\\[\n    \\int_0^\\pi \\sin(x^2) dx?\n\\]\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef f(x):\n    return np.sin(x**2)\n\na = 0\nb = np.pi\nn = 1000  # Number of points for numerical integration\n\nx = np.linspace(a, b, n)\ny = f(x)\n\n# Calculate the numerical integral using the trapezoidal rule\nintegral = np.trapezoid(y, x)\n\n# Shade the positive and negative regions differently\nplt.fill_between(x, y, where=y&gt;=0, color='green', alpha=0.5, label=\"Positive\")\nplt.fill_between(x, y, where=y&lt;0, color='red', alpha=0.5, label=\"Negative\")\n\n# Plot the curve\nplt.plot(x, y, color='black', label=r\"$\\sin(x^2)$\")\n\n# Set labels and title\nplt.xlabel(\"x\")\n\n# Add legend\nplt.legend()\n\n# Show the plot\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†2: Visual representation of the integral of \\(\\sin(x^2)\\) from \\(0\\) to \\(\\pi\\).\n\n\n\n\n\nAgain, trying to use any of the possible techniques for using the Fundamental Theorem of Calculus, and hence finding an antiderivative, on the function \\(\\sin(x^2)\\) is completely hopeless. Substitution, integration by parts, and all of the other techniques that you know will all fail. Again, a numerical approximation is not so difficult and is very fast and gives the value\n\n\nCode\n# Use Simpson's rule to approximate the integral of sin(x^2) from 0 to pi\nfrom scipy.integrate import simpson\nprint(simpson(y, x = x))\n\n\n0.7726517138019184\n\n\nBy the way, this integral (called the Fresnel Sine Integral) actually shows up naturally in the field of optics and electromagnetism, so it is not just some arbitrary integral that was cooked up just for fun.\n\n\nExample from Differential Equations\nSay we needed to solve the differential equation\n\\[\\frac{dy}{dt} = \\sin(y^2) + t.\\]\nThe nonlinear nature of the problem precludes us from using most of the typical techniques (e.g.¬†separation of variables, undetermined coefficients, Laplace Transforms, etc). However, computational methods that result in a plot of an approximate solution can be made very quickly. Here is a plot of the solution up to time \\(t=2.5\\) with initial condition \\(y(0)=0.1\\):\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef f(t, y):\n    return np.sin(y**2) + t\n\n# Initial condition\ny0 = 0.1\n\n# Time span for the solution\nt_span = (0, 2.5)\n\n# Solve the differential equation using SciPy's solver\nsol = solve_ivp(f, t_span, [y0], max_step=0.1, dense_output=True)\n\n# Extract the time values and solution\nt = sol.t\ny = sol.sol(t)[0]  \n\n# Plot the numerical solution\nplt.plot(t, y)\n\n# Labels and title\nplt.xlabel('t')\nplt.ylabel('y')\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†3: Plot of numerical solution of \\(dy/dt=\\sin(y^2)+t\\) with \\(y(0)=0.1\\).\n\n\n\n\n\nThis was an artificial example, but differential equations are central to modelling the real world in order to predict the future. They are the closest thing we have to a crystal ball. Here is a plot of a numerical solution of the SIR model of the evolution of an epidemic over time:\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n# SIR model differential equations\ndef sir_model(y, t, N, beta, gamma):\n    S, I, R = y\n    dSdt = -beta * S * I / N\n    dIdt = beta * S * I / N - gamma * I\n    dRdt = gamma * I\n    return dSdt, dIdt, dRdt\n\n# Total population, N\nN = 1000\n# Initial number of infected and recovered individuals\nI0, R0 = 1, 0\n# Everyone else is susceptible to infection initially\nS0 = N - I0 - R0\n# Contact rate, beta, and mean recovery rate, gamma, (in 1/days)\nbeta, gamma = 0.25, 1./20 \n# A grid of time points (in days)\nt = np.linspace(0, 160, 160)\n\n# Initial conditions vector\ny0 = S0, I0, R0\n# Integrate the SIR equations over the time grid, t\nret = odeint(sir_model, y0, t, args=(N, beta, gamma))\nS, I, R = ret.T\n\n# Plot the data on three separate curves for S(t), I(t) and R(t)\nplt.figure(figsize=(10,6))\nplt.plot(t, S, 'b', alpha=0.7, linewidth=2, label='Susceptible')\nplt.plot(t, I, 'y', alpha=0.7, linewidth=2, label='Infected')\nplt.plot(t, R, 'g', alpha=0.7, linewidth=2, label='Recovered')\nplt.xlabel('Time /days')\nplt.ylabel('Number (1000s)')\nplt.ylim(0, N)\nplt.title('SIR Model Simulation')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†4: Plot of a numerical solution of the SIR model\n\n\n\n\n\n\n\nReasons to study Numerical Analysis\nSo why should you want to venture into Numerical Analysis rather than just use the computer as a black box?\n\nPrecision and Stability: Computers, despite their power, can introduce significant errors if mathematical problems are implemented without care. Numerical Analysis offers techniques to ensure we obtain results that are both accurate and stable.\nEfficiency: Real-world applications often demand not just correctness, but efficiency. By grasping the methods of Numerical Analysis, we can design algorithms that are both accurate and resource-efficient.\nBroad Applications: Whether your interest lies in physics, engineering, biology, finance, or many other scientific fields, Numerical Analysis provides the computational tools to tackle complex problems in these areas.\nBasis for Modern Technologies: Core principles of Numerical Analysis are foundational in emerging fields such as artificial intelligence, quantum computing, and data science.\n\nThe prerequisites for this material include a firm understanding of calculus and linear algebra and a good understanding of the basics of differential equations.\nBy the end of this module, you will not merely understand the methods of Numerical Analysis; you will be equipped to apply them efficiently and effectively in diverse scenarios: you will be able to tackle problems in physics, engineering, biology, finance, and many other fields; you will be able to design algorithms that are both accurate and resource-efficient; you will be able to ensure that your computational solutions are both accurate and stable; you will be able to leverage the power of computers to solve complex problems.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-how_this_module_works",
    "href": "index.html#sec-how_this_module_works",
    "title": "Numerical Analysis",
    "section": "How this module works",
    "text": "How this module works\nThere are 4 one-hour whole-class sessions every week. Three of these are listed on your timetable as ‚ÄúLecture‚Äù and one as ‚ÄúComputer Practical‚Äù. However, in all these sessions you, the student, are the one that is doing the work; discovering methods, writing code, working problems, leading discussions, and pushing the pace. I, the lecturer, will act as a guide who only steps in to redirect conversations or to provide necessary insight. You will use the whole-class sessions to share and discuss your work with the other members of your group. There will also be some whole-class discussions moderated by me.\nYou will find that this text is not a set of lecture notes. Instead it mostly just contains collections of exercises with minimal interweaving exposition. It is expected that you do every one of the exercises in the main body of each chapter and use the sequencing of the exercises to guide your learning and understanding.\nTherefore the whole-class sessions form only a very small part of your work on this module. For each hour of whole-class work you should timetable yourself about two and a half hours of work outside class for working through the exercises on your own. I strongly recommend that you put those two and a half hours (ten hours spread throughout the week) into your timetable.\nIn order to enable you to get immediate feedback on your work also in between class sessions, I have made feedback quizzes where you can test your understanding of the material and your results from some of the exercises. Exercises that have an associated question in the feedback quiz are marked with a üéì.\nThere are no traditional problem sheets in this module. In this module you will be working on exercises continuously throughout the week rather than working through a problem sheet only every other week.\nAt the end of each chapter there is a section entitled ‚ÄúProblems‚Äù that contains additional exercises aimed at consolidating your new understanding and skills. These are optional. Many of the chapters also have a section entitled ‚ÄúProjects‚Äù. These projects are more open-ended investigations, designed to encourage creative mathematics, to push your coding skills and to require you to write and communicate mathematics. These projects are entirely optional and perhaps you will like to return to one of these even after the module has finished. If you do work on one of the projects, be sure to share your work with me at gustav.delius@york.ac.uk because will be very interested, also after the end of the module.\nIf you notice any mistakes or unclear things in the learning guide, please point them out to me in the class sessions or at gustav.delius@york.ac.uk. Many thanks go to Ben Mason and Toby Cheshire for the corrections they had sent in for a previous version of this guide.\nYou will need two notebooks for working through the exercises in this guide: one in paper form and one electronic. Some of the exercises are pen-and-paper exercises (and often these are marked with a pen icon ‚úèÔ∏è) while others are coding exercises (often marked with a computer icon üíª) and some require both writing or sketching and coding. You can keep your two notebooks linked through the numbering of the exercises. There are also some exercises that are marked with a Discussion icon üí¨. These are exercises that you should be discussing with other members of your group.\nYou will keep your coding notebooks in Google Colab, which we will discuss below. Most students find it easiest to have one dedicated Colab notebook per section, but some students will want to have one per chapter. You are highly encouraged to write explanatory text into your Google Colab notebooks as you go so that future-you can tell what it is that you were doing, which problem(s) you were solving, and what your thought processes were.\nIn the end, your collection of notebooks will contain solutions to every exercise in the guide and can serve as a reference manual for future numerical analysis problems. At the end of each of your notebooks you may also want to add a summary of what you have learned, which will both consolidate your learning and make it easier for you to remind yourself of your new skills later.\nOne request: do not share your notebooks publicly on the internet because that would create temptation for future students to not put in the work themselves, thereby robbing them of the learning experience.\nIf you have a computer, bring it along to the class sessions. However this is not a requirement. I will bring along some spare machines to make sure that every group has at least one computer to use during every session. The only requirements for a computer to be useful for this module is that it can connect to the campus WiFi, can run a web browser, and has a physical keyboard (typing code on virtual keyboards is too slow). The ‚ÄúComputer Practical‚Äù takes place in a PC classroom, so there will of course be plenty of machines available then.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-assessment",
    "href": "index.html#sec-assessment",
    "title": "Numerical Analysis",
    "section": "Assessment",
    "text": "Assessment\nUnfortunately, your learning in the module also needs to be assessed. The final mark will be made up of 40% coursework and 60% final exam.\nThe 40% coursework mark will come from 10 short quizzes that will take place during the ‚ÄúComputer practical‚Äù in weeks 2 to 11. Answering each quiz should take less than 5 minutes but you will be given 16 minutes each to complete the quizzes in order to give you a large safety margin and remove stress. Late answers will not be accepted. The quizzes will be based on exercises that you will already have worked through and for which you will have had time to discuss them in class, so they will be really easy if you have engaged with the exercises as intended. Each quiz will be worth 5 points. There will be a practice quiz in the computer practical in week 1.\nWhile working on the assessment quizzes you can already check your answers. If one of your answers is incorrect you can correct it and submit it again. However this will attract a penalty of 30% of the total mark for that answer. For multiple choice questions the penalty for a wrong answer may be even higher to discourage guessing. So it pays to be careful.\nDuring the assessment quizzes you will be required to work exclusively on one of the PCs in the computer practical room rather than your own machine. This means in particular that you need to be physically present for the assessment. While working on the quiz you are only allowed to use a web browser, and the only pages you are allowed to have open are this guide, the quiz page on Moodle and any of your notebooks on Google Colab, with the AI features switched off. You are not allowed to use any AI assistants or other web pages. Besides your digital notebooks on Google Colab you may also use any hand-written notes as long as you have written them yourself.\nTo allow for the fact that there may be weeks in which you are ill or otherwise prevented from performing to your best in the assessment quizzes, your final coursework mark will be calculated as the average over your 8 best marks. If exceptional circumstances affect more than two of the 10 quizzes then you would need to submit an exceptional circumstances claim.\nThe 60% final exam will be a 2 hour exam of the usual closed-book form in an exam room during the exam period. To prepare yourself for the final exam, there will be an exam style question at the end of each chapter, and I will make a practice exam available at the end of the module.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-textbooks",
    "href": "index.html#sec-textbooks",
    "title": "Numerical Analysis",
    "section": "Textbooks",
    "text": "Textbooks\nIn this module we will only scratch the surface of the vast subject that is Numerical Analysis. The aim is for you at the end of this module to be familiar with some key ideas and to have the confidence to engage with new methods when they become relevant to you.\nThere are many textbooks on Numerical Analysis. Standard textbooks are (Burden and Faires 2010) and (Kincaid and Cheney 2009). They contain much of the material from this module. A less structured and more opinionated account can be found in (Acton 1990). Another well known reference that researchers often turn to for solutions to specific tasks is (Press et al. 2007). You will find many others in the library. They may go also under alternative names like ‚ÄúNumerical Methods‚Äù or ‚ÄúScientific Computing‚Äù.\nYou may also want to look at textbooks for specific topics covered in this module, like for example (Butcher 2016) for methods for ordinary differential equations.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-your_jobs",
    "href": "index.html#sec-your_jobs",
    "title": "Numerical Analysis",
    "section": "Your jobs",
    "text": "Your jobs\nYou have the following jobs as a student in this module:\n\nFight! You will have to fight hard to work through this material. The fight is exactly what we are after since it is ultimately what leads to innovative thinking.\nScrew Up! More accurately, do not be afraid to screw up. You should write code, work problems, and develop methods, then be completely unafraid to scrap what you have done and redo it from scratch.\nCollaborate! You should collaborate with your peers, both within your group and across the whole class. Discuss exercises, ask questions, help others.\nEnjoy! Part of the fun of inquiry-based learning is that you get to experience what it is like to think like a true mathematician / scientist. It takes hard work but ultimately this should be fun!",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#python",
    "href": "index.html#python",
    "title": "Numerical Analysis",
    "section": "Python",
    "text": "Python\nTo properly understand numerical analysis, you will need to write code in order to experiment with the methods we discuss. You will be using Python for this purpose. or most of you, coding in Python will not be new. For example, you have probably seen it in your first year ‚ÄúMathematical Programming & Skills‚Äù module. But perhaps you have never seen Python before. You will have some notion of what a programming language ‚Äúis‚Äù and ‚Äúdoes‚Äù, but you may never have written any code. That is all right. You will pick it up as you go along.\nAppendix A ‚Äî Python covers some of the basics of Python programming that we will use in this module. If you are new to Python, don‚Äôt feel that you need to work through this appendix in one go. Instead, spread the work over the first two weeks of the course and interlace it with your work on the first two chapters.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-colab",
    "href": "index.html#sec-colab",
    "title": "Numerical Analysis",
    "section": "Google Colab",
    "text": "Google Colab\nEvery computer is its own unique flower with its own unique requirements. Hence, we will not spend time here giving you all of the ways that you can install Python and all of the associated packages necessary for this module. Instead I ask that you use the Google Colab notebook tool for writing and running your Python code: https://colab.research.google.com.\nGoogle Colab allows you to keep all of your Python code on your Google Drive. The Colab environment is a free and collaborative version of the popular Jupyter notebook project. Jupyter notebooks allow you to write and test code as well as to mix writing (including LaTeX formatting) in along with your code and your output. I recommend that if you are new to Google Colab, you start by watching the brief introductory video.\nNow the time has come for the first two exercises of this module.\n\nExercise 1 üíª Spend a bit of time poking around in Colab. Figure out how to\n\nCreate new Colab notebooks.\nAdd and delete code cells.\nType a simple calculation like 1+1 into a code cell and evaluate it.\nAdd and delete text cells.\nAdd an equation to a text cell using LaTeX notation.\nSave a notebook to your Google Drive.\nOpen a notebook from Google Drive.\nShare a notebook with other members of your group and see if you can collaboratively edit it.\n\n\n\n\nExercise 2 üíª Click on this link to a Colab notebook. It should open it in Colab. Then save a copy of it to your Google Drive. You need a copy because you will not have permission to edit the original. Follow the instructions in the notebook.\n\n\n\nThe use of AI\nYou will have gathered from the previous exercise that in this module you are not only allowed to use AI, you are encouraged to use AI. However you have probably already discovered that you get more out of an AI if you are already familiar with the basic concepts of a subject. You will need to be able to understand and check any answer an AI gives you. If there is something in an AI answer that is not totally clear or not obviously correct, always ask the AI to explain the details of its answer and ask follow-on questions until everything is crystal-clear.\nDuring the 10 assessment quizzes you will not be allowed to use any AI. In particular you will be required to switch off the AI features in Google Colab. It is thus a good idea when working on practice exercises to also switch off the AI features to make sure you know what you are doing even when there is no AI assistance. To switch off the AI features you should tick the ‚ÄúHide generative AI‚Äù checkbox on the ‚ÄúAI assistance‚Äù tab of the ‚ÄúSettings‚Äù page in Google Colab.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#about-you",
    "href": "index.html#about-you",
    "title": "Numerical Analysis",
    "section": "About you",
    "text": "About you\n\nExercise 3 üíª I am interested to learn more about you to help me make this module work well for you. It would be helpful if you would answer the questionnaire at https://forms.gle/YHHExaAnVzcLtBcU7. Of course you are free to share as much or as little as you like.\n\n\n¬© Gustav Delius. This learning guide is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. You may copy, distribute, display, remix, rework, and perform this copyrighted work, as long as you give credit to Gustav Delius gustav.delius@york.ac.uk and to the late Eric Sullivan, formerly Mathematics Faculty at Carroll College, on whose learning guide this one is based.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Numerical Analysis",
    "section": "References",
    "text": "References\n\n\n\n\nActon, Forman S. 1990. Numerical Methods That Work. 1St Edition edition. Washington, D.C: The Mathematical Association of America.\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.\n\n\nButcher, J. C. 2016. Numerical Methods for Ordinary Differential Equations. Third edition. Wiley. https://yorsearch.york.ac.uk/permalink/f/1kq3a7l/44YORK_ALMA_DS51336126850001381.\n\n\nKincaid, D. R., and E. W. Cheney. 2009. Numerical Analysis: Mathematics of Scientific Computing. Pure and Applied Undergraduate Texts. American Mathematical Society.\n\n\nPress, William H., Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. 2007. Numerical Recipes: The Art of Scientific Computing. Cambridge University Press. https://numerical.recipes/.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "nmNumbers.html",
    "href": "nmNumbers.html",
    "title": "1¬† Numbers",
    "section": "",
    "text": "1.1 Binary Numbers\nHave you ever wondered how computers, which operate in a realm of zeros and ones, manage to perform mathematical calculations with real numbers? The secret lies in approximation.\nIn this chapter and the next we will investigate the foundations that allow a computer to do mathematical calculations at all. How can it store real numbers? How can it calculate the values of mathematical functions? We will understand that the computer can do these things only approximately and will thus always make errors. Numerical Analysis is all about keeping these errors as small as possible while still being able to do efficient calculations.\nWe will meet the two kinds of errors that a computer makes: rounding errors and truncation errors. Rounding errors arise from the way the computer needs to approximate real numbers by binary floating point numbers, which are the numbers it know how to add, subtract, multiply and divide. We‚Äôll discuss this in this chapter. Truncation errors arise from the way the computer needs to reduce all calculations to a finite number of these four basic arithmetic operations. We will see that for the first time in Chapter 2 when we discuss how computers approximate functions by power series and then have to truncate these at some finite order.\nLet‚Äôs start with a striking example of how bad computers actually are at doing even simple calculations:\n(Even if you don‚Äôt know Python, you should be able to do this exercise after having read up to Section A.2.1 in the chapter on Essential Python.)\nIn the previous exercise it seems like the computer has failed you! What do you think happened on the computer and why did it give you a different answer? What, do you suppose, is the cautionary tale hiding behind the scenes with this problem?\nA computer circuit knows two states: on and off. As such, anything saved in computer memory is stored using base-2 numbers. This is called a binary number system. To fully understand a binary number system it is worthwhile to pause and reflect on our base-10 number system for a few moments.\nWhat do the digits in the number ‚Äú735‚Äù really mean? The position of each digit tells us something particular about the magnitude of the overall number. The number 735 can be represented as a sum of powers of 10 as\n\\[\\begin{equation}\n735 = 700 + 30 + 5 = 7 \\times 10^2 + 3 \\times 10^1 + 5 \\times 10^0\n\\end{equation}\\]\nand we can read this number as 7 hundreds, 3 tens, and 5 ones.\nNow let us switch to the number system used by computers: the binary number system. In a binary number system the base is 2 so the only allowable digits are 0 and 1 (just like in base-10 the allowable digits were 0 through 9). In binary (base-2), the number ‚Äú101,101‚Äù can be interpreted as\n\\[\\begin{equation}\n101,101_2 = 1 \\times 2^5 + 0 \\times 2^4 + 1 \\times 2^3 + 1 \\times 2^2 + 0 \\times 2^1 + 1 \\times 2^0\n\\end{equation}\\]\n(where the subscript ‚Äú2‚Äù indicates the base). If we put this back into base 10, so that we can read it more comfortably, we get\n\\[101,101_2 = 32 + 0 + 8 + 4 + 0 + 1 = 45_{10}.\\]\n(The commas in the numbers are only to allow for greater readability ‚Äì we can easily see groups of three digits and mentally keep track of what we are reading.)\nNext we will work with fractions and decimals.\nWe can do a similar thing with binary decimals.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmNumbers.html#sec-binary_numbers",
    "href": "nmNumbers.html#sec-binary_numbers",
    "title": "1¬† Numbers",
    "section": "",
    "text": "Exercise 1.5 üñã Express the following binary numbers in base-10.\n\n\\(111_2\\)\n\\(10,101_2\\)\n\\(1,111,111,111_2\\)\n\nFor the last one you can save yourself some work by noticing that \\(1,111,111,111_2 = 10,000,000,000_2 - 1\\). This is a generally useful trick that will help you again in some later exercises.\n\n\n\nExercise 1.6 üí¨ Explain the joke: There are 10 types of people. Those who understand binary and those who do not.\n\n\n\nExercise 1.7 üí¨ üñã Discussion: With your group, discuss how you would convert a base-10 number into its binary representation, without using a calculator or computer. Once you have a proposed method put it into action on the number \\(237_{10}\\) to show that the base-2 expression is \\(11,101,101_2\\).\n\n\n\nExercise 1.8 üñã By hand, using the methods you developed above, convert the following numbers from base 10 to base 2 or visa versa.\n\nWrite \\(12_{10}\\) in binary\nWrite \\(11_{10}\\) in binary\nWrite \\(23_{10}\\) in binary üéì\nWrite \\(11_2\\) in base \\(10\\)\nWhat is \\(100101_2\\) in base \\(10\\)? üéì\n\nThe üéì icons indicate that you should enter your answers into the feedback quiz. This gives you feedback on whether or not your answer is correct, but just as importantly, it lets your lecturer know how you are progressing with the material. The feedback quizzes are not used for assessment purposes, solely for feedback.\n\n\n\nExercise 1.9 üñã üí¨ Write down an explanation of the technique that your group has come up with to do the conversion from base 10 to base 2.\n\n\n\n\nExample 1.1 Let us take the base \\(10\\) number \\(5.341_{10}\\) and expand it out to get\n\\[5.341_{10} = 5 + \\frac{3}{10} + \\frac{4}{100} + \\frac{1}{1000} = 5 \\times 10^0 + 3 \\times 10^{-1} + 4 \\times 10^{-2} + 1 \\times 10^{-3}.\\]\nThe position to the right of the decimal point is the negative power of 10 for the given position.\n\n\n\n\nExercise 1.10 üñã The base-2 number \\(1,101.01_2\\) can be expanded in powers of \\(2\\). Fill in the question marks below and observe the pattern in the powers.\n\\[1,101.01_2 = ? \\times 2^3 + 1 \\times 2^2 + 0 \\times 2^1 + ? \\times 2^0 + 0 \\times 2^{?} + 1 \\times 2^{-2}.\\]\n\n\n\nExample 1.2 Convert \\(11.01011_2\\) to base \\(10\\).\nSolution:\n\\[\\begin{aligned} 11.01011_2 &= 2 + 1 + \\frac{0}{2} + \\frac{1}{4} + \\frac{0}{8} + \\frac{1}{16} + \\frac{1}{32} \\\\ &= 1 \\times 2^1 + 1 \\times 2^0 + 0 \\times 2^{-1} + 1 \\times 2^{-2} + 0 \\times 2^{-3} + 1 \\times 2^{-4} + 1 \\times 2^{-5}\\\\ &= 3.34375_{10}. \\end{aligned}\\]\n\n\n\nExercise 1.11 üí¨ üñã üéì Convert the base \\(10\\) decimal \\(0.15625_{10}\\) to binary using the following steps.\n\nMultiply \\(0.15625\\) by \\(2\\). The whole number part of the result is the first binary digit to the right of the decimal point.\nTake the result of the previous multiplication and ignore the digit to the left of the decimal point. Multiply the remaining decimal by \\(2\\). The whole number part is the second binary decimal digit.\nRepeat the previous step until you have nothing left.\n\nExplain to each other in the group why each step gives the binary digit that it does.\n\n\n\nExercise 1.12 üñã Convert the base \\(10\\) fraction \\(0.1\\) into binary. Use this to explain why the computer made errors when it calculated with this number in Exercise¬†1.3.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmNumbers.html#sec-floating_point_numbers",
    "href": "nmNumbers.html#sec-floating_point_numbers",
    "title": "1¬† Numbers",
    "section": "1.2 Floating Point Numbers",
    "text": "1.2 Floating Point Numbers\nIn this section we will discuss how a computer actually stores a number. More specifically, since computers only have finite memory, we would really like to know the full range of numbers that are possible to store in a computer. Clearly, given the uncountable nature of the real numbers, there will be gaps between the numbers that can be stored. We would like to know what gaps in our number system to expect when using a computer to store and do computations on numbers. For this it is important to know that computers store numbers in a way that is similar to how we write numbers in scientific notation.\n\n\nExample 1.3 Let us start the discussion with a very concrete example. Consider the number \\(x = -123.15625\\) (in base 10). As we have seen this number can be converted into binary. Indeed\n\\[x = -123.15625_{10} = -1111011.00101_2\\]\n(you should check this).\nIf a computer needs to store this number then first they put in the binary version of scientific notation. In this case this will be\n\\[\nx = -1.11101100101_2 \\times 2^{6}.\n\\] This is the floating point representation of the number.\n\n\n\nDefinition 1.1 For any non-zero base-2 number \\(x\\) the floating point representation is given by\n\\[x = (-1)^{s} \\times (1+ m) \\times 2^E\\]\nwhere \\(s \\in \\{0,1\\}\\), \\(m\\) is a binary number such that \\(0 \\le m &lt; 1\\), and \\(E\\) is an integer.\nThe number \\(1+m\\) is called the significand, \\(s\\) is known as the sign bit, and \\(E\\) is known as the exponent. We will refer to \\(m\\), the fractional part of the significand that actually contains the information, as the mantissa, but this use is not universal.\n\nTo allow for both very large and very small numbers, the exponent \\(E\\) can be positive or negative. However, inside the computer it is efficiently stored as an unsigned integer \\(e\\) called the biased exponent. The true exponent \\(E\\) is obtained by subtracting a fixed bias \\(B\\) from \\(e\\): \\[ E = e - B. \\] The bias is chosen to be roughly half of the maximum possible value of the stored exponent \\(e\\).\n\n\nExample 1.4 What are the mantissa, sign bit, and unbiased exponent for the numbers \\(7_{10}, -7_{10}\\), and \\((0.1)_{10}\\)?\nSolution:\n\nFor the number \\(7_{10}=111_2 = 1.11 \\times 2^2\\) we have \\(s=0, m=0.11\\) and \\(E=2\\).\nFor the number \\(-7_{10}=111_2 = -1.11 \\times 2^2\\) we have \\(s=1, m=0.11\\) and \\(E=2\\).\nFor the number \\(\\frac{1}{10} = 0.000110011001100\\cdots = 1.100110011\\cdots \\times 2^{-4}\\) we have \\(s=0, m=0.100110011\\cdots\\), and \\(E = -4\\).\n\n\n\nIn the last part of the previous example we saw that the number \\((0.1)_{10}\\) is actually a repeating decimal in base-2. This means that in order to completely represent the number \\((0.1)_{10}\\) in base-2 we need infinitely many decimal places. Obviously that cannot happen since we are dealing with computers with finite memory. Each number can only be allocated a finite number of bits. Thus the number needs to be rounded to the nearest number that can be represented with that number of bits. That leads to an error called the rounding error (sometimes also called roundoff error). We‚Äôll look into these in more detail in Section 1.3 below.\n\n\nDefinition 1.2 Machine precision is the gap between the number 1 and the next larger floating point number. Often it is represented by the symbol \\(\\epsilon\\). To clarify: the number 1 can always be stored in a computer system exactly and if \\(\\epsilon\\) is machine precision for that computer then \\(1+\\epsilon\\) is the next largest number that can be stored with that machine.\n\n\nFor all practical purposes the computer cannot tell the difference between two numbers if the relative difference is smaller than machine precision. It is important to remember this when you want to check the equality of two numbers in a computer.\n\nExercise 1.13 üñã üéì To make all of these ideas concrete let us play with a small computer system where each number is stored in the following format, using 6 bits:\n\\[s \\, e_1\\, e_2 \\, b_1 \\, b_2 \\, b_3\\]\nThe first bit is for the sign (\\(0=+\\) and \\(1=-\\)). The next two bits, \\(e_1\\) and \\(e_2\\) are for the biased exponent, and we will assume in this example that the bias is \\(B=1\\). The three bits on the right represent the significand of the number. Hence, every number in this number system takes the form\n\\[\n(-1)^s \\times (1+ 0.b_1b_2b_3) \\times 2^{e_1e_2-1}\n\\]\n\nWhat is the smallest positive number that can be represented in this form?\nWhat is the largest positive number that can be represented in this form?\nWhat is the machine precision in this number system?\n\n\n\nOver the course of the past several decades there have been many systems developed to properly store numbers. The IEEE standard that we now use is the accumulated effort of many computer scientists, much trial and error, and deep scientific research. We now have two standard precisions for storing numbers on a computer: single and double precision. The double precision standard is what most of our modern computers use.\n\nDefinition 1.3 According to the IEEE 754 standard:\n\nA single-precision number consists of 32 bits, with 1 bit for the sign, 8 for the exponent, and 23 for the mantissa. The bias is \\(B=127\\).\nA double-precision number consists of 64 bits with 1 bit for the sign, 11 for the exponent, and 52 for the mantissa. The bias is \\(B=1023\\).\n\n\n\n\nExercise 1.14 üñã What are the largest numbers that can be stored in single and double precision?\n\n\n\nExercise 1.15 üñã What is machine precision for the single and double precision standard?\n\n\n\nExercise 1.16 üñã üéì What is the gap between \\(2^n\\) and the next largest number that can be stored in double precision?\n\n\n\nExercise 1.17 üñã Computers contain hardware that can perform the basic operations of addition, subtraction, multiplication, and division on floating point numbers. To get a feel for what goes on under the hood, figure out how to add the numbers \\(x = 1.010_2 \\times 2^3\\) and \\(y = 1.110_2 \\times 2^1\\). How do you deal with the different exponents? What do you do so that the result is in the correct floating point format?\n\n\nMuch more can be said about floating point numbers such as how we store infinity, how we store NaN, and how we store 0. The Wikipedia page for floating point arithmetic might be of interest for the curious reader. It is beyond the scope of this module to go into all of those details here.\nThe biggest takeaway points from this section and the previous are:\n\nReal numbers are stored with finite precision in a computer.\nNice rational numbers like 0.1 are sometimes not machine representable in binary.\nMachine precision is the gap between 1 and the next largest number that can be stored.\nThe gap between one number and the next grows in proportion to the number.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmNumbers.html#sec-rounding_errors",
    "href": "nmNumbers.html#sec-rounding_errors",
    "title": "1¬† Numbers",
    "section": "1.3 Rounding Errors",
    "text": "1.3 Rounding Errors\nWhen the binary representation of a real number has too many binary digits to be represented faithfully by a floating point number, we need to round it to the nearest floating point number that can be represented. That introduces rounding errors. We have seen above that the gap between two consecutive floating point numbers grows in proportion to the number. This means that the relative error of rounding is bounded by \\(\\epsilon/2\\) where \\(\\epsilon\\) is the machine precision.\nThe rounding rule that is used is ‚Äúround to nearest, ties to even‚Äù, which means that if the number is exactly halfway between two numbers that can be represented then we round the mantissa to an even binary number, i.e., to a mantissa that ends in 0.\n\nExample 1.5 If we want to store the number \\(1.625 = 1.101_2\\) in a floating point number system where the mantissa has only 2 bits then we round to \\(1.10_2 = 1.5_{10}\\) because \\(1.101_2\\) is exactly halfway between \\(1.100_2\\) and \\(1.110_2\\) and the rounding rule is ‚Äúround to nearest, ties to even‚Äù.\n\n\nTo dive a little deeper into what happened in Exercise¬†1.3, simplify the detailed analysis by working with only a 4 bit mantissa:\n\nExercise 1.18 üñã Write down how the number \\(1/10\\) is represented in a floating point number system where the mantissa has only 4 bits. Then calculate the first 10 terms of the sequence \\[\\begin{equation}\nx_{n+1} = \\left\\{ \\begin{array}{ll} 2x_n, & x_n \\in [0,\\frac{1}{2}] \\\\ 2x_n - 1, & x_n \\in\n        (\\frac{1}{2},1] \\end{array} \\right. \\quad \\text{with} \\quad x_0 = \\frac{1}{10}\n\\end{equation}\\] using this number system.\n\n\n\nExercise 1.19 (This problem is modified from (Greenbaum and Chartier 2012))\nüíª Sometimes floating point arithmetic does not work like we would expect (and hope) as compared to exact mathematics. In each of the following problems we have a mathematical problem that the computer gets wrong. Explain why the computer is getting these wrong.\n\nMathematically we know that \\(\\sqrt{5}^2\\) should just give us \\(5\\) back. In Python type np.sqrt(5)**2 == 5. What do you get and why do you get it?\nMathematically we know that \\(49\\cdot \\left( \\frac{1}{49} \\right)\\) should just be 1. In Python type 49*(1/49) == 1. What do you get and why do you get it?\nMathematically we know that \\(e^{\\log(3)}\\) should just give us 3 back. In Python type np.exp(np.log(3)) == 3. What do you get and why do you get it?\nCreate your own example of where Python gets something incorrect because of floating point arithmetic.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmNumbers.html#sec-loss_of_significant_digits",
    "href": "nmNumbers.html#sec-loss_of_significant_digits",
    "title": "1¬† Numbers",
    "section": "1.4 Loss of Significant Digits",
    "text": "1.4 Loss of Significant Digits\nAs we have discussed, when representing real numbers by floating point numbers in the computer, rounding errors will usually occur. When doing a calculation with double-precision floating point numbers then the rounding error is only a tiny fraction of the actual number, so one might think that they really don‚Äôt matter. However, calculations usually involve a number of steps, and we saw in Exercise¬†1.3 that the rounding errors can accumulate and become quite noticeable after a large number of steps.\nBut the problem is even worse. If we are not careful, then the rounding errors can get magnified already after very few steps if we perform the steps in an unfortunate way. The following examples and exercises will illustrate this.\n\n\nExample 1.6 Consider the expression \\[\n(10^{10} + 0.123456789) - 10^{10}.\n\\] Mathematically, this is strictly equal to \\[\n(10^{10}  - 10^{10}) + 0.123456789=0.123456789.\n\\] However, let us evaluate this in Python:\n\n10**10 + 0.123456789 - 10**10\n\n0.12345695495605469\n\n\nOnly the first six digits after the decimal point were preserved, the other digits were replaced by something seemingly random. The reason should be clear. The computer makes a rounding error when it tries to store the \\(10000000000.123456789\\). This is known as the loss of significant digits. It occurs whenever you subtract two almost equal numbers from each other.\n\n\n\nExercise 1.20 üñã Consider these two mathematically equivalent ways to compute the same thing:\n\n\\((a + b) - c\\)\n\\(a + (b - c)\\)\n\n\nWhy might these give different results in floating-point arithmetic?\nIf \\(a\\) is very small compared to \\(b\\) and \\(c\\), which form would you expect to be more accurate? Why?\n\n\n\n\nExercise 1.21 üíª Consider the trigonometric identity\n\\[\n2\\sin^2(x/2) = 1 - \\cos(x).\n\\] It gives us two different methods to calculate the same quantity. Ask Python to evaluate both sides of the identity when \\(x=0.0001\\). Hint: as described in Section A.2.8, use import math so that you can then use math.cos() and math.sin(). Also remember that exponentiation in Python is represented by **.\nüí¨ What do you observe? If you want to calculate \\(1 - \\cos(x)\\) with the highest precision, which expression would you use? Discuss.\n\n\n\nExercise 1.22 üíª üñã üí¨ You know how to find the solutions to the quadratic equation \\[\na x^2+bx+c=0.\n\\] You know the quadratic formula. For the larger of the two solutions the formula is \\[\nx = \\frac{-b+\\sqrt{b^2-4ac}}{2a}.\n\\] Let‚Äôs assume that the parameters are given as \\[ a = 1,~~~b = 1000000, ~~~ c = 1.\\] Use the quadratic formula to find the larger of the two solutions, by coding the formula up in Python. You should get a solution slightly smaller than \\(-10^{-6}\\). Hint: use math.sqrt() to code up the square root.\nThen check whether your value for \\(x\\) really does solve the quadratic equation by evaluating \\(ax^2+bx+c\\) with your value of \\(x\\). You will notice that it does not work. Discuss the cause of the error.\nNow, on a piece of paper, rearrange the quadratic formula for the larger solution by multiplying both the numerator and denominator by \\(-b-\\sqrt{b^2-4ac}\\) and then simplify by multiplying out the resulting numerator. This should give you the alternative formula \\[\nx = \\frac{2c}{-b-\\sqrt{b^2-4ac}}.\n\\] Can you see why this expression will work better for the given parameter values? Again evaluate \\(x\\) with Python and then check it by substituting into the quadratic expression. What do you find?\n\n\n\nExercise 1.23 üíª üí¨ Google the term ‚Äúcatastrophic cancellation‚Äù to find more examples of this phenomenon of loss of significant digits.\n\n\nThese exercises will give much material for in-class discussion. The aim is to make you sensitive to the issue of loss of significant figures and the fact that expressions that are mathematically equal are not always computationally equal.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmNumbers.html#exam-style-question",
    "href": "nmNumbers.html#exam-style-question",
    "title": "1¬† Numbers",
    "section": "1.5 Exam-style question",
    "text": "1.5 Exam-style question\nConsider a hypothetical ‚Äú8-bit Mini-Float‚Äù system based on the IEEE 754 standard. The 8 bits are allocated as follows:\n\nSign bit (\\(s\\)): 1 bit (Bit 7)\nExponent (\\(e\\)): 3 bits (Bits 6-4), using a bias of 3.\nMantissa (\\(m\\)): 4 bits (Bits 3-0), normalized with an implied leading 1.\n\nThe value of a number in this system is given by: \\(x = (-1)^s \\times (1.m)_2 \\times 2^{e-3}\\).\n\nHow is the machine precision \\(\\epsilon\\) defined. Give its value for this floating-point system. How is machine precision related to rounding errors? [3 marks]\nConvert the decimal number 13.5 into this 8-bit floating-point representation. Write your final answer as an 8-bit binary pattern (e.g., 0 101 1010). [4 marks]\nUsing this specific floating-point system, perform the addition of the number 13.5 (from part b) and 0.25.\n\nWrite 0.25 in this floating point system.\nPerform the addition simulating the hardware: align exponents, add significands.\nApply the rounding rule (‚ÄúRound to Nearest, Ties to Even‚Äù) to determine the final stored bits.\nWhat is the final decimal value stored by the system, and what is the absolute error compared to the exact mathematical sum? [4 marks]\n\nA student attempts to calculate the function \\(f(x) = \\sqrt{x^2 + 1} - x\\) for a very large value \\(x = 10^8\\).\n\nExplain why the result computed by a standard computer might be inaccurate (specifically naming the type of error).\nPropose an algebraically equivalent formula for \\(f(x)\\) that avoids this error. [3 marks]",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmNumbers.html#sec-approximation_problems",
    "href": "nmNumbers.html#sec-approximation_problems",
    "title": "1¬† Numbers",
    "section": "1.6 Problems",
    "text": "1.6 Problems\nThese problem exercises will let you consolidate what you have learned so far and combine it with your Python coding skills, see Appendix A.\n\n\nExercise 1.24 (This problem is modified from (Greenbaum and Chartier 2012))\nüñã üíª In the 1999 film Office Space, a character creates a program that takes fractions of cents that are truncated in a bank‚Äôs transactions and deposits them to his own account. This idea has been attempted in the past and now banks look for this sort of thing. In this problem you will build a simulation of the program to see how long it takes to become a millionaire.\nAssumptions:\n\nAssume that you have access to 50,000 bank accounts.\nAssume that the account balances are uniformly distributed between $100 and $100,000.\nAssume that the annual interest rate on the accounts is 5% and the interest is compounded daily and added to the accounts, except that fractions of cents are truncated.\nAssume that your illegal account initially has a $0 balance.\n\nYour Tasks:\n\nExplain what the code below does.\n\nimport numpy as np\naccounts = 100 + (100000-100) * np.random.rand(50000,1);\naccounts = np.floor(100*accounts)/100;\n\nBy hand (no computer) write the mathematical steps necessary to increase the accounts by (5/365)% per day, truncate the accounts to the nearest penny, and add the truncated amount into an account titled ‚Äúillegal.‚Äù\nWrite code to complete your plan from part 2.\nUsing a while loop, iterate over your code until the illegal account has accumulated $1,000,000. How long does it take?\n\n\n\n\nExercise 1.25 (This problem is modified from (Greenbaum and Chartier 2012))\nüñã In the 1991 Gulf War, the Patriot missile defence system failed due to rounding error. The troubles stemmed from a computer that performed the tracking calculations with an internal clock whose integer values in tenths of a second were converted to seconds by multiplying by a 24-bit binary approximation to \\(\\frac{1}{10}\\): \\[\\begin{equation}\n0.1_{10} \\approx 0.00011001100110011001100_2.\n\\end{equation}\\]\n\nConvert the binary number above to a fraction by hand.\nThe approximation of \\(\\frac{1}{10}\\) given above is clearly not equal to \\(\\frac{1}{10}\\). What is the absolute error in this value?\nWhat is the time error, in seconds, after 100 hours of operation?\nDuring the 1991 war, a Scud missile travelled at approximately Mach 5 (3750 mph). Find the distance that the Scud missile would travel during the time error computed in part 3.\n\n\n\n\nExercise 1.26 (The Python Caret Operator) üñã üíª Now that you‚Äôre used to using Python to do some basic computations you are probably comfortable with the fact that the caret, ^, does NOT do exponentiation like it does in many other programming languages. But what does the caret operator do? That‚Äôs what we explore here.\n\nConsider the numbers \\(9\\) and \\(5\\). Write these numbers in binary representation. We are going to use four bits to represent each number (it is OK if the first bit happens to be zero). \\[\\begin{equation}\n\\begin{aligned} 9 &=& \\underline{\\hspace{0.2in}} \\, \\underline{\\hspace{0.2in}} \\, \\underline{\\hspace{0.2in}} \\, \\underline{\\hspace{0.2in}} \\\\ 5 &=& \\underline{\\hspace{0.2in}} \\, \\underline{\\hspace{0.2in}} \\, \\underline{\\hspace{0.2in}} \\, \\underline{\\hspace{0.2in}} \\end{aligned}\n\\end{equation}\\]\nNow go to Python and evaluate the expression 9^5. Convert Python‚Äôs answer to a binary representation (again using four bits).\nMake a conjecture: How do we go from the binary representations of \\(a\\) and \\(b\\) to the binary representation for Python‚Äôs a^b for numbers \\(a\\) and \\(b\\)? Test and verify your conjecture on several different examples and then write a few sentences explaining what the caret operator does in Python.\n\n\n\n\n\n\nGreenbaum, Anne, and Tim P. Chartier. 2012. Numerical Methods: Design, Analysis, and Computer Implementation of Algorithms. Princeton University Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html",
    "href": "nmFunctions.html",
    "title": "2¬† Functions",
    "section": "",
    "text": "2.1 Polynomial Approximations\nHow does a computer understand a function like \\(f(x) = e^x\\) or \\(f(x) = \\sin(x)\\) or \\(f(x) = \\log(x)\\)? What happens under the hood, so to speak, when you ask a computer to do a computation with one of these functions? A computer is good at arithmetic operations, but working with transcendental functions like these, or really any other sufficiently complicated functions for that matter, is not something that comes naturally to a computer. What is actually happening under the hood is that the computer only approximates the functions.\nA class of functions that computers are very good at working with are polynomial functions. This is because to evaluate a polynomial function at any point we only need to addition and multiplication operations. In this section we will explore how we can use polynomial functions to approximate other functions.\nIn the previous 3 exercises you have built up some basic intuition for what we would want out of a mathematical operation that might build an approximation of a complicated function. What we have built is actually a way to get better and better approximations for functions out to pretty much any arbitrary accuracy that we like so long as we are near some anchor point (which we called \\(x_0\\) in the previous exercises).\nIn the next several problems you will unpack the polynomial approximations of \\(f(x) = e^x\\) and we will wrap the whole discussion with a little bit of formal mathematical language. Then we will examine other functions like \\(\\sin(x)\\) and \\(\\log(x)\\). One of the points of this whole discussion is to give you a little glimpse as to what is happening behind the scenes in scientific programming languages when you do computations with these functions. A bigger point is to start getting a feel for how we might go in reverse and approximate an unknown function out of much simpler parts. This last goal is one of the big takeaways from numerical analysis: we can mathematically model highly complicated functions out of fairly simple pieces.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "nmRoots1.html",
    "href": "nmRoots1.html",
    "title": "3¬† Roots 1",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Roots 1</span>"
    ]
  },
  {
    "objectID": "nmRoots2.html",
    "href": "nmRoots2.html",
    "title": "4¬† Roots 2",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Roots 2</span>"
    ]
  },
  {
    "objectID": "nmCalculus.html",
    "href": "nmCalculus.html",
    "title": "5¬† Derivatives, Integrals",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Derivatives, Integrals</span>"
    ]
  },
  {
    "objectID": "nmOptimisation.html",
    "href": "nmOptimisation.html",
    "title": "6¬† Optimisation",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Optimisation</span>"
    ]
  },
  {
    "objectID": "nmODE1.html",
    "href": "nmODE1.html",
    "title": "7¬† ODEs 1",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>ODEs 1</span>"
    ]
  },
  {
    "objectID": "nmODE2.html",
    "href": "nmODE2.html",
    "title": "8¬† ODEs 2",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>ODEs 2</span>"
    ]
  },
  {
    "objectID": "nmPDE1.html",
    "href": "nmPDE1.html",
    "title": "9¬† PDEs 1",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>PDEs 1</span>"
    ]
  },
  {
    "objectID": "nmPDE2.html",
    "href": "nmPDE2.html",
    "title": "10¬† PDEs 2",
    "section": "",
    "text": "In preparation.",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>PDEs 2</span>"
    ]
  },
  {
    "objectID": "nmPython.html",
    "href": "nmPython.html",
    "title": "Appendix A ‚Äî Python",
    "section": "",
    "text": "A.1 Why Python?\nIn this appendix we will walk through some of the basics of using Python ‚Äî the popular general-purpose programming language that we will use throughout this module.\nFor most of you this material will not be new. For example, you have probably seen it in your first year ‚ÄúMathematical Programming & Skills‚Äù module. But for some of you this may be entirely new. You will have some notion of what a programming language ‚Äúis‚Äù and ‚Äúdoes‚Äù, but you may never have written any code. That is all right.\nIf you are new to Python, don‚Äôt feel that you need to work through this appendix in one go. Instead, spread the work over the first two weeks of the course and interlace it with your work on the first two chapters.\nThere is a lot of material in this appendix. Do not feel that you need to learn it all by hard. The idea is just that you should have seen the various language constructs once. Your familiarity with them will come automatically later when you use them throughout the course.\nWe are going to be using Python since\nIt is important to keep in mind that Python is a general purpose language that we will be using for Scientific Computing. The purpose of Scientific Computing is not to build apps, build software, manage databases, or develop user interfaces. Instead, Scientific Computing is the use of a computer programming language (like Python) along with mathematics to solve scientific and mathematical problems. For this reason it is definitely not our purpose to write an all-encompassing guide for how to use Python. We will only cover what is necessary for our computing needs. You will learn more as the course progresses, so use this appendix just to get going with the language. To keep things as simple as possible, we will for example not use object oriented programming, so will not introduce classes and methods.\nWe are also definitely not saying that Python is the best language for scientific computing under all circumstances. The reason there are so many scientific programming languages coexisting is that each has particular strengths that make it the best option for particular applications. But we are saying that Python is so widely used that everyone should know Python.\nThere is an overwhelming abundance of information available about Python and the suite of tools that we will frequently use.\nThese tools together provide all of the computational power that we will need. And they are free!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#sec-why_python",
    "href": "nmPython.html#sec-why_python",
    "title": "Appendix A ‚Äî Python",
    "section": "",
    "text": "Python is free,\nPython is very widely used,\nPython is flexible,\nPython is relatively easy to learn,\nand Python is quite powerful.\n\n\n\n\n\nPython https://www.python.org/,\nnumpy (numerical Python) https://www.numpy.org/,\nmatplotlib (a suite of plotting tools) https://matplotlib.org/,\nscipy (scientific Python) https://www.scipy.org/.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#sec-python_basics",
    "href": "nmPython.html#sec-python_basics",
    "title": "Appendix A ‚Äî Python",
    "section": "A.2 Python Programming Basics",
    "text": "A.2 Python Programming Basics\nIf you are already very practised in using Python then you can jump straight to Section A.6 with the coding exercises. But if you are new to Python or your Python skills are a bit rusty, then you will benefit from working through all the examples and exercises below, making sure you copy and paste all the code into your Colab notebook and run it there, and then critically evaluate and understand the output.\n\nA.2.1 Variables\nVariable names in Python can contain letters (lower case or capital), numbers 0-9, and some special characters such as the underscore. Variable names must start with a letter. There are a bunch of reserved words that you can not use for your variable names because they have a special meaning in the Python syntax. Python will let you know with a syntax error if you try to use a reserved word for a variable name.\nYou can do the typical things with variables. Assignment is with an equal sign (be careful R users, we will not be using the left-pointing arrow here!).\nWarning: When defining numerical variables you do not always get floating point numbers. In some programming languages, if you write x=1 then automatically x is saved as 1.0; a floating point number, not an integer. In Python however, if you assign x=1 it is defined as an integer (with no decimal digits) but if you assign x=1.0 it is assigned as a floating point number.\n# assign some variables\nx = 7 # integer assignment of the integer 7\ny = 7.0 # floating point assignment of the decimal number 7.0\nprint(\"The variable x has the value\", x, \" and has type\", type(x), \". \\n\")\nprint(\"The variable y has the value\", y, \" and has type\", type(y), \". \\n\")\nRemember to copy each code block to your own notebook, execute it and look at the output. To copy the code from this guide to your notebook you can use the ‚ÄúCopy to Clipboard‚Äù icon that pops up in the top right corner of a code block when you hover over that code block.\n# multiplying by a float will convert an integer to a float\nx = 7 # integer assignment of the integer 7\nprint(\"Multiplying x by 1.0 gives\", 1.0*x)\nprint(\"The type of this value is\", type(1.0*x), \". \\n\")\nThe allowed mathematical operations are:\n\nAddition: +\nSubtraction: -\nMultiplication: *\nDivision: /\nInteger Division (modular division): // and %\nExponents: **\n\nThat‚Äôs right, the caret key, ^, is NOT an exponent in Python (sigh). Instead we have to get used to ** for exponents.\nx = 7.0\ny = x**2 # square the value in x\ny\n\n\nExercise A.1 Write code to define positive integers \\(a,b\\) and \\(c\\) of your own choosing. Then calculate \\(a^2, b^2\\) and \\(c^2\\). When you have all three values computed, check to see if your three values form a Pythagorean Triple so that \\(a^2 + b^2 = c^2\\). Have Python simply say True or False to verify that you do, or do not, have a Pythagorean Triple defined.¬†Hint: You will need to use the == Boolean check just like in other programming languages.\n\n\n\n\nA.2.2 Indexing and Lists\nLists are a key component to storing data in Python. Lists are exactly what the name says: lists of things (in our case, usually the entries are floating point numbers).\nWarning: Python indexing starts at 0 whereas some other programming languages have indexing starting at 1. In other words, the first entry of a list has index 0, the second entry as index 1, and so on. We just have to keep this in mind.\nWe can extract a part of a list using the syntax name[start:stop] which extracts elements between index start and stop-1. Take note that Python stops reading at the second to last index. This often catches people off guard when they first start with Python.\n\n\nExample A.1 (Lists and Indexing) Let us look at a few examples of indexing from lists. In this example we will use the list of numbers 0 through 8. This list contains 9 numbers indexed from 0 to 8.\n\nCreate the list of numbers 0 through 8\n\nmy_list = [0,1,2,3,4,5,6,7,8]\n\nOutput the list\n\nmy_list\n\nSelect only the element with index 0.\n\nmy_list[0]\n\nSelect all elements up to, but not including, the third element of my_list.\n\nmy_list[:2]\n\nSelect the last element of my_list (this is a handy trick!).\n\nmy_list[-1] \n\nSelect the elements indexed 1 through 4. Beware! This is not the first through fifth element.\n\nmy_list[1:5] \n\nSelect every other element in the list starting with the first.\n\nmy_list[0::2]\n\nSelect the last three elements of my_list\n\nmy_list[-3:]\n\n\nIn Python, elements in a list do not need to be the same type. You can mix integers, floats, strings, lists, etc.\n\nExample A.2 In this example we see a list of several items that have different data types: float, integer, string, and complex. Note that the imaginary number \\(i\\) is represented by \\(1j\\) in Python. This use of \\(j\\) instead of \\(i\\) is common in some scientific disciplines and is just another thing that we Mathematicians will need to get used to in Python.\nMixedList = [1.0, 7, 'Bob', 1-1j]\nprint(MixedList)\nprint(type(MixedList[0]))\nprint(type(MixedList[1]))\nprint(type(MixedList[2]))\nprint(type(MixedList[3])) \n# Notice that we use 1j for the imaginary number \"i\".\n\n\n\nExercise A.2 In this exercise you will put your new list skills into practice.\n\nCreate the list of the first several Fibonacci numbers: \\[\\begin{equation}\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89.\n\\end{equation}\\]\nPrint the first four elements of the list.\nPrint every third element of the list starting from the first.\nPrint the last element of the list.\nPrint the list in reverse order.\nPrint the list starting at the last element and counting backward by every other element.\n\n\n\n\n\nA.2.3 List Operations\nPython is awesome about allowing you to do things like appending items to lists, removing items from lists, and inserting items into lists. Note in all of the examples below that we are using the code\nvariable.method\nwhere you put the variable name, a dot, and the thing that you would like to do to that variable. For example, my_list.append(7) will append the number 7 to the list my_list. We say that append is a ‚Äúmethod‚Äù of the list my_list. This is a common programming feature in Python and we will use it often.\n\n\nExample A.3 The .append method can be used to append an element to the end of a list.\nmy_list = [0,1,2,3]\nprint(my_list)\n# Append the string 'a' to the end of the list\nmy_list.append('a') \nprint(my_list)\n# Do it again ... just for fun\nmy_list.append('a') \nprint(my_list)\n# Append the number 15 to the end of the list\nmy_list.append(15) \nprint(my_list)\n\n\n\nExample A.4 The .remove method can be used to remove an element from a list.\n# Let us remove the 3\nmy_list.remove(3)\nmy_list\n\n\n\nExample A.5 The .insert method can be used to insert an element at a location in a list.\n# insert the letter `A` at the 0-indexed spot\nmy_list.insert(0,'A') \n# insert the letter `B` at the spot with index 3 \nmy_list.insert(3,'B') \n# remember that index 3 means the fourth spot in the list\nmy_list\n\n\n\nExercise A.3 In this exercise you will go a bit further with your list operation skills.\n\nCreate the list of the first several Lucas Numbers: \\(1,3,4,7,11,18,29,47.\\)\nAdd the next three Lucas Numbers to the end of the list.\nRemove the number 3 from the list.\nInsert the 3 back into the list in the correct spot.\nPrint the list in reverse order.\nDo a few other list operations to this list and report your findings.\n\n\n\n\n\nA.2.4 Tuples\nIn Python, a ‚Äútuple‚Äù is like an ordered pair (or ordered triple, or ordered quadruple, ...) in mathematics. We will occasionally see tuples in our work in numerical analysis so for now let us just give a couple of code snippets showing how to store and read them.\nWe can define the tuple of numbers \\((10,20)\\) in Python as follows:\n\nExample A.6 ¬†\npoint = 10, 20 \nprint(point, type(point))\nWe can also define a tuple with parenthesis if we like. Python does not care.\npoint = (10, 20) # now we define the tuple with parenthesis\nprint(point, type(point))\nWe can then unpack the tuple into components if we wish:\nx, y = point\nprint(\"x = \", x)\nprint(\"y = \", y)\n\nThere are other important data structures in Python that we will not use in this module. These include dictionaries and sets. We will not cover these here because we are trying to keep things simple so that we can concentrate on Numerical Analysis instead. If you are interested in learning more about these data structures, you can find a lot of information about them in the Python documentation.\n\n\nA.2.5 Control Flow: Loops and If Statements\nAny time you need to do some repetitive task with a programming language you can use a loop. Just like in other programming languages, we can do loops and conditional statements in very easy ways in Python. The thing to keep in mind is that the Python language is very white-space-dependent. This means that your indentations need to be correct in order for a loop to work. You could get away with sloppy indention in other languages but not so in Python. Also, in some languages (like R and Java) you need to wrap your loops in curly braces. Again, not so in Python.\nCaution: Be really careful of the white space in your code when you write loops.\n\nA.2.5.1 for Loops\nA for loop is designed to do a task a certain number of times and then stop. This is a great tool for automating repetitive tasks, but it also nice numerically for building sequences, summing series, or just checking lots of examples. The following are some examples of Python for loops.\n\nExample A.7 Print the first 6 perfect squares.\nfor x in [1,2,3,4,5,6]:\n    print(x**2)\nOften instead of writing the list of integers explicitly one uses the range() function, so that this example would be written as\nfor x in range(1,7):\n    print(x**2)\nNote that range(1,7) produces the integers from 1 to 6, not from 1 to 7. This is another manifestation of Python‚Äôs weird 0-based indexing. Of course it is only weird to people who are new to Python. For Pythonists it is perfectly natural.\nYou can also use range() to generate a sequence of numbers with a specific step size. For example, range(1, 10, 2) will generate the odd integers from 1 to 9.\nfor x in range(1, 10, 2):\n    print(x)\n\n\nTake careful note of the syntax for a for loop as it is the same as for other loops and conditional statements:\n\na control statement,\na colon, a new line,\nindent four spaces,\nsome programming statements\n\nWhen you are done with the loop, just back out of the indention. There is no need for an end command or a curly brace. All of the control statements in Python are white-space-dependent.\n\n\nExample A.8 Print the names in a list.\nNamesList = ['Alice','Billy','Charlie','Dom','Enrique','Francisco']\nfor name in NamesList:\n    print(name)\n\n\nIn Python you can use a more compact notation for for loops sometimes. This takes a bit of getting used to, but is super slick!\n\n\nExample A.9 Create a list of the perfect squares from 1 to 9.\n# create a list of the perfect squares from 1 to 9\nCoolList = [x**2 for x in range(1,10)]\nprint(CoolList)\n# Then print the sum of this list\nprint(\"The sum of the first 9 perfect squares is\", sum(CoolList))\n\n\nfor loops can also be used to build sequences, as can be seen in the next couple of examples.\n\n\nExample A.10 In the following code we write a for loop that outputs a list of the first 7 iterations of the sequence \\(x_{n+1}=-0.5x_n+1\\) starting with \\(x_0=3\\). Notice that we are using the command x.append instead of \\(x[n+1]\\) to append the new term to the list. This allows us to grow the length of the list dynamically as the loop progresses.\nx=[3.0]\nfor n in range(0,7):\n    x.append(-0.5*x[n] + 1)\n    print(x) # print the whole list x at each step of the loop\n\n\n\nExample A.11 As an alternative to the code from the previous example we can pre-allocate the memory in a list of zeros. This is done with the clever code x = [0] * 10. Literally multiplying a list by some number, like 10, says to repeat that list 10 times.\nNow we will build the sequence with pre-allocated memory.\nx = [0] * 7\nx[0] = 3.0\nfor n in range(0,6):\n    x[n+1] = -0.5*x[n]+1\n    print(x) # This print statement shows x at each iteration\n\n\n\nExercise A.4 We want to sum the first 100 perfect cubes. Let us do this in two ways.\n\nStart off a variable called total at 0 and write a for loop that adds the next perfect cube to the running total.\nWrite a for loop that builds the sequence of the first 100 perfect cubes. After the list has been built find the sum with the sum() function.\n\nThe answer is: 25,502,500 so check your work.\n\n\n\nExercise A.5 Write a for loop that builds the first 20 terms of the sequence \\(x_{n+1}=1-x_n^2\\) with \\(x_0=0.1\\). Pre-allocate enough memory in your list and then fill it with the terms of the sequence. Only print the list after all of the computations have been completed.\n\n\n\n\nA.2.5.2 while Loops\nA while loop repeats some task (or sequence of tasks) while a logical condition is true. It stops when the logical condition turns from true to false. The structure in Python is the same as with for loops.\n\n\nExample A.12 Print the numbers 0 through 4 and then the word ‚Äúdone.‚Äù we will do this by starting a counter variable, i, at 0 and increment it every time we pass through the loop.\ni = 0\nwhile i &lt; 5:\n    print(i)\n    i += 1 # increment the counter\nprint(\"done\")\n\n\n\nExample A.13 Now let us use a while loop to build the sequence of Fibonacci numbers and stop when the newest number in the sequence is greater than 1000. Notice that we want to keep looping until the condition that the last term is greater than 1000 ‚Äì this is the perfect task for a while loop, instead of a for loop, since we do not know how many steps it will take before we start the task\nFib = [1,1]\nwhile Fib[-1] &lt;= 1000:\n    Fib.append(Fib[-1] + Fib[-2])\nprint(\"The last few terms in the list are:\\n\",Fib[-3:])\n\n\n\nExercise A.6 Write a while loop that sums the terms in the Fibonacci sequence until the sum is larger than 1000\n\n\n\n\nA.2.5.3 if Statements\nConditional (if) statements allow you to run a piece of code only under certain conditions. This is handy when you have different tasks to perform under different conditions.\n\n\nExample A.14 Let us look at a simple example of an if statement in Python.\nName = \"Alice\"\nif Name == \"Alice\":\n    print(\"Hello, Alice.  Isn't it a lovely day to learn Python?\")\nelse:\n    print(\"You're not Alice.  Where is Alice?\")\nName = \"Billy\"\nif Name == \"Alice\":\n    print(\"Hello, Alice.  Isn't it a lovely day to learn Python?\")\nelse:\n    print(\"You're not Alice.  Where is Alice?\")\n\n\n\nExample A.15 For another example, if we get a random number between 0 and 1 we could have Python print a different message depending on whether it was above or below 0.5. Run the code below several times and you will see different results each time.\nNote: We have to import the numpy package to get the random number generator in Python. Do not worry about that for now. We will talk about packages in a moment.\nimport numpy as np\nx = np.random.uniform() # get a random number between 0 and 1\nif x &lt; 0.5:\n    print(x,\" is less than a half\")\nelse:\n    print(x, \"is NOT less than a half\")\n(Take note that the output will change every time you run it.)\n\n\n\nExample A.16 In many programming tasks it is handy to have several different choices between tasks instead of just two choices as in the previous examples. This is a job for the elif command.\nThis is the same code as last time except we will make the decision at 0.33 and 0.67.\nimport numpy as np\nx = np.random.rand(1,1) # get a random 1x1 matrix using numpy\nx = x[0,0] # pull the entry from the first row and first column\nif x &lt; 0.33:\n    print(x,\" &lt; 1/3\")\nelif x &lt; 0.67:\n    print(\"1/3 &lt;= \",x,\"&lt; 2/3\")\nelse:\n    print(x, \"&gt;= 2/3\")\n(Take note that the output will change every time you run it.)\n\n\n\nExercise A.7 Write code to give the Collatz Sequence \\[\\begin{equation}\nx_{n+1} = \\left\\{ \\begin{array}{ll} x_n / 2, & \\text{$x_n$ is even} \\\\ 3 x_n + 1, & \\text{otherwise} \\end{array} \\right.\n\\end{equation}\\] starting with a positive integer of your choosing. The sequence will converge1 to 1 so your code should stop when the sequence reaches 1.\nHints: To test whether a number x is even you can test whether the remainder after dividing by 2 is zero with (x % 2) == 0. Also you will want to use the integer division // when calculating \\(x_n/2\\).\n\n\n\n\n\nA.2.6 Functions\nMathematicians and programmers talk about functions in very similar ways, but they are not exactly the same. When we say ‚Äúfunction‚Äù in a programming sense we are talking about a chunk of code that you can pass parameters and expect an output of some sort. This is not unlike the mathematician‚Äôs version. But unlike a mathematical function, a Python function can also have side effects, like plotting a graph for example. So Python‚Äôs definition of a function is a bit more flexible than that of a mathematician.\nIn Python, to define a function we start with def, followed by the function‚Äôs name, any input variables in parenthesis, and a colon. The indented code after the colon is what defines the actions of the function.\n\n\nExample A.17 The following code defines the polynomial \\(f(x) = x^3 + 3x^2 + 3x + 1\\) and then evaluates the function at a point \\(x=2.3\\).\ndef f(x):\n    return(x**3 + 3*x**2 + 3*x + 1)\nf(2.3)\n\n\nTake careful note of several things in the previous example:\n\nTo define the function we cannot just type it like we would see it one paper. This is not how Python recognizes functions.\nOnce we have the function defined we can call upon it just like we would on paper.\nWe cannot pass symbols into this type of function.2\n\n\n\nExercise A.8 Define the function \\(g(n) = n^2 + n + 41\\) as a Python function. Write a loop that gives the output for this function for integers from \\(n=0\\) to \\(n=39\\). Euler noticed that each of these outputs is a prime number (check this on your own). Will the function produce a prime for \\(n=40\\)? For \\(n=41\\)?\n\n\n\nExample A.18 One cool thing that you can do with functions is call them recursively. That is, you can call the same function from within the function itself. This turns out to be really handy in several mathematical situations.\nLet us define a function for the factorial. This function is naturally going to be recursive in the sense that it calls on itself!\ndef factorial(n):\n    if n==0:\n        return(1)\n    else:\n        return(n*factorial(n-1)) \n        # Note: we are calling the function recursively.\nWhen you run this code there will be no output. You have just defined the function so you can use it later, as follows:\nfactorial(12)\n\n\n\nExample A.19 For this next example let us define a function to calculate the next element in the sequence \\[\\begin{equation}\nx_{n+1} = \\left\\{ \\begin{array}{ll} 2x_n, & x_n \\in [0,0.5] \\\\ 2x_n - 1, & x_n \\in (0.5,1] \\end{array} \\right.\n\\end{equation}\\] and then build a loop to find the first several elements of the sequence starting at any real number between 0 and 1.\n# Define the function\ndef my_seq(xn):\n    if xn &lt;= 0.5:\n        return(2*xn)\n    else:\n        return(2*xn-1)\n# Now build a sequence with this function\nx = [0.125] # arbitrary starting point\nfor n in range(0,5): # Let us only build the first 5 terms\n    x.append(my_seq(x[n]))\nprint(x)\n\n\n\nExample A.20 A fun way to approximate the square root of two is to start with any positive real number and iterate over the sequence \\[\\begin{equation}\nx_{n+1} = \\frac{1}{2} x_n + \\frac{1}{x_n}\n\\end{equation}\\] until we are within any tolerance we like of the square root of \\(2\\). Write code that defines the sequence as a function and then iterates in a while loop until we are within \\(10^{-8}\\) of the square root of 2.\nWe import the math package so that we get the square root function. More about packages in the next section.\nfrom math import sqrt\ndef f(x):\n    return(0.5*x + 1/x)\nx = 1.1 # arbitrary starting point\nprint(f\"{'Approximation':&lt;20} | {'Exact':&lt;20} | {'Absolute error':&lt;20}\")\nprint(\"-\" * 68)\nwhile abs(x-sqrt(2)) &gt; 10**(-8):\n    x = f(x)\n    print(f\"{x:&lt;20} | {sqrt(2):&lt;20} | {abs(x - sqrt(2)):&lt;20}\")\nThis example also shows how to format the output of a print statement so that it is nicely aligned in columns. The :&lt;20 means that the string will be left-aligned and padded with spaces to a total width of 20 characters. The f before the string allows us to use curly braces {} to insert variables into the string. You will see an alternative way for displaying tabular data in Example¬†A.48.\n\n\n\nExercise A.9 The previous example is a special case of the Babylonian Algorithm for calculating square roots. If you want the square root of \\(S\\) then iterate the sequence \\[\\begin{equation}\nx_{n+1} = \\frac{1}{2} \\left(x_n + \\frac{S}{x_n} \\right)\n\\end{equation}\\] until you are within an appropriate tolerance.\nModify the code given in the previous example to give a list of approximations of the square roots of the natural numbers \\(2\\) through \\(20\\), each to within \\(10^{-8}\\). This problem will require that you build a function, write a ‚Äòfor‚Äô loop (for the integers \\(2\\) through \\(20\\)), and write a ‚Äòwhile‚Äô loop inside your ‚Äòfor‚Äô loop to do the iterations.\n\n\n\n\nA.2.7 Lambda Functions\nUsing def to define a function as in the previous subsection is really nice when you have a function that is complicated or requires some bit of code to evaluate. However, in the case of mathematical functions we have a convenient alternative: lambda Functions.\nThe basic idea of a lambda Function is that we just want to state what the variable is and what the rule is for evaluating the function. This is closest to the way that we write mathematical functions. For example, we can define the mathematical function \\(f(x) = x^2+3\\) in two different ways.\n\nUsing def:\n\ndef f(x):\n    return(x**2+3)\n\nUsing lambda:\n\nf = lambda x: x**2+3\nYou can see that in the Lambda Function we are explicitly stating the name of the variable immediately after the word lambda, then we put a colon, and then the function definition. This is somewhat similar to but also annoyingly different from the mathematicians notation \\(f:x \\mapsto x^2 + 3\\).\nNo matter whether we use def or lambda to define the function f, if we want to evaluate the function at a point, say \\(x=1.5\\), then we can write code just like we would mathematically: \\(f(1.5)\\)\nf(1.5) # evaluate the function at x=1.5\nWe can also define Lambda Functions of several variables. For example, if we want to define the mathematical function \\(f(x,y) = x^2 + xy + y^3\\) we could write the code\nf = lambda x, y: x**2 + x*y + y**3\nIf we wanted the value \\(f(2,4)\\) we would now write the code f(2,4).\n\n\nExercise A.10 Go back to Exercise¬†A.8 and repeat this exercise using a lambda function.\n\n\n\nExercise A.11 Go back to Exercise¬†A.9 and repeat this exercise using a lambda function.\n\n\n\n\nA.2.8 Packages\nPython was not created as a scientific programming language. The reason Python can be used for scientific computing is that there are powerful extension packages that define additional functions that are needed for scientific calculations.\nLet us start with the math package.\n\n\nExample A.21 The code below imports the math package into your instance of Python and calculates the cosine of \\(\\pi/4\\).\nimport math\nx = math.cos(math.pi / 4)\nprint(x)\nThe answer, unsurprisingly, is the decimal form of \\(\\sqrt{2}/2\\).\n\n\nYou might already see a potential disadvantage to Python‚Äôs packages: there is now more typing involved! Let us fix this. When you import a package you could just import all of the functions so they can be used by their proper names.\n\n\nExample A.22 Here we import the entire math package so we can use every one of the functions therein without having to use the math prefix.\nfrom math import * # read this as: from math import everything\nx = cos(pi / 4)\nprint(x)\nThe end result is exactly the same: the decimal form of \\(\\sqrt{2}/2\\), but now we had less typing to do.\n\n\nNow you can freely use the functions that were imported from the math package. There is a disadvantage to this, however. What if we have two packages that import functions with the same name. For example, in the math package and in the numpy package there is a cos() function. In the next block of code we will import both math and numpy, but instead we will import them with shortened names so we can type things a bit faster.\n\n\nExample A.23 Here we import math and numpy under aliases so we can use the shortened aliases and not mix up which functions belong to which packages.\nimport math as ma\nimport numpy as np\n# use the math version of the cosine function\nx = ma.cos(ma.pi / 4) \n# use the numpy version of the cosine function\ny = np.cos(np.pi / 4) \nprint(x, y)\nBoth x and y in the code give the decimal approximation of \\(\\sqrt{2}/2\\). This is clearly pretty redundant in this really simple case, but you should be able to see where you might want to use this and where you might run into troubles.\n\n\n\nExample A.24 (Contents of a package) Once you have a package imported you can see what is inside of it using the dir command. The following block of code prints a list of all of the functions inside the math package.\nimport math\nprint(dir(math))\n\n\nBy the way: you only need to import a package once in a session. The only reason we are repeating the import statement in each code block is to make it easier to come back to this material later in a new session, where you will need to import the packages again.\nOf course, there will be times when you need help with a function. You can use the help function to view the help documentation for any function. For example, you can run the code help(math.acos) to get help on the arc cosine function from the math package.\n\n\nExercise A.12 Import the math package, figure out how the log function works, and write code to calculate the logarithm of the number 8.3 in base 10, base 2, base 16, and base \\(e\\) (the natural logarithm).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#sec-numpy",
    "href": "nmPython.html#sec-numpy",
    "title": "Appendix A ‚Äî Python",
    "section": "A.3 Numerical Python with NumPy",
    "text": "A.3 Numerical Python with NumPy\nThe base implementation of Python includes the basic programming language, the tools to write loops, check conditions, build and manipulate lists, and all of the other things that we saw in the previous section. In this section we will explore the package numpy that contains optimized numerical routines for doing numerical computations in scientific computing.\n\n\nExample A.25 To start with, let us look at a really simple example. Say you have a list of real numbers and you want to take the sine of every element in the list. If you just try to take the sine of the list you will get an error. Try it yourself.\nfrom math import pi, sin\nmy_list = [0,pi/6, pi/4, pi/3, pi/2, 2*pi/3, 3*pi/4, 5*pi/6, pi]\nsin(my_list)\nYou could get around this error using some of the tools from base Python, but none of them are very elegant from a programming perspective.\nfrom math import pi, sin\nmy_list = [0,pi/6, pi/4, pi/3, pi/2, 2*pi/3, 3*pi/4, 5*pi/6, pi]\nsine_list = [sin(n) for n in my_list]\nsine_list\nfrom math import pi, sin\nmy_list = [0,pi/6, pi/4, pi/3, pi/2, 2*pi/3, 3*pi/4, 5*pi/6, pi]\nsine_list = [ ]\nfor n in range(0,len(my_list)):\n    sine_list.append(sin(my_list[n]))\nsine_list\nPerhaps more simply, say we wanted to square every number in a list. Just appending the code **2 to the end of the list will fail!\nmy_list = [1,2,3,4]\nmy_list**2 # This will produce an error\nIf, instead, we define the list as a numpy array instead of a Python list then everything will work mathematically exactly the way that we intend.\nimport numpy as np\nmy_list = np.array([1,2,3,4])\nmy_list**2 # This will work as expected!  \n\n\n\nExercise A.13 See if you can take the sine of a full list of numbers that are stored in a numpy array.\nHint: you will now see why the numpy package provides its own version of the sine function.\n\n\nThe package numpy is used in many (most) mathematical computations in numerical analysis using Python. It provides algorithms for matrix and vector arithmetic. Furthermore, it is optimized to be able to do these computations in the most efficient possible way (both in terms of memory and in terms of speed).\nTypically when we import numpy we use import numpy as np. This is the standard way to name the numpy package. This means that we will have lots of function with the prefix ‚Äúnp‚Äù in order to call on the numpy functions. Let us first see what is inside the package\nimport numpy as np\ndir(np)\nA brief glimpse through the list reveals a huge wealth of mathematical functions that are optimized to work in the best possible way with the Python language. (We are intentionally not showing the output here since it is quite extensive, run it so you can see.)\n\nA.3.1 Numpy Arrays, Array Operations, and Matrix Operations\nIn the previous section you worked with Python lists. As we pointed out, the shortcoming of Python lists is that they do not behave well when we want to apply mathematical functions to the vector as a whole. The ‚Äúnumpy array‚Äù, np.array, is essentially the same as a Python list with the notable exceptions that\n\nIn a numpy array every entry is a floating point number\nIn a numpy array the memory usage is more efficient (mostly since Python is expecting data of all the same type)\nWith a numpy array there are ready-made functions that can act directly on the array as a matrix or a vector\n\nLet us just look at a few examples using numpy. What we are going to do is to define a matrix \\(A\\) and vectors \\(v\\) and \\(w\\) as \\[\\begin{equation}\nA = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}, \\quad v = \\begin{pmatrix} 5\\\\6 \\end{pmatrix} \\quad \\text{and} \\quad w = v^T = \\begin{pmatrix} 5 & 6 \\end{pmatrix}.\n\\end{equation}\\] Then we will do the following\n\nGet the size and shape of these arrays\nGet individual elements, rows, and columns from these arrays\nTreat these arrays as with linear algebra to\n\ndo element-wise multiplication\ndo matrix a vector products\ndo scalar multiplication\ntake the transpose of matrices\ntake the inverse of matrices\n\n\n\n\nExample A.26 (numpy Matrices) The first thing to note is that a matrix is a list of lists (each row is a list).\nimport numpy as np\nA = np.array([[1,2],[3,4]])\nprint(\"The matrix A is:\\n\",A)\nv = np.array([[5],[6]]) # this creates a column vector\nprint(\"The vector v is:\\n\",v)\nw = np.array([[5,6]]) # this creates a row vector\nprint(\"The vector w is:\\n\",w)\n\n\n\nExample A.27 (.shape) The .shape attribute can be used to give the shape of a numpy array. Notice that the output is a tuple showing the size (rows, columns).\nprint(\"The shape of the matrix A is \", A.shape)\nprint(\"The shape of the column vector v is \", v.shape)\nprint(\"The shape of the row vector w is \", w.shape)\n\n\n\nExample A.28 (.size) The .size attribute can be used to give the size of a numpy array. The size of a matrix or vector will be the total number of elements in the array. You can think of this as the product of the values in the tuple coming from the shape method.\nprint(\"The size of the matrix A is \", A.size)\nprint(\"The size of the column vector v is \", v.size)\nprint(\"The size of the row vector w is \", w.size)\n\n\nReading individual elements from a numpy array is the same, essentially, as reading elements from a Python list. We will use square brackets to get the row and column. Remember that the indexing all starts from 0, not 1!\n\nExample A.29 Let us read the top left and bottom right entries of the matrix \\(A\\).\nimport numpy as np\nA = np.array([[1,2],[3,4]])\nprint(A[0,0]) # top left\nprint(A[1,1]) # bottom right\n\n\n\nExample A.30 Let us read the first row from that matrix \\(A\\).\nimport numpy as np\nA = np.array([[1,2],[3,4]])\nprint(A[0,:])\n\n\n\nExample A.31 Let us read the second column from the matrix \\(A\\).\nimport numpy as np\nA = np.array([[1,2],[3,4]])\nprint(A[:,1])\nNotice when we read the column it was displayed as a row. Be careful. Reading a row or a column from a matrix will automatically flatten it into a 1-dimensional array.\n\n\nIf we try to multiply either \\(A\\) and \\(v\\) or \\(A\\) and \\(A\\) we will get some funky results. Unlike in some programming languages like MATLAB, the default notion of multiplication is NOT matrix multiplication. Instead, the default is element-wise multiplication. You may be familiar with this from R.\n\n\nExample A.32 If we write the code A*A we do NOT do matrix multiplication. Instead we do element-by-element multiplication. This is a common source of issues when dealing with matrices and Linear Algebra in Python.\nimport numpy as np\nA = np.array([[1,2],[3,4]])\nprint(\"Element-wise multiplication:\\n\", A * A)\nprint(\"Matrix multiplication:\\n\", A @ A)\n\n\n\nExample A.33 If we write A * v Python will do element-wise multiplication across each column since \\(v\\) is a column vector. If we want the matrix A to act on v we write A @ v.\nimport numpy as np\nA = np.array([[1,2],[3,4]])\nv = np.array([[5],[6]])\nprint(\"Element-wise multiplication on each column:\\n\", A * v) \n# A @ v will do proper matrix multiplication\nprint(\"Matrix A acting on vector v:\\n\", A @ v)\n\nIt is up to you to check that these products are indeed correct from the definitions of matrix multiplication from Linear Algebra.\nIt remains to show some of the other basic linear algebra operations: inverses, determinants, the trace, and the transpose.\n\n\nExample A.34 (Transpose) Taking the transpose of a matrix (swapping the rows and columns) is done with the .T attribute.\nA.T # The transpose is relatively simple\n\n\n\nExample A.35 (Trace) The trace is done with matrix.trace()\nA.trace() # The trace is pretty darn easy too\nOddly enough, the trace returns a matrix, not a scalar Therefore you will have to read the first entry (index [0,0]) from the answer to just get the trace.\n\n\n\nExample A.36 (Determinant) The determinant function is hiding under the linalg subpackage inside numpy. Therefore we need to call it as such.\nnp.linalg.det(A)\nYou notice an interesting numerical error here. You can do the determinant easily by hand and so know that it should be exactly \\(-2\\). We‚Äôll discuss the source of these kinds of errors in Chapter 1.\n\n\n\nExample A.37 (Inverse) In the linalg subpackage there is also a function for taking the inverse of a matrix.\nA_inv = np.linalg.inv(A)\nA_inv\nWe can check that we get the identity matrix back:\nA @ A_inv\n\n\n\nExercise A.14 Now that we can do some basic linear algebra with numpy it is your turn. Define the matrix \\(B\\) and the vector \\(u\\) as\n\n\\[\\begin{equation}\nB = \\begin{pmatrix} 1 & 4 & 8 \\\\ 2 & 3 & -1 \\\\ 0 & 9 & -3 \\end{pmatrix} \\quad \\text{and} \\quad u = \\begin{pmatrix} 6 \\\\ 3 \\\\ -7 \\end{pmatrix}.\n\\end{equation}\\]\nThen find\n\n\\(Bu\\)\n\\(B^2\\) (in the traditional linear algebra sense)\nThe size and shape of \\(B\\)\n\\(B^T u\\)\nThe element-by-element product of \\(B\\) with itself\nThe dot product of \\(u\\) with the first row of \\(B\\)\n\n\n\n\n\nA.3.2 arange, linspace, zeros, ones, and meshgrid\nThere are a few built-in ways to build arrays in numpy that save a bit of time in many scientific computing settings.\n\n\nExample A.38 The np.arange (array range) function is great for building sequences.\nimport numpy as np\nx = np.arange(0,0.6,0.1)\nx\nnp.arange builds an array of floating point numbers with the arguments start, stop, and step. Note that the stop value itself is not included in the result.\n\n\n\nExample A.39 The np.linspace function builds an array of floating point numbers starting at one point, ending at the next point, and have exactly the number of points specified with equal spacing in between: start, stop, number of points.\nimport numpy as np\ny = np.linspace(0,5,11)\ny\nIn a linear space you are always guaranteed to hit the stop point exactly, but you do not have direct control over the step size.\n\n\n\nExample A.40 The np.zeros function builds an array of zeros. This is handy for pre-allocating memory.\nimport numpy as np\nz = np.zeros((3,5)) # create a 3x5 matrix of zeros\nz\nIf you already have an array and want to create an array of zeros with the same shape, you can use np.zeros_like(array).\nimport numpy as np\nx = np.linspace(0,5,11)\nz = np.zeros_like(x)\nz\nSimilarly there are the functions np.ones and np.ones_like to build arrays of ones.\n\n\n\nExample A.41 The np.meshgrid function builds two arrays that when paired make up the ordered pairs for a 2D (or higher D) mesh grid of points. This is handy for building 2D (or higher dimensional) arrays of data for multi-variable functions. Notice that the output is defined as a tuple.\nimport numpy as np\nx, y = np.meshgrid(np.linspace(0,5,6), np.linspace(0,5,6))\nprint(\"x = \", x)\nprint(\"y = \", y)\nThe thing to notice with the np.meshgrid() function is that when you lay the two arrays on top of each other, the matching entries give every ordered pair in the domain.\nIf the purpose of this is not clear to you yet, don‚Äôt worry. You will see it used a lot later in the module.\n\n\n\nExercise A.15 Now it is time to practice with some of these numpy functions.\n\nCreate a numpy array of the numbers 1 through 10 and square every entry in the list without using a loop.\nCreate a \\(10 \\times 10\\) identity matrix and change the top right corner to a 5. Hint: np.identity()\nFind the matrix-vector product of the answer to part (b) and the answer to part (a).\nChange the bottom row of your matrix from part (b) to all \\(3\\)‚Äôs, then change the third column to all \\(7\\)‚Äôs, and then find the \\(5^{th}\\) power of this matrix.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#sec-matplotlib",
    "href": "nmPython.html#sec-matplotlib",
    "title": "Appendix A ‚Äî Python",
    "section": "A.4 Plotting with Matplotlib",
    "text": "A.4 Plotting with Matplotlib\nA key part of scientific computing is plotting your results or your data. The tool in Python best-suited to this task is the package matplotlib. As with all of the other packages in Python, it is best to learn just the basics first and then to dig deeper later. One advantage to using matplotlib in Python is that it is modelled off of MATLAB‚Äôs plotting tools. People coming from a MATLAB background should feel pretty comfortable here, but there are some differences to be aware of.\n\nA.4.1 Basics with plt.plot()\nWe are going to start right away with an example. In this example, however, we will walk through each of the code chunks one-by-one so that we understand how to set up a proper plot.\nBelow we will mention some tricks for getting the plots to render that only apply to Jupyter Notebooks. If you are using Google Colab then you may not need some of these little tricks.\n\n\nExample A.42 (Plotting with matplotlib) In the first example we want to simply plot the sine function on the domain \\(x \\in [0,2\\pi]\\), colour it green, put a grid on it, and give a meaningful legend and axis labels. To do so we first need to take care of a couple of housekeeping items.\n\nImport numpy so we can take advantage of some good numerical routines.\nImport matplotlib‚Äôs pyplot module. The standard way to pull it in is with the nickname plt (just like with numpy when we import it as np).\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt\n\nIn Jupyter Notebooks the plots will not show up unless you tell the notebook to put them ‚Äúinline.‚Äù Usually we will use the following command to get the plots to show up. You do not need to do this in Google Colab. The percent sign is called a magic command in Jupyter Notebooks. This is not a Python command, but it is a command for controlling the Jupyter IDE specifically.\n%matplotlib inline\nNow we will build a numpy array of \\(x\\) values (using the np.linspace function) and a numpy array of \\(y\\) values from the sine function.\n\n# 100 equally spaced points from 0 to 2pi\nx = np.linspace(0,2*np.pi,100) \ny = np.sin(x)\n\n\nNext, build the plot with plt.plot(). The syntax is: plt.plot(x, y, ‚Äôcolor‚Äô, ...)¬†where you have several options that you can pass (more on that later).\nWe send the plot label directly to the plot function. This is optional and we could set the legend up separately if we like.\nThen we will add the grid with plt.grid()\nThen we will add the legend to the plot\nFinally we will add the axis labels\nWe end the plotting code with plt.show() to tell Python to finally show the plot. This line of code tells Python that you are done building that plot.\n\n\nplt.plot(x,y, 'green', label='The Sine Function')\nplt.grid()\nplt.legend()\nplt.xlabel(\"x axis\")\nplt.ylabel(\"y axis\")\nplt.show()\n\n\n\n\n\n\n\nFigure¬†A.1: The sine function\n\n\n\n\n\n\n\n\nExample A.43 Now let us do a second example, but this time we want to show four different plots on top of each other. When you start a figure, matplotlib is expecting all of those plots to be layered on top of each other. (Note:For MATLAB users, this means that you do not need the hold on command since it is automatically ‚Äúon.‚Äù)\nIn this example we will plot \\[\\begin{equation}\ny_0 = \\sin(2\\pi x) \\quad y_1 = \\cos(2 \\pi x) \\quad y_2 = y_0 + y_1 \\quad \\text{and} \\quad y_3 = y_0 - y_1\n\\end{equation}\\] on the domain \\(x \\in [0,1]\\) with 100 equally spaced points. we will give each of the plots a different line style, built a legend, put a grid on the plot, and give axis labels.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n# %matplotlib inline # you may need this in Jupyter Notebooks\n\n# build the x and y values\nx = np.linspace(0,1,100)\ny0 = np.sin(2*np.pi*x)\ny1 = np.cos(2*np.pi*x)\ny2 = y0 + y1\ny3 = y0 - y1\n\n# plot each of the functions \n# (notice that they will be on the same axes)\nplt.plot(x, y0, 'b-.', label=r\"$y_0 = \\sin(2\\pi x)$\")\nplt.plot(x, y1, 'r--', label=r\"$y_1 = \\cos(2\\pi x)$\")\nplt.plot(x, y2, 'g:', label=r\"$y_2 = y_0 + y_1$\")\nplt.plot(x, y3, 'k-', label=r\"$y_3 = y_0 - y_1$\")\n\n# put in a grid, legend, title, and axis labels\nplt.grid()\nplt.legend()\nplt.title(\"Awesome Graph\")\nplt.xlabel('x axis label')\nplt.ylabel('y axis label')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†A.2: Plots of the sine, cosine, and sums and differences.\n\n\n\n\n\nNotice the r in front of the strings defining the legend. This prevents the backslash that is used a lot in LaTeX to be interpreted as an escape character. These strings are referred to as raw strings.\nThe legend was placed automatically at the lower left of the plot. There are ways to control the placement of the legend if you wish, but for now just let Python and matplotlib have control over the placement.\n\n\n\nExample A.44 Now let us create the same plot with slightly different code. The plot function can take several \\((x, y)\\) pairs in the same line of code. This can really shrink the amount of coding that you have to do when plotting several functions on top of each other.\n\n# The next line of code does all of the plotting of all \n# of the functions.  Notice the order: x, y, color and \n# line style, repeat\nimport numpy as np\nimport matplotlib.pyplot as plt\nx = np.linspace(0,1,100)\ny0 = np.sin(2*np.pi*x)\ny1 = np.cos(2*np.pi*x)\ny2 = y0 + y1\ny3 = y0 - y1\nplt.plot(x, y0, 'b-.', x, y1, 'r--', x, y2, 'g:', x, y3, 'k-')\n\nplt.grid()\nplt.legend([r\"$y_0 = \\sin(2\\pi x)$\",r\"$y_1 = \\cos(2\\pi x)$\",\\\n            r\"$y_2 = y_0 + y_1$\",r\"$y_3 = y_0 - y_1$\"])\nplt.title(\"Awesome Graph\")\nplt.xlabel('x axis label')\nplt.ylabel('y axis label')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†A.3: A second plot of the sine, cosine, and sums and differences.\n\n\n\n\n\n\n\n\nExercise A.16 Plot the functions \\(f(x) = x^2\\), \\(g(x) = x^3\\), and \\(h(x) = x^4\\) on the same axes. Use the domain \\(x \\in [0,1]\\). Put a grid, a legend, a title, and appropriate labels on the axes.\n\n\n\n\nA.4.2 Subplots\nIt is often very handy to place plots side-by-side or as some array of plots. The subplots command allows us that control. The main idea is that we are setting up a matrix of blank plots and then populating the axes with the plots that we want.\n\n\nExample A.45 Let us repeat the previous exercise, but this time we will put each of the plots in its own subplot. There are a few extra coding quirks that come along with building subplots so we will highlight each block of code separately.\n\nFirst we set up the plot area with plt.subplots(). The first two inputs to the subplots command are the number of rows and the number of columns in your plot array. For the first example we will do 2 rows of plots with 2 columns ‚Äì so there are four plots total.\nThen we build each plot individually telling matplotlib which axes to use for each of the things in the plots.\nNotice the small differences in how we set the titles and labels\nIn this example we are setting the \\(y\\)-axis to the interval \\([-2,2]\\) for consistency across all of the plots.\n\n\n# set up the blank matrix of plots\nimport numpy as np\nimport matplotlib.pyplot as plt\nx = np.linspace(0,1,100)\ny0 = np.sin(2*np.pi*x)\ny1 = np.cos(2*np.pi*x)\ny2 = y0 + y1\ny3 = y0 - y1\n\nfig, axes = plt.subplots(nrows = 2, ncols = 2)\n\n# Build the first plot\naxes[0,0].plot(x, y0, 'b-.')\naxes[0,0].grid()\naxes[0,0].set_title(r\"$y_0 = \\sin(2\\pi x)$\")\naxes[0,0].set_ylim(-2,2)\naxes[0,0].set_xlabel(\"x\")\naxes[0,0].set_ylabel(\"y\")\n\n# Build the second plot\naxes[0,1].plot(x, y1, 'r--')\naxes[0,1].grid()\naxes[0,1].set_title(r\"$y_1 = \\cos(2\\pi x)$\")\naxes[0,1].set_ylim(-2,2)\naxes[0,1].set_xlabel(\"x\")\naxes[0,1].set_ylabel(\"y\")\n\n# Build the first plot\naxes[1,0].plot(x, y2, 'g:')\naxes[1,0].grid()\naxes[1,0].set_title(r\"$y_2 = y_0 + y_1$\")\naxes[1,0].set_ylim(-2,2)\naxes[1,0].set_xlabel(\"x\")\naxes[1,0].set_ylabel(\"y\")\n\n# Build the first plot\naxes[1,1].plot(x, y3, 'k-')\naxes[1,1].grid()\naxes[1,1].set_title(r\"$y_3 = y_0 - y_1$\")\naxes[1,1].set_ylim(-2,2)\naxes[1,1].set_xlabel(\"x\")\naxes[1,1].set_ylabel(\"y\")\n\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nFigure¬†A.4: An example of subplots\n\n\n\n\n\nThe fig.tight_layout() command makes the plot labels a bit more readable in this instance (again, something you can play with).\n\n\n\nExercise A.17 Put the functions \\(f(x) = x^2\\), \\(g(x) = x^3\\) and \\(h(x) = x^4\\) in a subplot environment with 1 row and 3 columns of plots. Use the unit interval as the domain and range for all three plot. Make sure that each plot has a grid, appropriate labels, an appropriate title, and the overall figure has a title.\n\nA.4.3 Logarithmic Scaling with semilogy, semilogx, and loglog\nIt is occasionally useful to scale an axis logarithmically. This arises most often when we are examining an exponential function, or some other function, that is close to zero for much of the domain. Scaling logarithmically allows us to see how small the function is getting in orders of magnitude instead of as a raw real number. we will use this often in numerical methods.\n\n\n\n\nExample A.46 In this example we will plot the function \\(y = 10^{-0.01x}\\) on a regular (linear) scale and on a logarithmic scale on the \\(y\\) axis. We use the interval \\([0,500]\\) on the \\(x\\) axis.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx = np.linspace(0,500,1000)\ny = 10**(-0.01*x)\nfig, axis = plt.subplots(1,2)\n\naxis[0].plot(x,y, 'r')\naxis[0].grid()\naxis[0].set_title(\"Linearly scaled y axis\")\naxis[0].set_xlabel(\"x\")\naxis[0].set_ylabel(\"y\")\n\naxis[1].semilogy(x,y, 'r')\naxis[1].grid()\naxis[1].set_title(\"Logarithmically scaled y axis\")\naxis[1].set_xlabel(\"x\")\naxis[1].set_ylabel(\"Log(y)\")\n\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nFigure¬†A.5: An example of using logarithmic scaling.\n\n\n\n\n\nIt should be noted that the same result can be achieved using the yscale command along with the plot command instead of using the semilogy command. So you could replace\naxis[1].semilogy(x,y, 'r')\nby\naxis[1].plot(x,y, 'r')\naxis[1].set_yscale(\"log\")\nto produce identical results.\n\n\n\nExercise A.18 Plot the function \\(f(x) = x^3\\) for \\(x \\in [0,1]\\) on linearly scaled axes, logarithmic axis in the \\(y\\) direction, logarithmically scaled axes in the \\(x\\) direction, and a log-log plot with logarithmic scaling on both axes. Use subplots to put your plots side-by-side. Give appropriate labels, titles, etc.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#sec-pandas",
    "href": "nmPython.html#sec-pandas",
    "title": "Appendix A ‚Äî Python",
    "section": "A.5 Dataframes with Pandas",
    "text": "A.5 Dataframes with Pandas\nThe Pandas package provides Python with the ability to work with tables of data similar to what R provides via its dataframes. As we will not work much with data in this module, we do not need to dive deep into the Pandas package. In some of the optional exercises you will load in data from files using pd.read_csv().\n\nExample A.47 ¬†\n\nimport pandas as pd\ndf = pd.read_csv('https://github.com/gustavdelius/NumericalAnalysis2025/raw/main/data/Calculus/bikespeed.csv')\ndf\n\n\n\n\n\n\n\n\nTime (sec)\nSpeed (ft/sec)\n\n\n\n\n0\n0\n34\n\n\n1\n10\n32\n\n\n2\n20\n29\n\n\n3\n30\n33\n\n\n4\n40\n37\n\n\n5\n50\n40\n\n\n6\n60\n41\n\n\n7\n70\n36\n\n\n8\n80\n38\n\n\n9\n90\n39\n\n\n\n\n\n\n\n\n\n\nExample A.48 Pandas can also be useful to us for collecting computational results into tables for easier display. In this example we will build a table of the first 10 natural numbers and their squares and cubes. We then display the table.\n\nimport numpy as np\nimport pandas as pd\n\n# Calculate the columns for the table\nn = np.arange(1,11)\nn2 = n**2\nn3 = n**3\n\n# Combine the columns into a data frame with headers\ndf = pd.DataFrame({'n': n, 'n^2': n2, 'n^3': n3})\ndf\n\n\n\n\n\n\n\n\nn\nn^2\nn^3\n\n\n\n\n0\n1\n1\n1\n\n\n1\n2\n4\n8\n\n\n2\n3\n9\n27\n\n\n3\n4\n16\n64\n\n\n4\n5\n25\n125\n\n\n5\n6\n36\n216\n\n\n6\n7\n49\n343\n\n\n7\n8\n64\n512\n\n\n8\n9\n81\n729\n\n\n9\n10\n100\n1000\n\n\n\n\n\n\n\nThis provides an alternative to how we created a tabular display with the print() function in Example¬†A.20.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#sec-python_exercises",
    "href": "nmPython.html#sec-python_exercises",
    "title": "Appendix A ‚Äî Python",
    "section": "A.6 Problems",
    "text": "A.6 Problems\nThese problem exercises here are meant for you to practice and improve your coding skills. Please refrain from relying too much on Gemini or any other AI for solving these exercises. The point is to struggle through the code, get it wrong many times, debug, and then to eventually have working code. So I recommend switching off the AI features in Google Colab for the purpose of these exercises.\nYou do not need to do all the exercises. Do only as many as you have time for and you feel is useful. It might be a good idea to split the exercises up among your group members and then share the code with each other.\n\n\nExercise A.19 (This problem is modified from (‚ÄúProject Euler‚Äù n.d.))\nIf we list all of the numbers below 10 that are multiples of 3 or 5 we get 3, 5, 6, and 9. The sum of these multiples is 23. Write code to find the sum of all the multiples of 3 or 5 below 1000. Your code needs to run error free and output only the sum. There are of course many ways you could approach this exercise. Compare your approach to that of others in your group.\n\n\n\nExercise A.20 (This problem is modified from (‚ÄúProject Euler‚Äù n.d.))\nEach new term in the Fibonacci sequence is generated by adding the previous two terms. By starting with 1 and 2, the first 10 terms will be: \\[\\begin{equation}\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, \\dots\n\\end{equation}\\] By considering the terms in the Fibonacci sequence whose values do not exceed four million, write code to find the sum of the even-valued terms. Your code needs to run error free and output only the sum.\n\n\n\nExercise A.21 Write computer code that will draw random numbers from the unit interval \\([0,1]\\), distributed uniformly (using Python‚Äôs np.random.rand()), until the sum of the numbers that you draw is greater than 1. Keep track of how many numbers you draw. Then write a loop that does this process many many times. On average, how many numbers do you have to draw until your sum is larger than 1?\n\nHint #1:\n\nUse the np.random.rand()command to draw a single number from a uniform distribution with bounds \\((0,1)\\).\n\nHint #2:\n\nYou should do this more than 1,000,000 times to get a good average ‚Ä¶ and the number that you get should be familiar!\n\n\n\n\n\nExercise A.22 (This problem is modified from (‚ÄúProject Euler‚Äù n.d.))\nThe sum of the squares of the first ten natural numbers is, \\[\\begin{equation}\n1^2 + 2^2 + \\dots + 10^2 = 385\n\\end{equation}\\] The square of the sum of the first ten natural numbers is, \\[\\begin{equation}\n(1 + 2 + \\dots + 10)^2 = 55^2 = 3025\n\\end{equation}\\] Hence the difference between the square of the sum of the first ten natural numbers and the sum of the squares is \\(3025 - 385 = 2640\\).\nWrite code to find the difference between the square of the sum of the first one hundred natural numbers and the sum of the squares. Your code needs to run error free and output only the difference.\n\n\n\nExercise A.23 (This problem is modified from (‚ÄúProject Euler‚Äù n.d.))\nThe prime factors of \\(13195\\) are \\(5, 7, 13\\) and \\(29\\). Write code to find the largest prime factor of the number \\(600851475143\\)? Your code needs to run error free and output only the largest prime factor.\n\n\n\nExercise A.24 (This problem is modified from (‚ÄúProject Euler‚Äù n.d.))\nThe number 2520 is the smallest number that can be divided by each of the numbers from 1 to 10 without any remainder. Write code to find the smallest positive number that is evenly divisible by all of the numbers from 1 to 20?\nHint: You will likely want to use modular division for this problem.\n\n\n\nExercise A.25 The following iterative sequence is defined for the set of positive integers: \\[\\begin{equation}\n\\begin{aligned} & n \\to \\frac{n}{2} \\quad (n \\text{ is even}) \\\\ & n \\to 3n + 1 \\quad (n \\text{ is odd}) \\end{aligned}\n\\end{equation}\\] Using the rule above and starting with \\(13\\), we generate the following sequence: \\[\\begin{equation}\n13 \\to 40 \\to 20 \\to 10 \\to 5 \\to 16 \\to 8 \\to 4 \\to 2 \\to 1\n\\end{equation}\\] It can be seen that this sequence (starting at 13 and finishing at 1) contains 10 terms. Although it has not been proved yet (Collatz Problem), it is thought that all starting numbers finish at 1. This has been verified on computers for massively large starting numbers, but this does not constitute a proof that it will work this way for all starting numbers.\nWrite code to determine which starting number, under one million, produces the longest chain. NOTE: Once the chain starts, the terms are allowed to go above one million.\n\nFootnotes\n\n\n\n\n‚ÄúProject Euler.‚Äù n.d. Accessed December 14, 2023. https://projecteuler.net/.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "nmPython.html#footnotes",
    "href": "nmPython.html#footnotes",
    "title": "Appendix A ‚Äî Python",
    "section": "",
    "text": "Actually, it is still an open mathematical question whether every integer seed will converge to 1. The Collatz sequence has been checked for many millions of initial seeds and they all converge to 1, but there is no mathematical proof that it will always happen. You will check the conjecture numerically in Exercise¬†A.25‚Ü©Ô∏é\nThere is the sympy package if you want to do symbolic computations, but we will not use that in this module.‚Ü©Ô∏é",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "ex_exam_solns.html",
    "href": "ex_exam_solns.html",
    "title": "Appendix B ‚Äî Exam solutions",
    "section": "",
    "text": "B.1 Numbers\nIn this appendix you find example solutions to the exam-style questions.\n(a) Machine Precision\nMachine precision is the gap between the number 1 and the next larger floating point number. With 4 bits for the mantissa, the smallest number greater than \\(1\\) that can be represented is \\(1.0001_2\\). So machine precision is \\(\\epsilon = 0.0001_2=1/16\\). The machine precision is the upper bound for the relative rounding error.\n(b) Conversion of 13.5\n(c) Addition: 13.5 + 0.25\n(d) Loss of Significance",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Exam solutions</span>"
    ]
  },
  {
    "objectID": "ex_exam_solns.html#numbers",
    "href": "ex_exam_solns.html#numbers",
    "title": "Appendix B ‚Äî Exam solutions",
    "section": "",
    "text": "Sign: Positive (\\(+13.5\\)), so \\(s=0\\).\nConvert \\(13.5\\) to binary:\n\n\\(13_{10} = 1101_2\\).\n\\(0.5_{10} = 0.1_2\\).\nResult: \\(1101.1_2\\).\n\nNormalize: \\(1.1011 \\times 2^3\\).\nExponent (\\(E=3\\)):\n\nStored exponent \\(e = E + 3 = 3 + 3 = 6\\).\n\\(6_{10} = 110_2\\).\n\nMantissa (\\(m\\)): Drop the leading 1 \\(\\rightarrow\\) 1011.\nFinal Bit Pattern: 0 110 1011.\n\n\n\nConvert second number (0.25):\n\n\\(0.25 = 1/4 = 1.0 \\times 2^{-2}\\).\n\nAlign Exponents:\n\n\\(x_1 = 1.1011 \\times 2^3\\)\n\\(x_2 = 1.0000 \\times 2^{-2}\\)\nShift \\(x_2\\) to match exponent \\(3\\): Shift right by \\(3 - (-2) = 5\\) positions.\n\\(x_2 \\rightarrow 0.00001 \\times 2^3\\).\n\nAdd Significands:\n  1.1011      (13.5)\n+ 0.00001     (0.25 aligned)\n-----------\n  1.10111\nRounding:\n\nThe result \\(1.10111_2\\) has 5 fractional bits, but we can only store 4.\nIt lies exactly halfway between \\(1.1011\\) (\\(13.5\\)) and \\(1.1100\\) (\\(14.0\\)).\nTie-breaking rule: ‚ÄúTies to Even‚Äù.\nThe Least Significant Bit (4th bit) is 1 (odd). To make it even, we round up (add 1 to the LSB).\n\\(1.1011 + 0.0001 = 1.1100\\).\n\nFinal Result:\n\nSignificand: \\(1.1100\\)\nValue: \\(1.1100_2 \\times 2^3 = 1110.0_2 = \\mathbf{14.0}\\).\n\nError:\n\nExact sum: \\(13.75\\).\nStored sum: \\(14.0\\).\nAbsolute Error: \\(|13.75 - 14.0| = \\mathbf{0.25}\\).\n\n\n\n\nError Type: Catastrophic Cancellation (or Loss of Significant Digits).\nExplanation: When \\(x\\) is very large (\\(10^8\\)), \\(x^2 + 1 \\approx x^2\\), so \\(\\sqrt{x^2+1} \\approx x\\). Subtracting two extremely close numbers causes the cancellation of the leading digits, leaving only the random ‚Äúnoise‚Äù from the least significant bits.\nImproved (Stable) Formula: Multiply by the conjugate: \\[f(x) = \\frac{(\\sqrt{x^2+1} - x)(\\sqrt{x^2+1} + x)}{\\sqrt{x^2+1} + x} = \\frac{1}{\\sqrt{x^2+1} + x}.\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Exam solutions</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html#sec-polynomial_approximations",
    "href": "nmFunctions.html#sec-polynomial_approximations",
    "title": "2¬† Functions",
    "section": "",
    "text": "Exercise 2.1 üí¨ In this exercise you are going to make a bit of a wish list for all of the things that a computer will do when approximating a function. We are going to complete the following sentence:\nIf we are going to approximate a smooth function \\(f(x)\\) near the point \\(x=x_0\\) with a simpler function \\(g(x)\\) then ‚Ä¶\n(I will get us started with the first two things that seems natural to wish for. The rest of the wish list is for you to complete.)\n\nthe functions \\(f(x)\\) and \\(g(x)\\) should agree at \\(x=x_0\\). In other words, \\(f(x_0) = g(x_0)\\)\nthe function \\(g(x)\\) should only involve addition, subtraction, multiplication, division, and integer exponents since computer are very good at those sorts of operations.\nif \\(f(x)\\) is increasing / decreasing near \\(x=x_0\\) then \\(g(x)\\) ‚Ä¶\nif \\(f(x)\\) is concave up / down near \\(x=x_0\\) then \\(g(x)\\)‚Ä¶\nif we zoom into plots of the functions \\(f(x)\\) and \\(g(x)\\) near \\(x=x_0\\) then ‚Ä¶\n‚Ä¶ is there anything else that you would add?\n\n\n\n\nExercise 2.2 üí¨ Discuss: Could a polynomial function with a high enough degree satisfy everything in the wish list from the previous problem? Explain your reasoning.\n\n\n\nExercise 2.3 üñã üéì Let us put some parts of the wish list into action. If \\(f(x)\\) is a differentiable function at \\(x=x_0\\) and if \\(g(x) = A + B (x-x_0) + C (x-x_0)^2 + D (x-x_0)^3\\) then\n\nWhat is the value of \\(A\\) such that \\(f(x_0) = g(x_0)\\)? (Hint: substitute \\(x=x_0\\) into the \\(g(x)\\) function)\nWhat is the value of \\(B\\) such that at \\(x_0\\) \\(f\\) and \\(g\\) have the same slope? In other words, what is the value of \\(B\\) such that \\(f'(x_0) = g'(x_0)\\)? (Hint: Start by taking the derivative of \\(g(x)\\))\nWhat is the value of \\(C\\) such that at \\(x_0\\) \\(f\\) and \\(g\\) have the same concavity? In other words, what is the value of \\(C\\) such that \\(f''(x_0) = g''(x_0)\\)?\nWhat is the value of \\(D\\) such that at \\(x_0\\) \\(f\\) and \\(g\\) have the same third derivative? In other words, what is the value of \\(D\\) such that \\(f'''(x_0) = g'''(x_0)\\)?\n\n\n\n\n\n\n\n2.1.1 Approximating the exponential function\n\nExercise 2.4 üñã What is Euler‚Äôs number \\(e\\)? You have been using this number often in Calculus and Differential Equations. Do you know the decimal approximation for this number? Moreover, is there a way that we could approximate something like \\(\\sqrt{e} = e^{0.5}\\) or \\(e^{-1}\\) without actually having access to the full decimal expansion?\nFor all of the questions below let us work with the function \\(f(x) = e^x\\).\n\nThe function \\(g_0(x) = 1\\) matches \\(f(x) = e^x\\) exactly at the point \\(x=0\\) since \\(f(0) = e^0 = 1\\). Furthermore if \\(x\\) is very very close to \\(0\\) then the functions \\(f(x)\\) and \\(g_0(x)\\) are really close to each other. Hence we could say that \\(g_0(x) = 1\\) is an approximation of the function \\(f(x) = e^x\\) for values of \\(x\\) very very close to \\(x=0\\). Admittedly, though, it is probably pretty clear that this is a horrible approximation for any \\(x\\) just a little bit away from \\(x=0\\).\nLet us get a better approximation. What if we insist that our approximation \\(g_1(x)\\) matches \\(f(x) = e^x\\) exactly at \\(x=0\\) and ALSO has exactly the same first derivative as \\(f(x)\\) at \\(x=0\\).\n\nWhat is the first derivative of \\(f(x)\\)?\nWhat is \\(f'(0)\\)?\nUse the point-slope form of a line to write the equation of the function \\(g_1(x)\\) that goes through the point \\((0,f(0))\\) and has slope \\(f'(0)\\). Recall from algebra that the point-slope form of a line is \\(y = f(x_0) + m(x-x_0).\\) In this case we are taking \\(x_0 = 0\\) so we are using the formula \\(g_1(x) = f(0) + f'(0) (x-0)\\) to get the equation of the line.\n\nüíª Write Python code to build a plot like Figure¬†2.1. This plot shows \\(f(x) = e^x\\), our first approximation \\(g_0(x) = 1\\) and our second approximation \\(g_1(x) = 1+x\\). You may want to look at Example¬†A.43 in the Python chapter for a refresher on how to build plots containing the graphs of several functions. If you need a hint on how to plot the function \\(g_0(x)\\) since it is a constant function, take a look at the np.ones_like() function in Example¬†A.40.\n\n\n\n\n\n\n\n\n\nFigure¬†2.1: The first two polynomial approximations of the exponential function.\n\n\n\n\n\n\n\nExercise 2.5 üñã Let us extend the idea from the previous problem to much better approximations of the function \\(f(x) = e^x\\).\n\nLet us build a function \\(g_2(x)\\) that matches \\(f(x)\\) exactly at \\(x=0\\), has exactly the same first derivative as \\(f(x)\\) at \\(x=0\\), AND has exactly the same second derivative as \\(f(x)\\) at \\(x=0\\). To do this we will use a quadratic function. For a quadratic approximation of a function we just take a slight extension to the point-slope form of a line and use the equation \\[\\begin{equation}\ng_2(x) = f(x_0) + f'(x_0) (x-x_0) + \\frac{f''(x_0)}{2} (x-x_0)^2.\n\\end{equation}\\] In this case we are using \\(x_0 = 0\\) so the quadratic approximation function looks like \\[\\begin{equation}\ng_2(x) = f(0) + f'(0) x + \\frac{f''(0)}{2} x^2.\n\\end{equation}\\]\n\nFind the quadratic approximation for \\(f(x) = e^x\\).\nüíª Add your new function to the plot you created in the previous problem.\n\nLet us keep going!! Next we will do a cubic approximation. A cubic approximation takes the form \\[\\begin{equation}\ng_3(x) = f(x_0) + f'(0) (x-x_0) + \\frac{f''(0)}{2}(x-x_0)^2 + \\frac{f'''(0)}{3!}(x-x_0)^3\n\\end{equation}\\]\n\nFind the cubic approximation for \\(f(x) = e^x\\).\nHow do we know that this function matches the first, second, and third derivatives of \\(f(x)\\) at \\(x=0\\)? What‚Äôs the deal with the \\(3!\\) on the cubic term?\nüíª Add your function to the plot.\n\n\n\n\n\nExercise 2.6 üíª Write a function that takes the arguments x and n and returns the nth order Taylor series approximation of \\(f(x) = e^x\\). To remind yourself of how functions are defined in Python, you may want to look at Section A.2.6 in the Python chapter. You will also need a loop, see Section A.2.5. Please start from the following skeleton and put your code where it says ‚ÄúTODO‚Äù.\ndef exp_approx(x, n):\n    \"\"\"\n    Computes the nth order Taylor series approximation of e^x at x=0.\n\n    Parameters:\n    x (float): The value at which to evaluate the approximation.\n    n (int): The order of the Taylor series expansion.\n\n    Returns:\n    float: The nth order Taylor approximation of e^x.\n    \"\"\"\n    if n &lt; 0:\n        raise ValueError(\"n must be at least 0\")\n    # Start with zero-order approximation\n    approximation = 1.0\n    # Add higher-order terms\n    for i in range(1, n + 1):\n        approximation += # TODO: calculate the i'th term of the Taylor series\n    return approximation\nMake sure you perfectly understand the code. Use the AI to explain everything to you in detail. You can select parts of the code and ask the AI questions like ‚ÄúWhy do we need to use range(1, n + 1)?‚Äù and ‚ÄúWhat does approximation += do?‚Äù\n\n\n\nExercise 2.7 üéì üíª Use the function exp_approx that you have built in Exercise¬†2.6 to approximate \\(\\frac{1}{e} = e^{-1}\\). Check the accuracy of your answer using np.exp(-1) in Python.\n\n\n\nExercise 2.8 üíª üí¨ Brainstorm within your group to see if you can make your function more efficient by writing it without using exponentiation and the factorial function, coding all multiplications and divisions explicitly. Try to minimise the number of arithmetic operations that you need to perform? Can you make it so that it only needs \\(n-1\\) multiplications, \\(n-1\\) divisions and \\(n\\) additions?\nUse the %timeit magic command to measure how fast your exp_approx function is. In a new code cell, run\n%timeit exp_approx(1.5, 100)\nThis will run the function multiple times and give you an estimate of the execution time.\n\n\n\n\n2.1.2 Taylor Series\nWhat we have been exploring so far in this section is the Taylor Series of a function.\n\nDefinition 2.1 (Taylor Series) If \\(f(x)\\) is an infinitely differentiable function at the point \\(x_0\\) then \\[\\begin{equation}\nf(x) = f(x_0) + f'(x_0)(x-x_0) + \\frac{f''(x_0)}{2}(x-x_0)^2 + \\cdots \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + \\cdots\n\\end{equation}\\] for any reasonably small interval around \\(x_0\\). The infinite polynomial expansion is called the Taylor Series of the function \\(f(x)\\). Taylor Series are named for the mathematician Brook Taylor.\n\n\nThe Taylor Series of a function is often written with summation notation as \\[\\begin{equation}\nf(x) = \\sum_{k=0}^\\infty \\frac{f^{(k)}(x_0)}{k!} (x-x_0)^k.\n\\end{equation}\\] Do not let the notation scare you. In a Taylor Series you are just saying: give me a function that\n\nmatches \\(f(x)\\) at \\(x=x_0\\) exactly,\nmatches \\(f'(x)\\) at \\(x=x_0\\) exactly,\nmatches \\(f''(x)\\) at \\(x=x_0\\) exactly,\nmatches \\(f'''(x)\\) at \\(x=x_0\\) exactly,\netc.\n\n(Take a moment and make sure that the summation notation makes sense to you.)\nMoreover, Taylor Series are built out of the easiest types of functions: polynomials. Computers are rather good at doing computations with addition, subtraction, multiplication, division, and integer exponents, so Taylor Series are a natural way to express functions in a computer. The down side is that we can only get true equality in the Taylor Series if we have infinitely many terms in the series. A computer cannot do infinitely many computations. So, in practice, we truncate Taylor Series after many terms and think of the new polynomial function as being close enough to the actual function so far as we do not stray too far from the anchor \\(x_0\\).\n\n\nExercise 2.9 üñã Do all of the calculations to show that the Taylor Series centred at \\(x_0 = 0\\) for the function \\(f(x) = \\sin(x)\\) is indeed \\[\\begin{equation}\n\\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots .\n\\end{equation}\\]\n\n\n\nExercise 2.10 üíª Write a Pyton function sin_approx(x, n) that computes the \\(n\\)th order Taylor Series approximation of \\(\\sin(x)\\) centred at \\(x_0 = 0\\). Test your function by comparing its output to np.sin(x) for a few values of \\(x\\) and \\(n\\). Use it to make a plot of the first three approximations for \\(x\\) in the range \\([-\\pi, \\pi]\\) similar to the plots you made for approximations of \\(e^x\\) above.\n\n\n\nExercise 2.11 üñã Let us compute a Taylor Series that is not centred at \\(x_0 = 0\\). For example, let us approximate the function \\(f(x) = \\log (x)\\) near \\(x_0 = 1\\). Near the point \\(x_0 = 1\\), the Taylor Series approximation will take the form \\[\\begin{equation}\nf(x) = f\\left( 1 \\right) + f'\\left( 1 \\right)\\left( x - 1 \\right) + \\frac{f''\\left( 1 \\right)}{2!}\\left( x - 1 \\right)^2 + \\frac{f'''\\left( 1 \\right)}{3!}\\left( x - 1 \\right)^3 + \\cdots\n\\end{equation}\\]\nWrite the first several terms of the Taylor Series for \\(f(x) = \\log x\\) centred at \\(x_0 = 1\\) until you get a feel for the pattern.\n\n\n\nExercise 2.12 üíª Write a Pyton function log_approx(x, n) that computes the \\(n\\)th order Taylor Series approximation of \\(\\log(x)\\) centred at \\(x_0 = 1\\). Use it to build the plot below showing the approximations.\n\n\n\n\n\n\n\n\nFigure¬†2.2: Taylor series approximation of the logarithm.\n\n\n\n\n\n\n\n\nExample 2.1 Let us conclude this brief section by examining an interesting example. Consider the function \\[\\begin{equation}\nf(x) = \\frac{1}{1-x}.\n\\end{equation}\\] If we build a Taylor Series centred at \\(x_0 = 0\\) it is not too hard to show that we get \\[\\begin{equation}\nf(x) = 1 + x + x^2 + x^3 + x^4 + x^5 + \\cdots\n\\end{equation}\\] (you should stop now and verify this!). However, if we plot the function \\(f(x)\\) along with several successive approximations for \\(f(x)\\) we find that beyond \\(x=1\\) we do not get the correct behaviour of the function (see Figure¬†2.3). More specifically, we cannot get the Taylor Series to change behaviour across the vertical asymptote of the function at \\(x=1\\). This example is meant to point out the fact that a Taylor Series will only ever make sense near the point at which you centre the expansion. For the function \\(f(x) = \\frac{1}{1-x}\\) centred at \\(x_0 = 0\\) we can only get good approximations within the interval \\(x \\in (-1,1)\\) and no further.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# build the x and y values\nx = np.linspace(-1,2,101)\ny0 = 1/(1-x)\ny1 = 1 + 0*x\ny2 = 1 + x\ny3 = 1 + x + x**2\ny4 = 1 + x + x**2 + x**3 + x**4 + x**5 + x**6 + x**7 + x**8\n\n# plot each of the functions \nplt.plot(x, y0, 'r-', label=r\"$f(x)=1/(1-x)$\")\nplt.plot(x, y1, 'c-', label=r\"constant\")\nplt.plot(x, y2, 'g:', label=r\"linear\")\nplt.plot(x, y3, 'b-.', label=r\"quadratic\")\nplt.plot(x, y4, 'k--', label=r\"8th order\")\n\n# set limits on the y axis\nplt.ylim(-3,5)\n\n# put in a grid, legend, title, and axis labels\nplt.grid()\nplt.legend()\nplt.title(r\"Taylor approximations of $f(x)=\\frac{1}{1-x}$ around $x=0$\")\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†2.3: Several Taylor Series approximations of the function \\(f(x) = 1/(1-x)\\).\n\n\n\n\n\n\n\nIn the previous example we saw that we cannot always get approximations from Taylor Series that are good everywhere. For every Taylor Series there is a domain of convergence where the Taylor Series actually makes sense and gives good approximations. It is beyond the scope of this section to give all of the details for finding the domain of convergence for a Taylor Series. You have done that in your first-year Calculus module. However a good heuristic is to observe that a Taylor Series will only give reasonable approximations of a function from the centre of the series to the nearest asymptote. The domain of convergence is typically symmetric about the centre as well. For example:\n\nIf we were to build a Taylor Series approximation for the function \\(f(x) = \\log(x)\\) centred at the point \\(x_0 = 1\\) then the domain of convergence should be \\(x \\in (0,2)\\) since there is a vertical asymptote for the natural logarithm function at \\(x=0\\).\nIf we were to build a Taylor Series approximation for the function \\(f(x) = \\frac{5}{2x-3}\\) centred at the point \\(x_0 = 4\\) then the domain of convergence should be \\(x \\in (1.5, 6.5)\\) since there is a vertical asymptote at \\(x=1.5\\) and the distance from \\(x_0 = 4\\) to \\(x=1.5\\) is 2.5 units.\nIf we were to build a Taylor Series approximation for the function \\(f(x) = \\frac{1}{1+x^2}\\) centred at the point \\(x_0 = 0\\) then the domain of convergence should be \\(x \\in (-1,1)\\). This may seem quite odd (and perhaps quite surprising!) but let us think about where the nearest asymptote might be. To find the asymptote we need to solve \\(1+x^2 = 0\\) but this gives us the values \\(x = \\pm i\\). In the complex plane, the numbers \\(i\\) and \\(-i\\) are 1 unit away from \\(x_0 = 0\\), so the ‚Äúasymptote‚Äù is not visible in a real-valued plot but it is still only one unit away. Hence the domain of convergence is \\(x \\in (-1,1)\\). You may want to pause now and build some plots to show yourself that this indeed appears to be true.\n\nOf course you learned all this and more in your first-year Calculus but I hope it was fun to now rediscover these things yourself. In your Calculus module it was probably not stressed how fundamental Taylor series are to doing numerical computations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html#sec-truncation_error",
    "href": "nmFunctions.html#sec-truncation_error",
    "title": "2¬† Functions",
    "section": "2.2 Truncation Error",
    "text": "2.2 Truncation Error\nThe great thing about Taylor Series is that they allow for the representation of potentially very complicated functions as polynomials ‚Äì and polynomials are easily dealt with on a computer since they involve only addition, subtraction, multiplication, division, and integer powers. The down side is that the order of the polynomial is infinite. Hence, every time we use a Taylor series on a computer, what we are actually going to be using is a Truncated Taylor Series where we only take a finite number of terms. The idea here is simple in principle:\n\nIf a function \\(f(x)\\) has a Taylor Series representation it can be written as an infinite sum.\nComputers cannot do infinite sums.\nSo stop the sum at some point \\(n\\) and throw away the rest of the infinite sum.\nNow \\(f(x)\\) is approximated by some finite sum so long as you stay pretty close to \\(x = x_0\\),\nand everything that we just chopped off of the end is called the remainder for the finite sum.\n\nLet us be a bit more concrete about it. The Taylor Series for \\(f(x) = e^x\\) centred at \\(x_0 = 0\\) is \\[\\begin{equation}\ne^x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\cdots.\n\\end{equation}\\]\nWhen we truncate this series at order \\(n\\), we separate it into an approximation and a remainder: \\[\\begin{equation}\ne^x = \\underbrace{1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^n}{n!}}_{\\text{$n^{th}$ order approximation}} + \\underbrace{\\frac{x^{n+1}}{(n+1)!} + \\frac{x^{n+2}}{(n+2)!} + \\cdots}_{\\text{remainder}}.\n\\end{equation}\\]\nFor small values of \\(x\\) near \\(x_0 = 0\\), the largest term in the remainder is \\(\\frac{x^{n+1}}{(n+1)!}\\), since higher powers of \\(x\\) become progressively smaller. We use Big-O notation to express this: \\[\\begin{equation}\ne^x \\approx 1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^n}{n!} + \\mathcal{O}(x^{n+1}),\n\\end{equation}\\] where the notation \\(\\mathcal{O}(x^{n+1})\\) (read ‚ÄúBig-O of \\(x^{n+1}\\)‚Äù) signifies that the error is bounded by \\(C|x|^{n+1}\\) for some constant \\(C\\) as \\(x \\to 0\\). This indicates that the error scales like \\(x^{n+1}\\) for values of \\(x\\) near the center \\(x_0=0\\).\nFor example:\n\n\\(0^{th}\\) order: \\(e^x \\approx 1 + \\mathcal{O}(x)\\)\n\\(1^{st}\\) order: \\(e^x \\approx 1 + x + \\mathcal{O}(x^2)\\)\n\\(2^{nd}\\) order: \\(e^x \\approx 1 + x + \\frac{x^2}{2} + \\mathcal{O}(x^3)\\)\n\nKeep in mind that this sort of analysis is only good for values of \\(x\\) that are very close to the centre of the Taylor Series. If you are making approximations that are too far away then all bets are off.\n\n\nExercise 2.13 üéì üíª Now make the previous discussion a bit more concrete. You know the Taylor Series for \\(f(x) = e^x\\) around \\(x=0\\) quite well at this point so use it to approximate the values of \\(f(0.1) = e^{0.1}\\) and \\(f(0.2)=e^{0.2}\\) by truncating the Taylor series at different orders. Because \\(x=0.1\\) and \\(x=0.2\\) are pretty close to the centre of the Taylor Series \\(x_0 = 0\\), this sort of approximation is reasonable.\nThen compare your approximate values to Python‚Äôs values \\(f(0.1)=e^{0.1} \\approx\\) np.exp(0.1) \\(=1.1051709180756477\\) and \\(f(0.2)=e^{0.2} \\approx\\) np.exp(0.2) \\(=1.2214027581601699\\) to calculate the truncation errors \\(\\epsilon_n(0.1)=|f(0.1)-f_n(0.1)|\\) and \\(\\epsilon_n(0.2)=|f(0.2)-f_n(0.2)|\\).\nFill in the blanks in the table. If you like, you can copy and paste the code and extend it to fill in the missing rows. For a bit of explanation of the syntax of the print commands see Example¬†A.20 but for more detailed information ask Gemini.\n\n\nCode\nimport numpy as np\n\n# Create table header\nprint(\n    f\"{'Order n':&lt;8} | {'f_n(0.1)':&lt;15} | {'Œµ_n(0.1)':&lt;15} | \"\n    f\"{'f_n(0.2)':&lt;15} | {'Œµ_n(0.2)':&lt;15} \"\n)\nprint(\"-\" * 80)\n\n# Fill in n=0 row\nf_n = lambda x: 1\ne_n = lambda x: abs(np.exp(x) - f_n(x))\nprint(\n    f\"{0:&lt;8} | {f_n(0.1):&lt;15.10g} | {e_n(0.1):&lt;15.10g} | \"\n    f\"{f_n(0.2):&lt;15.10g} | {e_n(0.2):&lt;15.10g} \"\n)\n\n# Fill in n=1 row\nf_n = lambda x: 1 + x\ne_n = lambda x: abs(np.exp(x) - f_n(x))\nprint(\n    f\"{1:&lt;8} | {f_n(0.1):&lt;15.10g} | {e_n(0.1):&lt;15.10g} | \"\n    f\"{f_n(0.2):&lt;15.10g} | {e_n(0.2):&lt;15.10g} \"\n)\n\n# Fill in more rows.\nfor n in range(2,6):\n    # TODO. You can use your `exp_approx()` function here.\n    print(f\"{n:&lt;8} | {'':&lt;15} | {'':&lt;15} | {'':&lt;15} | {'':&lt;15} \")\n\n\nOrder n  | f_n(0.1)        | Œµ_n(0.1)        | f_n(0.2)        | Œµ_n(0.2)        \n--------------------------------------------------------------------------------\n0        | 1               | 0.1051709181    | 1               | 0.2214027582    \n1        | 1.1             | 0.005170918076  | 1.2             | 0.02140275816   \n2        |                 |                 |                 |                 \n3        |                 |                 |                 |                 \n4        |                 |                 |                 |                 \n5        |                 |                 |                 |                 \n\n\nYou will find that, as expected, the truncation errors \\(\\epsilon_n(x)\\) decrease with \\(n\\) but increase with \\(x\\).\n\n\n\nExercise 2.14 üíª To investigate the dependence of the truncation error \\(\\epsilon_n(x)\\) on \\(n\\) and \\(x\\) a bit more, add an extra column to the table from the previous exercise with the ratio \\(\\epsilon_n(0.2) / \\epsilon_n(0.1)\\).\n\n\nOrder n  | Œµ_n(0.1)        | Œµ_n(0.2)        |  Œµ_n(0.2) / Œµ_n(0.1)\n--------------------------------------------------------------------------------\n0        | 0.1051709181    | 0.2214027582    | 2.105170918     \n1        | 0.005170918076  | 0.02140275816   | 4.139063479     \n2        |                 |                 |                \n3        |                 |                 |                \n4        |                 |                 |                \n5        |                 |                 |                \n\n\nüí¨ Formulate a conjecture about how \\(\\epsilon_n\\) changes as \\(x\\) changes.\n\n\n\nExercise 2.15 üíª To test your conjecture, examine the truncation error for the sine function near \\(x_0 = 0\\). You know that the sine function has the Taylor Series centred at \\(x_0 = 0\\) as \\[\\begin{equation}\nf(x) = \\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots.\n\\end{equation}\\] So there are only approximations of odd order. Use the truncated Taylor series to approximate \\(f(0.1)=\\sin(0.1)\\) and \\(f(0.2)=\\sin(0.2)\\) and use Python‚Äôs values np.sin(0.1) and np.sin(0.2) to calculate the truncation errors \\(\\epsilon_n(0.1)=|f(0.1)-f_n(0.1)|\\) and \\(\\epsilon_n(0.2)=|f(0.2)-f_n(0.2)|\\).\nComplete the following table:\n\n\nOrder n  | Œµ_n(0.1)        | Œµ_n(0.2)        |  Œµ_n(0.2) / Œµ_n(0.1)      \n--------------------------------------------------------------------------------\n1        | 0.0001665833532 | 0.001330669205  | 7.988008283               \n3        |                 |                 |                          \n5        |                 |                 |                          \n7        |                 |                 |                          \n9        |                 |                 |                          \n\n\nTo learn how you can loop over only odd integers in Python, see Example¬†A.7.\nüí¨ Did these results force you to revise your conjecture of how \\(\\epsilon_n\\) changes as \\(x\\) changes?\nThe entry in the last row of the table will almost certainly not agree with your conjecture. That is okay! That discrepancy has a different explanation. Can you figure out what it is? Hint: Think about the discussion of machine precision in Chapter 1.\n\n\n\nExercise 2.16 üéì üíª Perform another check of your conjecture by approximating \\(\\log(1.02)\\) and \\(\\log(1.1)\\) from truncations of the Taylor series around \\(x=1\\): \\[\n\\log(1+x) = x - \\frac{x^2}{2} + \\frac{x^3}{3} - \\frac{x^4}{4} + \\frac{x^5}{5} - \\cdots.\n\\]\n\n\n\nExercise 2.17 üí¨ üñã Write down your groups‚Äôs observations about how the truncation error changes as \\(x\\) changes. Explain this in terms of the form of the remainder of the truncated Taylor series.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html#exam-style-question",
    "href": "nmFunctions.html#exam-style-question",
    "title": "2¬† Functions",
    "section": "2.3 Exam-style question",
    "text": "2.3 Exam-style question\nYou know the Taylor Series expansion for \\(f(x) = \\sin(x)\\) centred at \\(x_0 = 0\\): \\[\\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots.\\]\n\nExplain why there is no \\(x^2\\) term in this Taylor Series expansion. [2 marks]\nComplete the Python code to calculate the Taylor expansion for \\(f(x) = \\sin(x)\\) centred at \\(x_0 = 0\\) up to order \\(n\\). [4 marks]\n\n\ndef sin_taylor(x, n):\n    \"\"\"\n    Calculate the Taylor expansion for f(x) = sin(x) centred at x_0 = 0 up to order n.\n    \"\"\"\n    ....\n    for i in range(...):\n        ....\n    \n    return result\n\n\nIf we only keep terms up to \\(x^3\\) in this Taylor Series expansion, what is the truncation error in Big-O notation for the approximation? [2 marks]\nIf we use the same approximation to calculate \\(\\sin(0.05)\\) instead of \\(\\sin(0.1)\\), by what factor do we expect the truncation error to decrease? [2 marks]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html#sec-nn",
    "href": "nmFunctions.html#sec-nn",
    "title": "2¬† Functions",
    "section": "2.4 Neural Networks",
    "text": "2.4 Neural Networks\nSo far we have discussed approximating functions with polynomials, and in particular with Taylor Series. However there are other families of functions that can be used to approximate an arbitrary function. One of them you have already met in your first year: Fourier series. Another one that is usually discussed in a course on Numerical Analysis is splines. In this module we will not discuss these families of functions. Our aim in this module is not to be exhaustive, but to get the fundamental ideas across, so that you will be well equipped to acquire further knowledge on the topic later on.\nThere is however a family of functions that has recently become very popular in machine learning: neural networks. This section guides you through exercises to obtain a good intuitive understanding of neural networks.\nIt may well be that by the time you reach this point in the learning guide, you will not have much time left this week. For that reason the material on neural networks is not examinable. You are under no pressure to work through this material. However, if you do have the time and interest, I would encourage you to do so.\nSimilar to how a polynomial \\(p(x)\\) is determined by giving the coefficients in front of the powers of \\(x\\), a neural network is determined by giving a set of parameters, called weights and biases. In this section you will explore how the weights and biases determine the neural network function.\n\n\n2.4.1 A Single Neuron\nLet us start by building up the components of a neural network one piece at a time. The fundamental building block is called a neuron.\n\nExercise 2.18 üñã Consider the simple function \\[\\begin{equation}\nf(x) = \\max(0, x).\n\\end{equation}\\] The function \\(g(x) = \\max(0, x)\\) is called the Rectified Linear Unit or ReLU for short.\n\nBy hand, sketch the graph of this function for \\(x \\in [-3, 3]\\).\nWhat is the derivative of \\(f(x)\\) for \\(x &gt; 0\\)? What about for \\(x &lt; 0\\)? What happens at \\(x = 0\\)?\n\n\n\nThe ReLU function is an example of what is called an activation function in neural networks. The idea is that the neuron ‚Äúactivates‚Äù (produces a non-zero output) only when the input exceeds a certain threshold.\n\nExercise 2.19 üñã Now let us make our neuron a bit more interesting by allowing it to have adjustable parameters.\nConsider the function \\[\\begin{equation}\nh(x) = \\max(0, w x + b)\n\\end{equation}\\] where \\(w\\) and \\(b\\) are parameters that we can choose. These are called the weight and bias respectively.\n\nBy hand, sketch the graph of \\(h(x)\\) for \\(x \\in [-3, 3]\\) for each of the following parameter values:\n\n\\(w = 1, b = 0\\)\n\\(w = 2, b = 0\\)\n\\(w = 1, b = 1\\)\n\\(w = 1, b = -1\\)\n\\(w = -1, b = 0\\)\n\nDescribe in words what the weight \\(w\\) controls about the function \\(h(x)\\).\nDescribe in words what the bias \\(b\\) controls about the function \\(h(x)\\).\nFor which values of \\(x\\) is the function ‚Äúactive‚Äù (i.e., non-zero) when \\(w = 1\\) and \\(b = -1\\)?\n\n\n\n\nExercise 2.20 üñã So far we have been working with a neuron that takes a single input \\(x\\). In many applications, we want to work with functions of multiple variables.\nSuppose we have two inputs \\(x_1\\) and \\(x_2\\), and we define a neuron as \\[\\begin{equation}\nh(x_1, x_2) = \\max(0, w_1 x_1 + w_2 x_2 + b)\n\\end{equation}\\] where \\(w_1, w_2\\) are weights and \\(b\\) is a bias.\n\nWhat is the output of this neuron when \\(x_1 = 1, x_2 = 2\\), using the parameters \\(w_1 = 1, w_2 = -1, b = 0\\)?\nThe expression \\(w_1 x_1 + w_2 x_2 + b = 0\\) defines a line in the \\((x_1, x_2)\\) plane. For the parameters in part 1, sketch this line in the region \\(x_1 \\in [-2, 2], x_2 \\in [-2, 2]\\).\nOn which side of this line is the neuron ‚Äúactive‚Äù (produces non-zero outputs)? Shade that area in your sketch from part 2.\n\n\n\n\n\n2.4.2 Combining Neurons into a Layer\nA single neuron can detect when the input crosses a particular threshold. But to approximate more complex functions, we need to combine multiple neurons together. Let us explore this idea.\n\nExercise 2.21 üñã Suppose we have two neurons, both taking the same input \\(x\\), but with different weights and biases: \\[\\begin{align}\nh_1(x) &= \\max(0, w_1 x + b_1) \\\\\nh_2(x) &= \\max(0, w_2 x + b_2)\n\\end{align}\\]\nConsider the specific case where \\(w_1 = 1, b_1 = -1\\) and \\(w_2 = -1, b_2 = 1\\).\n\nFor what values of \\(x\\) is \\(h_1(x)\\) active (non-zero)?\nFor what values of \\(x\\) is \\(h_2(x)\\) active (non-zero)?\nBy hand, sketch the graphs of both \\(h_1(x)\\) and \\(h_2(x)\\) on the same axes for \\(x \\in [-2, 2]\\).\nNow consider the sum \\(h_1(x) + h_2(x)\\). By hand, sketch the graph of this function. Describe its shape.\nWhat is the minimum value of \\(h_1(x) + h_2(x)\\)? At what value of \\(x\\) does this minimum occur?\n\n\n\n\nExercise 2.22 üñã Rather than just adding two ReLU neurons, consider the weighted combination: \\[\\begin{equation}\nf(x) = c_1 h_1(x) + c_2 h_2(x)\n\\end{equation}\\] where \\(c_1\\) and \\(c_2\\) are output weights that can be positive or negative.\nLet \\(h_1(x) = \\max(0, x)\\) and \\(h_2(x) = \\max(0, x - 1)\\).\n\nWhat is \\(f(x) = h_1(x) - 2h_2(x)\\) for \\(x &lt; 0\\)?\nWhat is \\(f(x) = h_1(x) - 2h_2(x)\\) for \\(0 \\leq x &lt; 1\\)?\nWhat is \\(f(x) = h_1(x) - 2h_2(x)\\) for \\(x \\geq 1\\)?\n\nBy hand, sketch the graph of this function.\n\n\n\nExercise 2.23 üñã In the previous exercise you created a function with a triangular bump but the function continued decreasing to negative values beyond \\(x=2\\). Now see if you can find a way to combine three ReLU neurons to create a triangular bump function that:\n\nis zero for \\(x &lt; 0\\) and \\(x &gt; 2\\)\nequals \\(x\\) for \\(0 \\leq x \\leq 1\\)\nequals \\(2-x\\) for \\(1 &lt; x \\leq 2\\)\n\n\nWrite down the weights \\(w_1, b_1, w_2, b_2, w_3, b_3\\) and output weights \\(c_1, c_2\\) and \\(c_3\\) that produce the desired function. Hint: You need \\(h_3\\) to ‚Äúcancel out‚Äù the negative values after \\(x=2\\).\nSketch the graph of your function to verify that it works.\nHow could you modify the output weights to make the bump twice as tall?\nHow could you modify the weights and biases to shift the bump so that it is centred at \\(x = 5\\) instead of \\(x = 1\\)?\n\n\n\n\n\n2.4.3 A Two-Layer Neural Network\nIn the previous exercises, you discovered that by combining multiple neurons (each with a ReLU activation), we can build flexible function approximations. Let us now formalise this into what is called a two-layer neural network or single hidden layer network.\nThe structure is as follows:\n\nInput: We start with an input value \\(x\\).\nHidden Layer: We apply \\(n\\) neurons to the input, creating \\(n\\) hidden values: \\[\\begin{equation}\nh_i(x) = \\max(0, w_i x + b_i) \\quad \\text{for } i = 1, 2, \\ldots, n\n\\end{equation}\\] The parameters \\(w_i\\) and \\(b_i\\) are called the weights and biases of the hidden layer.\nOutput Layer: We combine the hidden values using output weights: \\[\\begin{equation}\nf(x) = c_1 h_1(x) + c_2 h_2(x) + \\cdots + c_n h_n(x) + c_0\n\\end{equation}\\] where \\(c_0, c_1, \\ldots, c_n\\) are the output layer parameters.\n\nWe can write this more compactly using summation notation: \\[\\begin{equation}\nf(x) = \\sum_{i=1}^{n} c_i \\max(0, w_i x + b_i) + c_0.\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\nThis function \\(f(x)\\) is determined by the parameters:\n\nHidden layer weights: \\(w_1, w_2, \\ldots, w_n\\)\nHidden layer biases: \\(b_1, b_2, \\ldots, b_n\\)\n\nOutput weights: \\(c_1, c_2, \\ldots, c_n\\)\nOutput bias: \\(c_0\\)\n\nThat gives us a total of \\(3n + 1\\) parameters to work with.\nNote that, due to the simple linear nature of the ReLU activation function that we have chosen to use here, we can absorb the weights of the hidden layer neurons into a rescaling of the of the output weights and the biases. This would not be true for more general activation functions.\nSo we choose to set all hidden weights to \\(1\\) and thus work with \\[\\begin{equation}\nf_{nn}(x) = \\sum_{i=1}^{n} c_i \\max(0, x + b_i) + c_0\n\\end{equation}\\]\nThe following Python code implements such a neural network. Make sure you understand the code.\n\nimport numpy as np\n\ndef two_layer_network(x, biases, output_weights, output_bias=0):\n    \"\"\"\n    Evaluates a two-layer neural network approximation.\n    \n    Parameters:\n    x (float): The value at which to evaluate the network.\n    biases (list or array): Biases for hidden layer\n        These determine the knot points: x_i = -b_i\n    output_weights (list or array) : Weights for output layer\n    output_bias (float): Bias for output layer (default: 0)\n    \n    Returns:\n    --------\n    float: The output of the neural network.\n    \"\"\"\n    f_nn = output_bias * np.ones_like(x)  # bias term\n    for i in range(len(biases)):\n        f_nn += output_weights[i] * np.maximum(0, x + biases[i])\n    return f_nn\n\n\n\nExercise 2.24 üí¨ Explain in your own words why a two-layer neural network is flexible enough to approximate many different functions. How do the output weights control the shape of the approximation?\nHow is this similar to polynomial approximation? How is it different?\n\n\n\nExercise 2.25 üíª In this exercise we will approximate a smooth function with a neural network using a simple but powerful idea: we can create a piecewise linear approximation by using a sum of ReLU neurons, each of which activates at a new point. Each ReLU neuron that activates at a new point changes the slope of our piecewise linear approximation.\nConsider approximating \\(f(x) = \\sin(x)\\) on the interval \\([0, \\pi]\\) using a two-layer neural network. We‚Äôll place ReLU neurons at several ‚Äúknot points‚Äù along the curve, and each neuron will adjust the slope.\n\nUnderstanding slope changes: Suppose we use knot points at \\(x_1 = -b_1 = 0, x_2 = -b_2 = \\pi/2\\).\n\nFor \\(x \\in [0, \\pi/2)\\): What is the slope of \\(f_{nn}(x)\\)? (Hint: which neurons are active?)\nFor \\(x \\in [\\pi/2, \\pi)\\): What is the slope?\n\nExplain how the output weight \\(c_2\\) controls the change in slope at \\(x = \\pi/2\\).\n\nSuggest a choice for the output weights \\(c_0, c_1, c_2\\) that you think will give some kind of crude approximation of \\(\\sin(x)\\) on the interval \\([0,\\pi]\\). Use the Python function plot_neural_network provided below to make a plot of your approximation.\n\nUse the Python function plot_neural_network with 4 knot points at \\(x = 0, \\pi/4, \\pi/2, 3\\pi/4\\). Try to find output weights that create a good approximation.\nCalculate the maximum approximation error and discuss how it could be improved.\nExperiment with more knot points (try 9 or 17 points evenly spaced). How does the approximation improve?\n\nPython helper function:\n\nimport numpy as np\nimport matplotlib.pyplot as plt \n\ndef plot_neural_network(biases, output_weights, output_bias=0,\n                        x_range=(0, np.pi), target_func=np.sin):\n    \"\"\"\n    Plot a two-layer neural network approximation.\n    \n    Parameters:\n    biases (list or array): Biases for hidden layer\n        These determine the knot points: x_i = -b_i\n    output_weights (list or array) : Weights for output layer\n    output_bias (float): Bias for output layer (default: 0)\n    x_range : tuple\n        (x_min, x_max) for plotting (default: (0, np.pi))\n    target_func : function\n        The target function to approximate (default: np.sin)\n    \n    Returns:\n    float: Maximum absolute error\n    \"\"\"\n    x = np.linspace(x_range[0], x_range[1], 500)\n    \n    # Compute neural network output\n    f_nn = two_layer_network(x, biases, output_weights, output_bias)\n    \n    # Compute target\n    f_target = target_func(x)\n    \n    # Plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, f_target, 'r-', linewidth=2, label='Target function')\n    plt.plot(x, f_nn, 'b--', linewidth=2, label='Neural network')\n    \n    # Mark knot points\n    knots = [-b for b in biases]\n    for knot in knots:\n        if x_range[0] &lt;= knot &lt;= x_range[1]:\n            plt.axvline(knot, color='gray', linestyle=':', alpha=0.5)\n    \n    plt.grid(True, alpha=0.3)\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Neural Network Approximation')\n    plt.show()\n    \n    # Calculate and return error\n    error = np.max(np.abs(f_target - f_nn))\n    print(f\"Maximum error: {error:.4f}\")\n    return error\n\n# Example usage:\n# output_weights = [1, -0.3, -0.5, -0.4]\n# biases = [0, -np.pi/4, -np.pi/2, -3*np.pi/4]\n# plot_neural_network(biases, output_weights)\n\n\n\nAfter your experimentation, the following result will no longer seem so surprising:\n\nTheorem 2.1 (Universal Approximation Theorem (informal version)) A two-layer neural network with a sufficient number of neurons can approximate any continuous function on a bounded interval to arbitrary accuracy.\nMore precisely: for any continuous function \\(f: [a,b] \\to \\mathbb{R}\\) and any \\(\\epsilon &gt; 0\\), there exists a two-layer neural network \\(f_{\\text{nn}}\\) such that \\[\\begin{equation}\n\\max_{x \\in [a,b]} |f(x) - f_{\\text{nn}}(x)| &lt; \\epsilon.\n\\end{equation}\\]\n\n\n\nExercise 2.26 üí¨ Reflect on what you have learned about neural networks and compare them to Taylor series:\n\nWhat are the advantages of using neural networks for function approximation compared to Taylor series?\nWhat are the advantages of Taylor series compared to neural networks?\nFor each of the following functions, which approximation method (Taylor series or neural network) do you think would be more appropriate, and why?\n\n\\(f(x) = e^x\\) near \\(x = 0\\)\n\\(f(x) = |x|\\) near \\(x = 0\\)\n\n\\(f(x) = \\sin(100x)\\) on \\([0, 2\\pi]\\)\nA function defined by experimental data points\n\nNeural networks are determined by their weights and biases. Taylor series are determined by the derivatives of the function at a point. Which do you think is easier to compute in practice, and why?\n\n\n\n\n\n2.4.4 Deep Neural Networks\nSo far we have looked at two-layer neural networks (one hidden layer + one output layer). But we can also stack multiple layers on top of each other to create deep neural networks.\nThe idea is simple: instead of having the output layer directly combine the hidden neurons, we can feed the hidden neurons into another layer of neurons, and then another, and so on.\nFor example, a three-layer network would look like:\n\nInput: \\(x\\)\nFirst Hidden Layer: \\[\\begin{equation}\nh_i^{(1)}(x) = \\max(0, w_i^{(1)} x + b_i^{(1)}) \\quad \\text{for } i = 1, \\ldots, n_1\n\\end{equation}\\]\nSecond Hidden Layer: Each neuron in this layer takes all outputs from the first hidden layer: \\[\\begin{equation}\nh_j^{(2)} = \\max\\left(0, \\sum_{i=1}^{n_1} w_{ji}^{(2)} h_i^{(1)} + b_j^{(2)}\\right) \\quad \\text{for } j = 1, \\ldots, n_2\n\\end{equation}\\]\nOutput Layer: \\[\\begin{equation}\nf(x) = \\sum_{j=1}^{n_2} c_j h_j^{(2)} + c_0\n\\end{equation}\\]\n\nThis is called a deep neural network because it has multiple hidden layers. The term ‚Äúdeep learning‚Äù comes from using such multi-layer architectures.\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5 Why Depth Matters: The Sawtooth Example\nWhy are deep neural networks, with many layers, often more powerful than shallow networks with just one large hidden layer? In the following exercises, you will explore a classic example, the sawtooth wave, to discover a concrete answer. You‚Äôll build both a shallow and a deep network to represent the same function, and compare their efficiency as the complexity grows. Through this exploration, you‚Äôll see how deep networks can represent certain functions far more efficiently by exploiting their compositional structure.\nWe‚Äôll work with a sawtooth function that has 2 triangular peaks on the interval \\([0, 1]\\): \\[\\begin{equation}\nf(x) = \\begin{cases}\n4x & \\text{if } 0 \\leq x &lt; 0.25 \\\\\n2 - 4x & \\text{if } 0.25 \\leq x &lt; 0.5 \\\\\n4x - 2 & \\text{if } 0.5 \\leq x &lt; 0.75 \\\\\n4 - 4x & \\text{if } 0.75 \\leq x \\leq 1\n\\end{cases}\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\nExercise 2.27 (Building a Shallow Network for the Sawtooth) You already know how to represent piecewise linear functions with a two-layer neural network. Each of the 5 ‚Äúhinge points‚Äù (where the slope changes) requires a ReLU neuron.\na) For each hinge point at position \\(x_i\\), you need a ReLU neuron with bias \\(b_i = -x_i\\).\nb) What are the output weights with which you need to combinae these neurons?\nUse this to complete the code below and use the plot to check that the resulting function has the desired form.\ndef shallow_2_peak_network(x):\n    biases = [.....]\n    output_weights = [.....]\n    return two_layer_network(x, biases, output_weights)\n\n# Plot\nplt.figure(figsize=(10, 6))\nx = np.linspace(-0.1,1.1,500)\nplt.plot(x, shallow_2_peak_network(x), 'r-', lw=3)\nplt.grid()\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('2-Peak Sawtooth Function')\nplt.show()\n\n\n\nExercise 2.28 (Building the Deep Network) A deeper network takes a more elegant approach. Instead of directly creating all the peaks, it uses one layer to create a single peak and then another layer to duplicate this peak.\nThe key insight is to create a single-peak function \\[g(x) = \\begin{cases}2x&0\\leq x&lt;1/2\\\\2(1-x)&1/2\\leq x\\leq1\\\\0 & x\\not\\in [0,1]\\end{cases}\\] that produces one triangular peak at \\(x = 0.5\\) with height 1, returning to 0 at \\(z &lt; 0\\) and \\(z &gt; 1\\).\n\n\n\n\n\n\n\n\n\nThen, our 2-peak sawtooth is simply \\(f(x) = g(g(x))\\).\na) First, create a single-peak as a shallow network with three hidden neurons.\ndef g(x):\n    \"\"\" Single triangular peak \"\"\"\n    biases = [.....]\n    output_weights = [.....]\n    return two_layer_network(x, biases, output_weights)\n\n# Plot\nplt.figure(figsize=(10, 6))\nx = np.linspace(-0.1,1.1,500)\nplt.plot(x, g(x), 'r-', lw=3))\nplt.grid()\nplt.xlabel('x')\nplt.ylabel('g(x)')\nplt.title('Single peak function')\nplt.show()\nb) Now comes the magic! Pass the result of your network \\(g(x)\\) through the same network again: compute \\(g(g(x))\\). Plot the result and compare it to the target.\n\nf = lambda x: g(g(x))\n\n# Plot\nplt.figure(figsize=(10, 6))\nx = np.linspace(-0.1,1.1,500)\nplt.plot(x, f(x), 'r-', lw=3)\nplt.grid()\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('2-Peak Sawtooth Function')\nplt.show()\n\n\n\n\n\n\n\n\nc) Explain in your own words: Why does applying \\(g\\) twice produce two peaks? Think about what happens as the first application of \\(g\\) creates a peak that rises from 0 to 1 and back to 0. What does the second application of \\(g\\) see as its input?\nd) Create a 4-peak sawtooth by composing \\(g\\) three times: \\(g(g(g(x)))\\). Plot it. How many hidden neurons does this use? Compare to the shallow network approach from the previous exercise.\n\n\n\nExercise 2.29 (Scaling Analysis: The Exponential Advantage) Now let‚Äôs compare how the two approaches scale as we increase the number of peaks.\na) üñã Complete this table by implementing both shallow and deep networks for different numbers of peaks:\n\n\n\n\n\n\n\n\n\nNumber of Peaks\nShallow Network Neurons\nDeep Network Neurons\nAdvantage (ratio)\n\n\n\n\n2\n5\n6\n0.83\n\n\n4\n?\n?\n?\n\n\n8\n?\n?\n?\n\n\n16\n?\n?\n?\n\n\n\nb) üñã Based on your table, write formulas for the number of neurons needed as a function of the number of peaks \\(n\\) for both approaches. What kind of growth do you observe (linear, logarithmic, exponential)?\nHint: For the deep network, if \\(n = 2^k\\) peaks, how many layers do you need? How many neurons per layer?\nc) üíª Visualize the scaling behavior. Plot the number of neurons (y-axis) versus the number of peaks (x-axis) for both approaches:\n# TODO: Create arrays for different numbers of peaks\npeaks = [2, 4, 8, 16, 32, 64]\nshallow_neurons = [...]  # Fill in based on your formula\ndeep_neurons = [...]     # Fill in based on your formula\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.plot(peaks, shallow_neurons, 'bo-', label='Shallow Network', lw=2)\nplt.plot(peaks, deep_neurons, 'mo-', label='Deep Network', lw=2)\nplt.xlabel('Number of Peaks')\nplt.ylabel('Number of Hidden Neurons')\nplt.title('Scaling: Shallow vs Deep Networks')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\nd) üí¨ Based on your analysis, explain why deep networks can be more efficient than shallow networks for certain types of functions. What specific property of the sawtooth function makes it particularly well-suited for a deep architecture?\ne) üí¨ The deep network achieves its efficiency by reusing the same learned ‚Äúpeak-making‚Äù module across layers through composition. Can you think of other real-world functions or patterns that might benefit from deep architectures in a similar way? Consider:\n\nFunctions with repetitive structures at different scales (e.g., fractals, wavelets)\nHierarchical patterns (e.g., language: letters ‚Üí words ‚Üí sentences)\nFunctions that can be naturally expressed as compositions of simpler functions\n\nf) üí¨ What are the limitations of this advantage? Can you think of functions where a shallow network might be more efficient than a deep one? (Hint: What if the function has no repetitive or compositional structure?)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html#sec-functions_problems",
    "href": "nmFunctions.html#sec-functions_problems",
    "title": "2¬† Functions",
    "section": "2.5 Problems",
    "text": "2.5 Problems\n\nExercise 2.30 Find the Taylor Series for \\(f(x) = \\frac{1}{\\log(x)}\\) centred at the point \\(x_0 = e\\). Then use the Taylor Series to approximate the number \\(\\frac{1}{\\log(3)}\\) to 4 decimal places.\n\n\n\nExercise 2.31 In this problem we will use Taylor Series to build approximations for the irrational number \\(\\pi\\).\n\nWrite the Taylor series centred at \\(x_0=0\\) for the function \\[\\begin{equation}\nf(x) = \\frac{1}{1+x}.\n\\end{equation}\\]\nNow we want to get the Taylor Series for the function \\(g(x) = \\frac{1}{1+x^2}\\). It would be quite time consuming to take all of the necessary derivatives to get this Taylor Series. Instead we will use our answer from part (a) of this problem to shortcut the whole process.\n\nSubstitute \\(x^2\\) for every \\(x\\) in the Taylor Series for \\(f(x) = \\frac{1}{1+x}\\).\nMake a few plots to verify that we indeed now have a Taylor Series for the function \\(g(x) = \\frac{1}{1+x^2}\\).\n\nRecall from Calculus that \\[\\begin{equation}\n\\int \\frac{1}{1+x^2} dx = \\arctan(x).\n\\end{equation}\\] Hence, if we integrate each term of the Taylor Series that results from part (2) we should have a Taylor Series for \\(\\arctan(x)\\).1\nNow recall the following from Calculus:\n\n\\(\\tan(\\pi/4) = 1\\)\nso \\(\\arctan(1) = \\pi/4\\)\nand therefore \\(\\pi = 4\\arctan(1)\\).\n\nLet us use these facts along with the Taylor Series for \\(\\arctan(x)\\) to approximate \\(\\pi\\): we can just plug in \\(x=1\\) to the series, add up a bunch of terms, and then multiply by 4. Write a loop in Python that builds successively better and better approximations of \\(\\pi\\). Stop the loop when you have an approximation that is correct to 6 decimal places.\n\n\n\n\nExercise 2.32 In this problem we will prove the famous formula \\[\\begin{equation}\ne^{i\\theta} = \\cos(\\theta) + i \\sin(\\theta).\n\\end{equation}\\] This is known as Euler‚Äôs formula after the famous mathematician Leonard Euler. Show all of your work for the following tasks.\n\nWrite the Taylor series for the functions \\(e^x\\), \\(\\sin(x)\\), and \\(\\cos(x)\\).\nReplace \\(x\\) with \\(i\\theta\\) in the Taylor expansion of \\(e^x\\). Recall that \\(i = \\sqrt{-1}\\) so \\(i^2 = -1\\), \\(i^3 = -i\\), and \\(i^4 = 1\\). Simplify all of the powers of \\(i\\theta\\) that arise in the Taylor expansion. I will get you started: \\[\\begin{equation}\n\\begin{aligned} e^x &= 1 + x + \\frac{x^2}{2} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\frac{x^5}{5!} + \\cdots \\\\ e^{i\\theta} &= 1 + (i\\theta) + \\frac{(i\\theta)^2}{2!} + \\frac{(i\\theta)^3}{3!} + \\frac{(i\\theta)^4}{4!} + \\frac{(i\\theta)^5}{5!} + \\cdots \\\\ &= 1 + i\\theta + i^2 \\frac{\\theta^2}{2!} + i^3 \\frac{\\theta^3}{3!} + i^4 \\frac{\\theta^4}{4!} + i^5 \\frac{\\theta^5}{5!} + \\cdots \\\\ &= \\ldots \\text{ keep simplifying ... } \\ldots \\end{aligned}\n\\end{equation}\\]\nGather all of the real terms and all of the imaginary terms together. Factor the \\(i\\) out of the imaginary terms. What do you notice?\nUse your result from part (3) to prove that \\(e^{i\\pi} + 1 = 0\\).\n\n\n\n\nExercise 2.33 In physics, the relativistic energy of an object is defined as \\[\\begin{equation}\nE_{rel} = \\gamma mc^2\n\\end{equation}\\] where \\[\\begin{equation}\n\\gamma = \\frac{1}{\\sqrt{1 - \\frac{v^2}{c^2}}}.\n\\end{equation}\\] In these equations, \\(m\\) is the mass of the object, \\(c\\) is the speed of light (\\(c \\approx 3 \\times 10^8\\)m/s), and \\(v\\) is the velocity of the object. For an object of fixed mass (m) we can expand the Taylor Series centred at \\(v=0\\) for \\(E_{rel}\\) to get \\[\\begin{equation}\nE_{rel} = mc^2 + \\frac{1}{2} mv^2 + \\frac{3}{8} \\frac{mv^4}{c^2} + \\frac{5}{16} \\frac{mv^6}{c^4} + \\cdots.\n\\end{equation}\\]\n\nWhat do we recover if we consider an object with zero velocity?\nWhy might it be completely reasonable to only use the quadratic approximation \\[\\begin{equation}\nE_{rel} = mc^2 + \\frac{1}{2} mv^2\n\\end{equation}\\] for the relativistic energy equation?2\n(some physics knowledge required) What do you notice about the second term in the Taylor Series approximation of the relativistic energy function?\nShow all of the work to derive the Taylor Series centred at \\(v = 0\\) given above.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "nmFunctions.html#footnotes",
    "href": "nmFunctions.html#footnotes",
    "title": "2¬† Functions",
    "section": "",
    "text": "There are many reasons why integrating an infinite series term by term should give you a moment of pause. For the sake of this problem we are doing this operation a little blindly, but in reality we should have verified that the infinite series actually converges uniformly.‚Ü©Ô∏é\nThis is something that people in physics and engineering do all the time ‚Äì there is some complicated nonlinear relationship that they wish to use, but the first few terms of the Taylor Series captures almost all of the behaviour since the higher-order terms are very very small.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Functions</span>"
    ]
  }
]