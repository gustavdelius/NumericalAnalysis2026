# Exam solutions

In this appendix you find example solutions to the exam-style questions.

## Numbers

**(a) Machine Precision**

Machine precision is the gap between the number 1 and the next larger floating point number. With 4 bits for the mantissa, the smallest number greater than $1$ that can be represented is $1.0001_2$. So machine precision is $\epsilon = 0.0001_2=1/16$. The machine precision is the upper bound for the relative rounding error.

**(b) Conversion of 13.5**

*   Sign: Positive ($+13.5$), so **$s=0$**.
*   Convert $13.5$ to binary:
    *   $13_{10} = 1101_2$.
    *   $0.5_{10} = 0.1_2$.
    *   Result: $1101.1_2$.
*   Normalize: $1.1011 \times 2^3$.
*   Exponent ($E=3$):
    *   Stored exponent $e = E + 3 = 3 + 3 = 6$.
    *   $6_{10} = 110_2$.
*   Mantissa ($m$): Drop the leading 1 $\rightarrow$ `1011`.
*   **Final Bit Pattern:** **`0 110 1011`**.

**(c) Addition: 13.5 + 0.25**

*   **Convert second number (0.25):**
    *   $0.25 = 1/4 = 1.0 \times 2^{-2}$.
*   **Align Exponents:**
    *   $x_1 = 1.1011 \times 2^3$
    *   $x_2 = 1.0000 \times 2^{-2}$
    *   Shift $x_2$ to match exponent $3$: Shift right by $3 - (-2) = 5$ positions.
    *   $x_2 \rightarrow 0.00001 \times 2^3$.
*   **Add Significands:**

    ``` text
      1.1011      (13.5)
    + 0.00001     (0.25 aligned)
    -----------
      1.10111
    ```

*   **Rounding:**
    *   The result $1.10111_2$ has 5 fractional bits, but we can only store 4.
    *   It lies exactly halfway between $1.1011$ ($13.5$) and $1.1100$ ($14.0$).
    *   Tie-breaking rule: "Ties to Even".
    *   The Least Significant Bit (4th bit) is `1` (odd). To make it even, we round **up** (add 1 to the LSB).
    *   $1.1011 + 0.0001 = 1.1100$.
*   **Final Result:**
    *   Significand: $1.1100$
    *   Value: $1.1100_2 \times 2^3 = 1110.0_2 = \mathbf{14.0}$.
*   **Error:**
    *   Exact sum: $13.75$.
    *   Stored sum: $14.0$.
    *   Absolute Error: $|13.75 - 14.0| = \mathbf{0.25}$.

**(d) Loss of Significance**

*   **Error Type:** Catastrophic Cancellation (or Loss of Significant Digits).
*   **Explanation:** When $x$ is very large ($10^8$), $x^2 + 1 \approx x^2$, so $\sqrt{x^2+1} \approx x$. Subtracting two extremely close numbers causes the cancellation of the leading digits, leaving only the random "noise" from the least significant bits.
*   **Improved (Stable) Formula:** Multiply by the conjugate:
    $$f(x) = \frac{(\sqrt{x^2+1} - x)(\sqrt{x^2+1} + x)}{\sqrt{x^2+1} + x} = \frac{1}{\sqrt{x^2+1} + x}.$$

## Roots 1

**(a) Conditions for Bisection Method Convergence**

*   The function $f$ must be continuous on the closed interval $[a, b]$.
*   The function values at the endpoints must have opposite signs, i.e., $f(a) \cdot f(b) < 0$. 


**(b) Number of Iterations**

*   The error after $n$ iterations is bounded by $\frac{|b-a|}{2^n} = \frac{1}{2^n}$.
*   We need $\frac{1}{2^n} \le 2^{-20}$. Therefore, $n = 20$ iterations are required.

**(c) Three Iterations of Bisection Method**

*   **Iteration 1:**
    *   Interval: $[a, b] = [1, 2]$.
    *   Midpoint $m_1 = 1.5$.
*   **Iteration 2:**
    *   From the graph, $f(1.5)$ is slightly below the x-axis, so $f(1.5) < 0$.
    *   Since $f(1.5) < 0$ and $f(2) > 0$, the root must lie in the new interval $[1.5, 2]$.
    *   Midpoint $m_2 = \frac{1.5 + 2}{2} = 1.75$.
*   **Iteration 3:**
    *   From the graph, at $x=1.75$, the function curve is clearly above the x-axis, so $f(1.75) > 0$.
    *   Since $f(1.5) < 0$ and $f(1.75) > 0$, the narrower interval containing the root is $[1.5, 1.75]$.
    *   Midpoint $m_3 = \frac{1.5 + 1.75}{2} = 1.625$.


**(d) Fixed-Point Iteration**

*   **i) Convergence check:**
    *   $g(x) = (x+2)^{1/3}$
    *   $g'(x) = \frac{1}{3}(x+2)^{-2/3}$.
    *   For $x \in [1, 2]$, the denominator is positive and increasing.
    *   The maximum of $|g'(x)|$ on this interval occurs at $x = 1$, where $g'(1) = \frac{1}{3(3)^{2/3}}$.
    *   Since $|g'(x)| < 1$ for all $x \in [1, 2]$ and $g(x) \in [1, 2]$ on this interval (as $g(1) \approx 1.44$ and $g(2) \approx 1.58$), the Fixed-Point Theorem guarantees convergence for any $x_0 \in [1, 2]$.

*   **ii) Code:**

    ``` python
    def fixed_point_iteration():
        x = 1.0
        for i in range(10):
            x = (x + 2)**(1/3)
        return x
    ```
